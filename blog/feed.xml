<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://www.testmysearch.com/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.testmysearch.com/blog/" rel="alternate" type="text/html" /><updated>2026-02-27T21:01:47-05:00</updated><id>https://www.testmysearch.com/blog/feed.xml</id><title type="html">TestMySearch Blog</title><subtitle>The official blog for TestMySearch. Articles and insights on search quality,  information retrieval, and relevance engineering from Rauf Aliev.</subtitle><author><name>Rauf Aliev</name></author><entry><title type="html">Gemini API offers significant architectural and functional advantages over GPT-4 API, particularly when handling complex, multi-page scientific document</title><link href="https://www.testmysearch.com/blog/2026/02/27/gemini-chatgpt.html" rel="alternate" type="text/html" title="Gemini API offers significant architectural and functional advantages over GPT-4 API, particularly when handling complex, multi-page scientific document" /><published>2026-02-27T00:00:00-05:00</published><updated>2026-02-27T00:00:00-05:00</updated><id>https://www.testmysearch.com/blog/2026/02/27/gemini-chatgpt</id><content type="html" xml:base="https://www.testmysearch.com/blog/2026/02/27/gemini-chatgpt.html"><![CDATA[<h1 id="gemini-api-offers-significant-architectural-and-functional-advantages-over-gpt-4-api-particularly-when-handling-complex-multi-page-scientific-documents">Gemini API offers significant architectural and functional advantages over GPT-4 API, particularly when handling complex, multi-page scientific documents</h1>

<p>The core task was to take a large volume PDF, load it once, and ask several questions across separate, independent sessions. The goal was to avoid re-uploading the file and paying for the same input tokens every time by utilizing existing API caching mechanisms. Additionally, it was critical that the LLM processes both text and embedded images accurately from these large documents.</p>

<p>To test this, I analyzed a 39-page research paper (<a href="https://arxiv.org/abs/2310.01783">arXiv:2310.01783</a>) using both Gemini and OpenAI GPT-4. The results highlight fundamental differences in how these systems “see”, “remember”, and handle pricing for large documents.</p>

<p>Here are the key takeaways from the comparison.</p>

<h3 id="1-native-multi-modal-understanding-vs-textual-rag">1. Native Multi-Modal Understanding vs. Textual RAG</h3>

<p>Scientific papers are not just text; they are a synthesis of formulas, charts, and diagrams. When working with large volume PDFs, it is essential that the model effortlessly understands both text and images together.</p>

<p>OpenAI’s Assistants API handles PDFs primarily through File Search (a Retrieval-Augmented Generation, or RAG, approach). GPT-4o extracts the text and stores it in a vector database. To get the API to “see” a diagram, you have to manually crop it, convert it to an image, and send it via the Vision API. For large documents, this workaround is slow, expensive, and breaks context. <em>(Note: ChatGPT functions differently as an agentic system, but the API relies on this extraction method).</em></p>

<p><strong>Gemini’s Advantage:</strong> While the exact internal mechanics of how Gemini processes PDFs are not exhaustively documented, available documentation indicates it still parses the PDF into text and images within the pipeline, feeding both directly into its multimodal model. The true advantage is that this mechanism is built natively into Gemini and operates significantly faster than the manual, multi-step image cropping and separate database extraction required for the OpenAI GPT-4 API. This integrated, out-of-the-box multimodal approach makes Gemini exceptionally efficient and well-suited for processing large volume PDFs.</p>

<h3 id="2-visual-accuracy">2. Visual Accuracy</h3>

<p>To test visual reasoning, I asked both models to analyze Figure 3 in the document—a complex log-frequency ratio diagram.</p>

<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdr5Cdzh217dPnNJGNBw7MNG3XfYScxLKUeXwqqGHYx7c3_vzSsnJXxp06UOMO9yh8xBZ56WakPWSnKko4urEoXPRDj7WL_4VpUosbDPADbuyF4STdMcJ3P221m74JsHsqf7UXGr1s9s84y0QYpvXOykgUrbw?key=1miJacsJFi0g4LKmYfBfaA" alt="The diagram about which I asked the LLMs providing the PDF containing this diagram at the page 17" /></p>

<ul>
  <li><strong>Gemini</strong> correctly identified the specific color coding of the diagram (“The primary colors used are shades of blue, purple, and red (specifically a reddish-pink or salmon color)… Blue/Deep Purple is used for aspects more frequently mentioned by human reviewers… Red/Pink is used for aspects more frequently mentioned by GPT-4.”). This proves it is performing true visual reasoning on the document’s content.</li>
  <li><strong>OpenAI GPT-4o</strong>, despite having access to the file via its Assistant storage, provided a generic response about “shades of blue and red.” It guessed standard chart colors based on the parsed text, failing to actually “see” the diagram.</li>
</ul>

<h3 id="3-context-caching-vs-vector-stores">3. Context Caching vs. Vector Stores</h3>

<p>The way these models maintain “memory” and handle pricing for ongoing, separate sessions is fundamentally different.</p>

<ul>
  <li><strong>OpenAI (Assistants API):</strong> To maintain a session, you must upload files to a Vector Store, manage a Thread ID, and manually delete files later to avoid storage costs. It is a “search-and-retrieve” architecture. The model only sees snippets of text relevant to your question, often missing the broader context of the paper. When querying the full length of a document directly without Vector stores, you end up paying full price for the input tokens every single time.</li>
  <li><strong>Gemini (Context Caching):</strong> Gemini allows you to upload a file and create a Context Cache. This keeps the large document in “warm” memory. You can return a day later, in a completely separate session, ask a follow-up question, and the model immediately responds with the full context already loaded. Because of its specific pricing mechanisms, you pay significantly less for “cached tokens” compared to passing the document from scratch each time. There is no repetitive token billing for the full document, no “indexing” delay, and no “search” phase—it is a true, cost-effective persistent session.</li>
</ul>

<h3 id="4-workflow-integrity">4. Workflow Integrity</h3>

<p>To mimic Gemini’s native performance with OpenAI, you would have to convert all 39 pages into 39 high-resolution images and send them in a single session. This often exceeds token limits and is remarkably inefficient.</p>

<p>With Gemini, you simply attach the PDF. The model handles the text, the complex mathematical notations, and the logical flow of the paper’s imagery in one go.</p>

<p>While ChatGPT is excellent at processing extracted text, between the two tested models, <strong>Gemini was the only API model capable of natively performing a “visual” peer review.</strong> It understands not just what the researchers <em>wrote</em>, but what they <em>plotted</em>.</p>

<h3 id="5-other-vendors-claude-and-others">5. Other Vendors (Claude and others)</h3>

<p>It is worth noting that other options exist in the market, such as Anthropic’s Claude 3.5 models. According to their documentation, Claude also offers <a href="https://docs.anthropic.com/en/docs/build-with-claude/pdf-support">native PDF support featuring visual understanding</a> and <a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching">Prompt Caching</a> mechanisms which similarly reduce latency and token costs for large contexts across separate queries.</p>

<p><em>Please note: No direct testing was conducted on Claude for this specific workflow, and these capabilities are mentioned based purely on their official documentation.</em></p>

<hr />

<h3 id="the-proof-testing-the-models">The Proof: Testing the Models</h3>

<p>I asked both models to analyze a specific diagram from the paper to see how they handled visual data.</p>

<h4 id="test-1-gemini-native-pdf-upload">Test 1: Gemini (Native PDF Upload)</h4>

<blockquote>
  <p><strong>User:</strong> Please analyze the log frequency ratio diagram in this PDF.</p>

  <p><strong>Gemini:</strong> Based on page 17 of the document, Figure 3 is a horizontal dot plot titled “LLM based feedback emphasizes certain aspects more than humans.”</p>
  <ul>
    <li><strong>Y-axis:</strong> Lists 11 categorized aspects of scientific feedback…</li>
    <li><strong>X-axis:</strong> Labeled “log Frequency Ratio (GPT-4/Human)”, ranging from -1 to 1.</li>
    <li><strong>Position &amp; Color:</strong> Dots to the right (pink/red) are mentioned more frequently by GPT-4. Dots to the left (blue/purple) are mentioned more frequently by humans…</li>
    <li><strong>Key Findings:</strong> GPT-4 is over 10 times less likely to comment on novelty but over 7 times more likely to discuss research implications compared to human reviewers.</li>
  </ul>
</blockquote>

<blockquote>
  <p><strong>User:</strong> What are the primary colors used in the log frequency ratio diagram?</p>

  <p><strong>Gemini:</strong> The primary colors used are shades of blue, purple, and red (specifically a reddish-pink or salmon color)… Blue/Deep Purple is used for aspects more frequently mentioned by human reviewers… Red/Pink is used for aspects more frequently mentioned by GPT-4.</p>
</blockquote>

<p><em>Result: Flawless visual and contextual understanding.</em></p>

<h4 id="test-2-gpt-4o-api-pdf-uploaded-as-file">Test 2: GPT-4o API (PDF Uploaded as File)</h4>

<blockquote>
  <p><strong>User:</strong> Please analyze the log frequency ratio diagram in this PDF.</p>

  <p><strong>GPT-4o:</strong> The log frequency ratio diagram… compares how frequently GPT-4 comments on various aspects… The circle sizes denote the prevalence of each aspect in human feedback… <em>(Proceeds to summarize text accurately but misses visual layout).</em></p>
</blockquote>

<blockquote>
  <p><strong>User:</strong> What are the primary colors used in the log frequency ratio diagram?</p>

  <p><strong>GPT-4o:</strong> The primary colors used… are shades of blue and shades of red. Blue shades represent aspects where GPT-4 comments more frequently… while red shades indicate aspects where GPT-4 comments less frequently.</p>
</blockquote>

<p><em>Result: GPT-4o hallucinated the color mapping, guessing based on standard heat-map conventions and getting the assignments backward.</em></p>

<h4 id="test-3-gpt-4o-api-diagram-uploaded-manually-as-jpg">Test 3: GPT-4o API (Diagram Uploaded Manually as JPG)</h4>

<blockquote>
  <p><strong>User:</strong> What are the primary colors used in the log frequency ratio diagram?</p>

  <p><strong>GPT-4o:</strong> The primary colors used in the log frequency ratio diagram are purple and blue. There is also a small red dot indicating a data point.</p>
</blockquote>

<p><em>Result: Even when force-fed the image, GPT-4o struggled to accurately describe the distinct blue-to-pink/red gradient that Gemini easily identified.</em></p>]]></content><author><name>Rauf Aliev</name></author><category term="Retrieval-Augmented Generation (RAG)" /><category term="Multimodal Search (Text, Image, Audio)" /><category term="Algorithms &amp; Models" /><category term="Information Retrieval (IR)" /><summary type="html"><![CDATA[Gemini API offers significant architectural and functional advantages over GPT-4 API, particularly when handling complex, multi-page scientific documents]]></summary></entry><entry><title type="html">Automatic Facet Discovery in E-Commerce Search</title><link href="https://www.testmysearch.com/blog/2025/09/06/facet-discovery.html" rel="alternate" type="text/html" title="Automatic Facet Discovery in E-Commerce Search" /><published>2025-09-06T00:00:00-04:00</published><updated>2025-09-06T00:00:00-04:00</updated><id>https://www.testmysearch.com/blog/2025/09/06/facet-discovery</id><content type="html" xml:base="https://www.testmysearch.com/blog/2025/09/06/facet-discovery.html"><![CDATA[<p>This paper addresses a significant challenge in e-commerce information retrieval: the failure of standard keyword search systems to correctly interpret complex user queries that contain product attributes. Queries such as “blue XL Burton jacket” are often processed as a simple set of keywords, leading to irrelevant results and compelling users to engage in a laborious manual filtering process. We present a proof-of-concept (PoC) for an automatic facet discovery system designed to parse user queries, identify terms corresponding to product facets (e.g., color, brand, size), and apply these filters automatically. This research demonstrates a practical methodology for bridging the semantic gap between unstructured free-text search and structured faceted navigation, thereby enhancing result relevance and improving the overall user experience.</p>

<p>A video demonstration of the system, implemented on the Hybris accelerator platform, is provided below.</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
  <iframe src="https://player.vimeo.com/video/223100657" frameborder="0" allowfullscreen="" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
</div>

<h2 id="1-introduction">1. Introduction</h2>

<p>Faceted search is an integral feature of modern e-commerce platforms, fundamentally improving the user’s search and discovery experience. From a user-centric perspective, faceted navigation decomposes search results into multiple, orthogonal categories (facets), each with corresponding value counts. This paradigm enables users to iteratively refine, or “drill down,” into the result set by applying filters in any desired sequence.</p>

<p>The utility of this functionality is particularly evident when interacting with large-scale product catalogs, as it substantially improves product findability, mitigates user frustration, and provides a structured navigational framework. Furthermore, faceted search architectures programmatically generate relevant landing pages for long-tail keyword queries, a long-standing strategy in search engine optimization that was traditionally accomplished through static category pages.</p>

<h2 id="2-a-taxonomy-of-user-search-queries">2. A Taxonomy of User Search Queries</h2>

<p>Empirical research from the Baymard Institute classifies user search behavior into 12 distinct query types, the majority of which are inadequately supported by out-of-the-box e-commerce search engines.</p>

<ol>
  <li><strong>Exact Searches</strong>: Queries for specific products via title or model number (e.g., <em>Keurig K45</em>).</li>
  <li><strong>Product Type Searches</strong>: Broad queries for product categories (e.g., <em>Sandals</em>).</li>
  <li><strong>Symptom Searches</strong>: Problem-based queries where the user seeks a product as a solution (e.g., <em>“stained rug”</em>).</li>
  <li><strong>Non-Product Searches</strong>: Informational queries regarding policies, company details, or help documentation.</li>
  <li><strong>Feature Searches</strong>: Queries specifying particular product attributes (e.g., <em>Waterproof cameras</em>).</li>
  <li><strong>Thematic Searches</strong>: Queries for abstract or conceptual categories with ill-defined boundaries (e.g., <em>“Living room rug”</em>).</li>
  <li><strong>Relational Searches</strong>: Queries based on a product’s association with another entity (e.g., <em>Movies starring Tom Hanks</em>).</li>
  <li><strong>Compatibility Searches</strong>: Queries for products compatible with another item (e.g., <em>Lenses for Nikon D7000</em>).</li>
  <li><strong>Subjective Searches</strong>: Queries using non-objective, qualitative terms (e.g., <em>“High-quality kettles”</em>).</li>
  <li><strong>Slang, Abbreviation, and Symbol Searches</strong>: Queries employing linguistic shortcuts (e.g., <em>Sleeping bag -10 deg</em>).</li>
  <li><strong>Implicit Searches</strong>: Queries that omit context-dependent qualifiers (e.g., searching <em>Pants</em> when intending <em>Women’s Pants</em>).</li>
  <li><strong>Natural Language Searches</strong>: Queries formulated in complete sentences rather than keyword sets (e.g., <em>Women’s shoes that are red and available in size 7.5</em>).</li>
</ol>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/ecommerce-search-01-query-support-e26a0c0f33559b8702edfe2f626a3dba-1.png" alt="A chart from Baymard.com illustrating the poor support for various e-commerce search query types." /></p>

<p>While platforms such as Hybris provide foundational support for some of these query types, the implementation often lacks the necessary sophistication for accurate intent interpretation. Neither Hybris nor its underlying SOLR search engine can natively associate query terms with semantic concepts like product features or categories. By default, all input is treated as a simple keyword query. The proposed PoC serves as a semantic bridge between these free-text queries and the platform’s powerful faceted search capabilities, thereby addressing many of the aforementioned query types more effectively.</p>

<h2 id="3-the-challenge-with-conventional-faceted-search">3. The Challenge with Conventional Faceted Search</h2>

<p>Conventional faceted search implementations present known usability challenges. Although platforms like Hybris display facets relevant to an initial query, the presence of attribute-related terms within the query itself can paradoxically cause those same facets to be excluded from the results.</p>

<p>For instance, in the query “blue armada jacket XXL,” a standard search engine processes all four terms as a free-text request, returning only documents containing all four keywords. This approach is fundamentally flawed, as product attributes are often stored internally in structured formats or with distinct internal codes, necessitating duplicate index fields for their textual representations.</p>

<p>The primary issue is the significant divergence between search results and user expectations. A query for “blue armada jacket XXL” will retrieve products that simply contain these keywords in their title or description, a limitation that encourages merchants to engage in keyword stuffing to improve findability. This leads to a cumbersome, multi-step user journey to locate a specific product:</p>

<ol>
  <li><strong>Execute initial search</strong>: User enters the query “<em>blue female XL Burton jacket</em>.”</li>
  <li><strong>Apply Color facet</strong>: User locates and selects “blue” from the color facet list.</li>
  <li><strong>Apply Brand facet</strong>: User locates and selects “Burton” from the brand facet list.</li>
  <li><strong>Apply Size facet</strong>: User locates and selects “XL” from the size facet list.</li>
  <li><strong>Apply Gender facet</strong>: User locates and selects “Female” from the gender facet list.</li>
</ol>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/searchimproved10.png" alt="A typical e-commerce interface showing multiple facet categories on a sidebar." /></p>

<p>This iterative process requires multiple user interactions and page reloads. While some platforms like Google Shopping have implemented automatic facet application, this functionality is not standard in most e-commerce solutions.</p>

<p>A default SAP Commerce implementation, for example, yields highly irrelevant results for the query “blue female XL Burton jacket”:</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_21h36_23-1.png" alt="Screenshot of a default Hybris search result page showing irrelevant products." />
<em>How SAP Commerce Cloud works out-of-the-box (the default configuration).</em></p>

<ul>
  <li><strong>Observation</strong>: The results include items that are not jackets, not blue, not for women, and mostly not from the specified brand.</li>
</ul>

<p>In contrast, the proposed PoC delivers highly relevant results for the identical query:</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_21h39_15-1.png" alt="Screenshot of the PoC search result page showing highly relevant, correctly filtered products." />
<em>Performance of the proposed PoC for the query “Blue burton female XL jacket”.</em></p>

<ul>
  <li><strong>Observation</strong>: All resulting products are blue, female jackets from the Burton brand.</li>
</ul>

<p>This performance improvement is consistent across different product domains. For an electronics catalog, the query “fixed camera lenses from canon” on a standard system yields irrelevant products:</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_21h45_27-1.png" alt="Standard Hybris search results for an electronics query, showing incorrect product types." />
<em>Standard SAP Commerce search performance for the query “Fixed camera lens from Canon”.</em></p>

<p>The proposed system, however, correctly identifies and filters for the requested products:</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_21h47_181-1.png" alt="PoC results for the electronics query, showing correctly identified and filtered fixed camera lenses." />
<em>Performance of the proposed PoC for the query “Fixed camera lens from Canon”.</em></p>

<p>The system can also interpret numerical ranges. A query for “5 mp kodak camera” correctly applies a filter for the “5-5.9 Mp” facet range.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_21h54_03.png" alt="The PoC system correctly interpreting a numerical value and applying a corresponding range facet." />
<em>The PoC applying a facet range for the query “5 Mp Kodak camera”.</em></p>

<h2 id="4-implementation-strategy-automatic-vs-suggested-queries">4. Implementation Strategy: Automatic vs. Suggested Queries</h2>

<p>While the PoC implements fully automatic query interpretation, a production deployment would benefit from A/B testing to determine the optimal strategy for a specific business context. Factors such as catalog structure, product diversity, and user profiles should inform this decision.</p>

<p>An alternative, non-automatic approach involves presenting the interpreted query as a one-click suggestion alongside the standard keyword search results.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-26_02h13_24-1.png" alt="A conceptual mockup of a search suggestion panel." /></p>

<p>This method provides user control while still leveraging the benefits of query interpretation. If implemented, the suggestion interface should be designed to be both compact and informative.</p>

<h2 id="5-technical-architecture-and-implementation-details">5. Technical Architecture and Implementation Details</h2>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/searchimproved30.png" alt="A diagram illustrating the system architecture for automatic facet discovery." /></p>

<p>The system operates by analyzing the input query to extract terms that correspond to known facet values. A primary technical challenge is resolving ambiguity when a query contains conflicting or mutually exclusive facet terms. For example, the query “<em>Canon flash memory</em>” is ambiguous if the product catalog contains no flash memory manufactured by Canon. The system must then infer user intent: is the brand “Canon” or the category “Flash memory” the primary constraint?</p>

<p>This ambiguity is resolved when the catalog contains products that satisfy all specified attributes. For instance, if the catalog contains Sony-branded flash memory, the query “<em>Sony Flash Memory 32Gb</em>” is unambiguous, allowing the system to confidently apply facets for brand, category, and storage capacity.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_22h24_20-1.png" alt="The system correctly applying multiple facets for an unambiguous query." /></p>

<p>To facilitate this mapping, the system maintains an in-memory representation of all available facet values. These values are retrieved directly from the SOLR index using its built-in “terms” request handler, which provides an efficient method for obtaining a complete and uniform list of facet terms.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_22h33_17-1.png" alt="The SOLR terms component response, listing all values for a given facet field." /></p>

<p>For optimal performance, this technique requires SOLR fields configured with a <code class="language-plaintext highlighter-rouge">KeywordTokenizer</code> (to preserve multi-word facet values) and without stemming filters (to ensure exact matching). This can be achieved by creating dedicated, non-stemmed copy fields or by changing the field type to <code class="language-plaintext highlighter-rouge">string</code>, though the latter may have minor implications for full-text search relevance.</p>

<p>The PoC employs an efficient strategy by only processing facets that are returned by an initial standard keyword search, rather than analyzing all possible facets in the entire catalog.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/searchimproved2.png" alt="A diagram showing the two-step process: an initial search returns relevant facets, which are then processed." /></p>

<p>Once terms are mapped to facets, the remaining query words are categorized as stopwords, special commands (e.g., “cheap”), or residual keywords for the free-text search component.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/searchimproved3.png" alt="A diagram illustrating the mapping of query terms to facet values." /></p>

<p>The system then constructs a new, hybrid query combining the discovered facet filters with the remaining keywords.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/searchimproved4-1.png" alt="The final stage of query construction, combining facet filters with remaining keywords." /></p>

<p>To handle conflicts where a term matches multiple facets (e.g., “red” as a color vs. part of the brand “Red Hat”), the PoC implements a simple disambiguation logic: it executes a count for each interpretation and proceeds with the option that yields a non-zero result set. If both interpretations are valid, or if both yield zero results, the system defaults to a standard keyword search. More advanced implementations could prompt the user for clarification.</p>

<p>The system is designed to support dynamic facet configurations in SAP Commerce without requiring manual reconfiguration. However, it does not yet handle complex natural language constructs (e.g., “with,” “or,” “without”), which would require more advanced natural language processing techniques.</p>

<h2 id="6-conclusion-and-future-work">6. Conclusion and Future Work</h2>

<p>This paper has presented a proof-of-concept for an automatic facet discovery system designed to address a prevalent limitation in e-commerce search engines. By programmatically parsing unstructured user queries to identify and apply corresponding structured facet filters, the proposed system effectively bridges the semantic gap between keyword-based retrieval and faceted navigation. The experimental results demonstrate a significant improvement in result relevance and a more streamlined user experience compared to standard search implementations.</p>

<p>The current implementation, while promising, has several recognized limitations that provide clear directions for future research. The system’s reliance on exact-match string comparisons for facet mapping is inherently brittle and does not account for synonyms, morphological variations, or misspellings. Furthermore, the conflict resolution logic for ambiguous terms is heuristic-based and could be substantially improved. The PoC does not yet support complex linguistic constructs (e.g., conjunctions, prepositions) or handle redundant terminology within queries.</p>

<p>Future work will focus on integrating more sophisticated Natural Language Processing (NLP) techniques to overcome these challenges. The exploration of libraries such as OpenNLP is underway to incorporate capabilities like stemming, synonym expansion, and dependency parsing for a deeper understanding of query syntax and semantics. Further research will also involve developing a more robust disambiguation model, potentially leveraging machine learning trained on historical search logs to predict user intent more accurately. Finally, a quantitative evaluation through rigorous A/B testing and formal user studies is required to measure the system’s impact on key performance indicators, such as search success rate, session duration, and conversion.</p>

<p>Ultimately, the continued development of such intelligent query interpretation systems is a critical step toward creating more intuitive, efficient, and user-centric information retrieval experiences within the e-commerce domain.</p>]]></content><author><name>Rauf Aliev</name></author><category term="Relevance" /><category term="Indexing" /><category term="Query Processing" /><category term="Keyword Search" /><category term="Information Retrieval (IR)" /><category term="Query Understanding (NLU)" /><category term="Faceted Search" /><category term="Filtering" /><category term="Search UI/UX" /><summary type="html"><![CDATA[This paper addresses a significant challenge in e-commerce information retrieval: the failure of standard keyword search systems to correctly interpret complex user queries that contain product attributes. Queries such as “blue XL Burton jacket” are often processed as a simple set of keywords, leading to irrelevant results and compelling users to engage in a laborious manual filtering process. We present a proof-of-concept (PoC) for an automatic facet discovery system designed to parse user queries, identify terms corresponding to product facets (e.g., color, brand, size), and apply these filters automatically. This research demonstrates a practical methodology for bridging the semantic gap between unstructured free-text search and structured faceted navigation, thereby enhancing result relevance and improving the overall user experience.]]></summary></entry><entry><title type="html">A Comprehensive Survey of Recommendation Algorithms: From Collaborative Filtering to Large Language Models</title><link href="https://www.testmysearch.com/blog/2025/09/06/recommerder-algorithms-review.html" rel="alternate" type="text/html" title="A Comprehensive Survey of Recommendation Algorithms: From Collaborative Filtering to Large Language Models" /><published>2025-09-06T00:00:00-04:00</published><updated>2025-09-06T00:00:00-04:00</updated><id>https://www.testmysearch.com/blog/2025/09/06/recommerder-algorithms-review</id><content type="html" xml:base="https://www.testmysearch.com/blog/2025/09/06/recommerder-algorithms-review.html"><![CDATA[<p>This paper provides a systematic and exhaustive review of recommendation algorithms, charting their evolution from foundational collaborative filtering techniques to the sophisticated deep learning and generative models of the modern era. We organize the landscape into three primary categories based on the dominant data modality: Interaction-Driven, Text-Driven, and Multimodal algorithms. For each paradigm and its key algorithms, we distill the core concepts, highlight key differentiators, identify primary use cases, and offer practical guidance for implementation. Our analysis reveals a recurring tension between model complexity and performance, the transformative impact of self-supervised learning, and the paradigm-shifting potential of Large Language Models. This survey is intended as a cornerstone reference for engineers and researchers seeking to navigate the complex, dynamic, and powerful field of recommender systems.</p>

<p><strong>IMPORTANT: The structure and content of this blog post partially overlap with my book <a href="https://testmysearch.com/books/recommender-algorithms.html">Recommender Algorithms</a>, but it is far, far behind in terms of detail and depth of explanations. Many concepts are explained in the book more thoroughly and accessibly. I don’t rule out the possibility that some inaccuracies in the post below were corrected in the book—I simply didn’t have the energy to work on both the book and keeping this post up to date. On the book’s page, you can view the first 40 pages and form your own impression.</strong></p>

<h2 id="table-of-contents">Table of Contents</h2>
<ul>
  <li><a href="#Abstract">Abstract</a></li>
  <li><a href="#Introduction">Introduction</a></li>
  <li><a href="#InteractionDriven">Section 1: Interaction-Driven Recommendation Algorithms</a>
    <ul>
      <li><a href="#11ClassicNeighborhoodBasedModels">1.1 Classic &amp; Neighborhood-Based Models</a>
        <ul>
          <li><a href="#Userknn">UserKNN</a></li>
          <li><a href="#Itemknn">ItemKNN</a></li>
          <li><a href="#Slopeone">SlopeOne</a></li>
        </ul>
      </li>
      <li><a href="#12LatentFactorModelsMatrixFactorization">1.2 Latent Factor Models (Matrix Factorization)</a>
        <ul>
          <li><a href="#ClassicSolversSVDALS">Classic Solvers: SVD &amp; ALS</a></li>
          <li><a href="#PairwiseRankingObjectiveBprBayesianPersonalizedRanking">Pairwise Ranking Objective: BPR</a></li>
          <li><a href="#ItembasedLatentModelsSLIMFISM">Item-based Latent Models: SLIM &amp; FISM</a></li>
        </ul>
      </li>
      <li><a href="#13DeepLearningHybridsRepresentationLearning">1.3 Deep Learning Hybrids &amp; Representation Learning</a>
        <ul>
          <li><a href="#NeuralCollaborativeFiltering">Neural Collaborative Filtering (NCF)</a></li>
          <li><a href="#FactorizationMachinebasedDeepFMxDeepFM">Factorization Machine-based: DeepFM &amp; xDeepFM</a></li>
          <li><a href="#AutoencoderbasedDAEVAE">Autoencoder-based: DAE &amp; VAE</a></li>
        </ul>
      </li>
      <li><a href="#14SequentialSessionBasedModels">1.4 Sequential &amp; Session-Based Models</a>
        <ul>
          <li><a href="#RnnbasedGru4rec">RNN-based: GRU4Rec</a></li>
          <li><a href="#CnnbasedNextitnet">CNN-based: NextItNet</a></li>
          <li><a href="#AttentionTransformerbasedSASRecBERT4Rec">Attention/Transformer-based: SASRec &amp; BERT4Rec</a></li>
          <li><a href="#WithContrastiveLearningCl4srec">With Contrastive Learning: CL4SRec</a></li>
        </ul>
      </li>
      <li><a href="#15GraphbasedModelsGnns">1.5 Graph-Based Models (GNNs)</a>
        <ul>
          <li><a href="#StandardGNNsNGCFLightGCN">Standard GNNs: NGCF &amp; LightGCN</a></li>
          <li><a href="#SessionbasedGnnsSrgnn">Session-based GNNs: SR-GNN</a></li>
          <li><a href="#WithContrastiveLearningSGLSimGCL">With Contrastive Learning: SGL &amp; SimGCL</a></li>
        </ul>
      </li>
      <li><a href="#16DeepGenerativeModels">1.6 Deep Generative Models</a>
        <ul>
          <li><a href="#GenerativeAdversarialNetworks">Generative Adversarial Networks (GANs): IRGAN</a></li>
          <li><a href="#DiffusionForCfDiffrec">Diffusion for CF: DiffRec</a></li>
          <li><a href="#GflownetsGfn4rec">GFlowNets: GFN4Rec</a></li>
          <li><a href="#NormalizingFlowsIdnp">Normalizing Flows: IDNP</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#Section2TextdrivenRecommendationAlgorithms">Section 2: Text-Driven Recommendation Algorithms</a>
    <ul>
      <li><a href="#21ReviewbasedModels">2.1 Review-Based Models</a>
        <ul>
          <li><a href="#Deepconn">DeepCoNN</a></li>
          <li><a href="#NARRE">NARRE</a></li>
        </ul>
      </li>
      <li><a href="#22LargeLanguageModelLlmbasedParadigms">2.2 Large Language Model (LLM)-Based Paradigms</a>
        <ul>
          <li><a href="#RetrievalbasedDenseRetrievalCrossEncoders">Retrieval-based: Dense Retrieval &amp; Cross-Encoders</a></li>
          <li><a href="#GenerativeInstruction">Generative / Instruction-Tuned</a></li>
          <li><a href="#RAGFeatureExtraction">RAG &amp; Feature Extraction</a></li>
          <li><a href="#LLMAgentsToolUse">LLM Agents &amp; Tool Use</a></li>
        </ul>
      </li>
      <li><a href="#23ConversationalRecommenderSystems">2.3 Conversational Recommender Systems</a>
        <ul>
          <li><a href="#DialoguebasedPreferenceElicitation">Dialogue-based Preference Elicitation</a></li>
          <li><a href="#NaturalLanguageExplanationCritique">Natural Language Explanation &amp; Critique</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#Section3MultimodalRecommendationAlgorithms">Section 3: Multimodal Recommendation Algorithms</a>
    <ul>
      <li><a href="#31ContrastiveLearningForMultimodalAlignment">3.1 Contrastive Learning for Multimodal Alignment</a>
        <ul>
          <li><a href="#CLIP">CLIP</a></li>
          <li><a href="#ALBEF">ALBEF</a></li>
        </ul>
      </li>
      <li><a href="#32GenerativeMultimodalModels">3.2 Generative Multimodal Models</a>
        <ul>
          <li><a href="#MultimodalVaes">Multimodal VAEs</a></li>
          <li><a href="#MultimodalDiffusion">Multimodal Diffusion</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#Conclusion">Conclusion</a></li>
</ul>

<h2 id="abstract">Abstract</h2>

<p>This paper provides a systematic and exhaustive review of recommendation algorithms, charting their evolution from foundational collaborative filtering techniques to the sophisticated deep learning and generative models of the modern era. We organize the landscape into three primary categories based on the dominant data modality: Interaction-Driven, Text-Driven, and Multimodal algorithms. For each paradigm and its key algorithms, we distill the core concepts, highlight key differentiators, identify primary use cases, and offer practical guidance for implementation. Our analysis reveals a recurring tension between model complexity and performance, the transformative impact of self-supervised learning, and the paradigm-shifting potential of Large Language Models. This survey is intended as a cornerstone reference for engineers and researchers seeking to navigate the complex, dynamic, and powerful field of recommender systems.</p>

<h2 id="introduction">Introduction</h2>

<p>In the modern digital ecosystem, users are confronted with a virtually infinite selection of items, from products and movies to news articles and music. This phenomenon, often termed “information overload,” presents a significant challenge for both consumers and platforms. Recommender systems have emerged as a critical technology to address this challenge, serving as personalized information filters that guide users toward relevant content, thereby enhancing user experience, engagement, and commerce.</p>

<p>The field of recommendation algorithms has undergone a remarkable evolution. Early systems were built on simple statistical methods that leveraged direct user-item interactions. These foundational techniques, known as collaborative filtering, gave way to more sophisticated latent factor models, which sought to uncover the hidden dimensions of user preference by decomposing the user-item interaction matrix. The deep learning revolution subsequently ushered in a new era, with neural networks enabling the modeling of complex, non-linear relationships that were previously intractable.</p>

<p>This progression continued with the development of specialized architectures to capture the sequential dynamics of user behavior, borrowing heavily from advances in natural language processing. Concurrently, a new perspective emerged that modeled the recommendation problem as a graph, applying Graph Neural Networks to capture high-order relationships between users and items. Most recently, the landscape is being reshaped by the advent of large-scale generative models, including Generative Adversarial Networks, Diffusion Models, and, most notably, Large Language Models (LLMs), which are redefining the boundaries of what recommender systems can achieve.</p>

<p>This paper aims to provide a structured, high-level, and practical overview of this algorithmic landscape. We organize our survey into three principal sections based on the primary data modality each class of algorithms leverages:</p>

<ol>
  <li>
    <p><strong>Interaction-Driven Algorithms:</strong> Models that rely exclusively on user-item interaction data (e.g., ratings, clicks, purchases).</p>
  </li>
  <li>
    <p><strong>Text-Driven Algorithms:</strong> Models that incorporate unstructured text, such as user reviews or item descriptions, and are increasingly powered by LLMs.</p>
  </li>
  <li>
    <p><strong>Multimodal Algorithms:</strong> Models that fuse information from multiple sources, such as text, images, and video, to create a holistic understanding of items and preferences.</p>
  </li>
</ol>

<p>For each algorithm, we provide a concise explanation of its core concept, key differentiators, primary use cases, and practical considerations for implementation, along with a link to its seminal paper. Our objective is to equip engineers and researchers with a comprehensive map to navigate the field, understand its historical trajectory, and make informed decisions when designing and deploying the next generation of recommender systems.</p>

<p><img src="/img/recommendation_algorithms.png" alt="Structure" /></p>

<h2 id="section-1-interaction-driven-recommendation-algorithms">Section 1: Interaction-Driven Recommendation Algorithms</h2>

<p>These algorithms rely solely on user-item interaction data, such as ratings, clicks, or purchases, without incorporating additional content like text or images. They focus on patterns in how users engage with items to make predictions, forming the foundation of collaborative filtering.</p>

<p><a id="11ClassicNeighborhoodBasedModels"></a></p>
<h3 id="11-classic--neighborhood-based-models">1.1 Classic &amp; Neighborhood-Based Models</h3>

<p>These are foundational “memory-based” collaborative filtering approaches that recommend items based on similarities between users or items. They operate directly on the user-item interaction matrix, are simple, interpretable, and work well with sparse data but can struggle with scalability, coverage, and cold-start issues in very large or sparse datasets. They serve as powerful baselines for more complex models.</p>

<p><a id="Userknn"></a></p>
<h4 id="111-userknn-user-based-k-nearest-neighbors">1.1.1 UserKNN (User-based k-Nearest Neighbors)</h4>

<p>UserKNN (User-based K-Nearest Neighbors) finds users similar to the target user based on their interaction histories (using similarity measures like cosine or Pearson correlation on rating vectors) and recommends items that those similar users liked.</p>

<p><strong>Key concept:</strong> It assumes similar users have similar tastes, enabling predictions from “neighbors.”</p>

<p><strong>Key differentiator</strong>: Focuses on user similarities, making it intuitive for scenarios where user preferences are stable and interpretability is key (e.g., explaining recommendations via “Users who liked X also liked Y”).</p>

<p><strong>Use cases:</strong> E-commerce sites for personalized suggestions based on similar shoppers, or early recommender systems like GroupLens. Consider it when you have a moderate number of users, ample interaction data, and want quick, explainable recommendations without deep learning overhead.</p>

<ul>
  <li>
    <p><strong>Seminal Papers:</strong></p>

    <ul>
      <li>
        <p>GroupLens: an open architecture for collaborative filtering of netnews. Resnick, Paul and Iacovou, Neophytos and Suchak, Mitesh and Bergstrom, Peter and Riedl, John. 1994. https://dl.acm.org/doi/10.1145/192844.192905.</p>
      </li>
      <li>
        <p>On the challenges of studying bias in Recommender Systems: A UserKNN case study. Savvina Daniil, Manel Slokom, Mirjam Cuper, Cynthia C.S. Liem, Jacco van Ossenbruggen, Laura Hollink. https://arxiv.org/abs/2409.08046</p>
      </li>
    </ul>
  </li>
</ul>

<p><a id="Itemknn"></a></p>
<h4 id="112-itemknn-item-based-k-nearest-neighbors">1.1.2 ItemKNN (Item-based k-Nearest Neighbors)</h4>

<p>ItemKNN (Item-based K-Nearest Neighbors) recommends items similar to those the user has interacted with in the past, based on item similarity computed from user interactions (often using adjusted cosine similarity to account for user biases).</p>

<p><strong>Key concept:</strong> It builds item similarity matrices, assuming users tend to like items similar to ones they’ve liked before.</p>

<p><strong>Key Differentiator:</strong> More scalable than UserKNN for large item catalogs since item similarities change less frequently; offers transparency via “Because you watched X, you might like Y.”</p>

<p><strong>Use cases:</strong> Streaming services like Netflix for “similar to what you’ve watched,” or Amazon’s early item-based recommender for efficient, real-time suggestions. Consider it when your item set is stable, data is sparse, and you need efficient computation with reasonable accuracy and minimal training.</p>

<ul>
  <li>
    <p><strong>Seminal Papers:</strong></p>

    <ul>
      <li>
        <p>Item-based collaborative filtering recommendation algorithms, Sarwar, Badrul and Karypis, George and Konstan, Joseph and Riedl, John., 2001. https://dl.acm.org/doi/10.1145/371920.372071</p>
      </li>
      <li>
        <p>On the challenges of studying bias in Recommender Systems: A UserKNN case study. Savvina Daniil, Manel Slokom, Mirjam Cuper, Cynthia C.S. Liem, Jacco van Ossenbruggen, Laura Hollink. https://arxiv.org/abs/2409.08046</p>
      </li>
    </ul>
  </li>
</ul>

<p><a id="Slopeone"></a></p>
<h4 id="113-slopeone">1.1.3 SlopeOne</h4>

<p>SlopeOne is a simple, non-iterative algorithm that predicts ratings by computing average deviations (or “slopes”) between item pairs, assuming linear relationships like f(x) = x + b, where b is the pre-computed average rating deviation.</p>

<p><strong>Key concept:</strong> It models consistent offsets in ratings (e.g., if Item B is rated 0.5 higher than Item A on average, predict accordingly for a new user); new ratings can update averages incrementally.</p>

<p><strong>Differentiator:</strong> Extremely lightweight with no training phase (O(n²) preprocessing for n items), handles cold-start better than KNN, and supports dynamic updates with fast queries.</p>

<p><strong>Use cases:</strong> Quick prototyping, mobile apps, or online systems with limited resources where numerical ratings exist and simplicity/speed trump top accuracy. Consider it when preferences have consistent offsets, you need an incremental model, or engineering overhead must be minimal.</p>

<p><a id="PythonFrameworks"></a></p>
<h4 id="python-frameworks">Python Frameworks</h4>

<ul>
  <li>
    <p><strong>Surprise</strong> <a href="https://surpriselib.com/">https://surpriselib.com/</a>: Provides robust implementations for explicit data, including KNNBasic, KNNWithMeans, and KNNWithZScore, allowing for various baseline and normalization strategies.</p>
  </li>
  <li>
    <p><strong>scikit-learn</strong> <a href="https://scikit-learn.org/">https://scikit-learn.org/</a>: While not a dedicated recommender library, its NearestNeighbors module is a common choice for implementing the core similarity search component of a k-NN recommender.</p>
  </li>
</ul>

<p><a id="Productionready"></a></p>
<h4 id="production-ready">Production-ready?</h4>

<p>Item-based k-NN, in particular, is a proven, scalable, and effective algorithm that has been a cornerstone of production recommender systems for years. It is famously used by companies like Amazon for their “customers who bought this also bought” feature, demonstrating its real-world utility. While it remains a powerful tool, especially as a baseline or a component in a hybrid system, it can face challenges with data sparsity and, in the case of user-based variants, scalability issues as the number of users grows.</p>

<p>For the Slope One, it is different. The primary advantages of Slope One are its ease of implementation, low storage requirements, and extremely fast prediction time. These characteristics make it an excellent choice for systems with limited computational resources, as a strong and simple-to-debug baseline, or in online settings where the model needs to be updated frequently and dynamically as new ratings arrive.</p>

<p><a id="12LatentFactorModelsMatrixFactorization"></a></p>
<h3 id="12-latent-factor-models-matrix-factorization">1.2 Latent Factor Models (Matrix Factorization)</h3>

<p>These “model-based” methods address data sparsity by decomposing the user-item interaction matrix into lower-dimensional latent factor matrices for users and items. The core idea is to represent users and items in a shared latent space where their proximity reflects preference. This condenses complex interaction patterns into a small number of hidden features, moving beyond direct neighbor comparisons to uncover the underlying reasons for preferences.</p>

<!-- Note: I use blockquotes (>) to create asides for explanatory text like "Simply put..." to provide additional context for readers who need clarification. -->

<blockquote>
  <p><strong>Simply put…</strong><br />
It’s like creating a “taste profile” for both users and items using the same set of hidden characteristics.</p>

  <p>Imagine you’re recommending movies. Instead of just knowing which movies a person likes, the model tries to figure out why. It creates a handful of underlying characteristics, like “amount of sci-fi,” “level of comedy,” or “degree of romance.”</p>

  <p>Each movie gets a score for each of these characteristics. For example, a rom-com would score high on “comedy” and “romance” but low on “sci-fi.”
Each user gets a matching profile based on the movies they’ve enjoyed. Someone who loves rom-coms would get high scores for “comedy” and “romance” preferences.
To make a recommendation, the system just finds movies whose characteristic scores are a great match for the user’s preference scores. This way, it can recommend a new movie the user has never seen, as long as its “taste profile” fits theirs.</p>
</blockquote>

<p><a id="ClassicSolversSVDALS"></a></p>
<h4 id="121-classic-solvers-svd--als">1.2.1 Classic Solvers: SVD &amp; ALS</h4>

<p><strong>Key concept:</strong> These techniques represent each user and item as a vector of latent factors, which capture underlying characteristics (e.g., for movies, a factor might represent the “action vs. drama” dimension). The predicted rating is then calculated as the dot product of their respective latent vectors.</p>

<p>For example, a user who scores high on the “prefers action” factor will have a high predicted rating for a movie that scores high on the “is an action movie” factor. The model learns these factor vectors by minimizing the prediction error on known ratings.</p>

<p><strong>Key differentiator:</strong> The main difference lies in the optimization method.</p>

<ul>
  <li><strong>SVD (Singular Value Decomposition)</strong>, in the context of recommendation, typically refers to models trained with <strong>Stochastic Gradient Descent (SGD)</strong>. This method iteratively adjusts the factors to minimize prediction error. It’s flexible but can be slow on very large datasets.</li>
  <li><strong>ALS (Alternating Least Squares)</strong> works by fixing one set of factors (e.g., all user vectors) and solving a standard least-squares problem for the other set (all item vectors), and then alternating. This process is highly parallelizable, making ALS more scalable in distributed environments like Spark. It is also particularly effective for implicit feedback data, where interactions are treated as positive signals with varying confidence levels.</li>
</ul>

<p><strong>Use cases:</strong> These models are workhorses for personalized recommendation, primarily for predicting explicit ratings (e.g., 1-5 stars) in domains like e-commerce (such as Amazon) and media streaming (such as Netflix). ALS is dominant in industrial settings with very large, sparse datasets that require distributed training.</p>

<p><strong>When to Consider:</strong> Matrix factorization is a powerful step up from neighborhood models, especially for sparse data. Use an SVD-like model (trained with SGD) when you need a flexible model and are comfortable with iterative training. Opt for <strong>ALS</strong> when dealing with large-scale, sparse datasets, especially if you have access to a distributed computing framework. ALS is particularly effective for implicit feedback scenarios when using a weighted formulation (WR-ALS).</p>

<blockquote>
  <p><strong>Matrix factorization</strong> is a technique to break down a large user-item interaction matrix (like ratings or clicks) into two smaller matrices that represent users and items in a shared “taste” space. By finding hidden patterns in the data, it assigns scores to users and items based on latent features (e.g., “love for sci-fi” or “preference for comedy”). These scores help predict how much a user will like an item they haven’t interacted with, making recommendations more accurate.</p>
</blockquote>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>SVD (in RecSys context):</strong> Koren, Y., Bell, R., &amp; Volinsky, C. (2009). <em>Matrix factorization techniques for recommender systems</em>. <a href="https://www.researchgate.net/publication/220381329_Matrix_factorization_techniques_for_recommender_systems">https://www.researchgate.net/publication/220381329_Matrix_factorization_techniques_for_recommender_systems</a>.</li>
      <li><strong>ALS:</strong> Zhou, Y., Wilkinson, D., Schreiber, R., &amp; Pan, R. (2008). <em>Large-scale Parallel Collaborative Filtering for the Netflix Prize</em>. <a href="https://www.researchgate.net/publication/221566136_Large-scale_Parallel_Collaborative_Filtering_for_the_Netflix_Prize">https://www.researchgate.net/publication/221566136_Large-scale_Parallel_Collaborative_Filtering_for_the_Netflix_Prize</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="PairwiseRankingObjectiveBprBayesianPersonalizedRanking"></a></p>
<h4 id="122-pairwise-ranking-objective-bpr-bayesian-personalized-ranking">1.2.2 Pairwise Ranking Objective: BPR (Bayesian Personalized Ranking)</h4>

<p><strong>Key concept:</strong> BPR reframes the recommendation problem from predicting a score (rating prediction) to predicting a preference order (ranking). It operates on a pairwise assumption: for a given user, an item they have interacted with (a positive item) should be ranked higher than an item they have not interacted with (a negative item). The model is trained to maximize this probability for pairs of items.</p>

<p><strong>Key differentiator:</strong> This represents a crucial maturation of the field. Early models focused on optimizing metrics like RMSE, which measures the accuracy of predicting a specific rating value (e.g., 3.7 stars vs. 3.8). However, the practical value of a recommender lies in its ability to place the most relevant items at the top of a list. BPR was a landmark development because it aligned the model’s optimization objective directly with this business goal of creating a high-quality ranked list, making it ideal for implicit feedback data (clicks, purchases) where there are no negative examples, only unobserved ones.</p>

<p><strong>Use cases:</strong> BPR is the standard for modeling implicit feedback data where the goal is to produce a ranked list of recommendations (Top-N recommendation). It is widely used in e-commerce, media streaming, and any domain where explicit ratings are unavailable or sparse but interaction data is plentiful.</p>

<p><strong>When to Consider:</strong> An engineer should choose BPR whenever the primary goal is to generate a ranked list of items rather than predict ratings. By learning to correctly order pairs of items, it directly improves the quality of the ranked list, a far more meaningful outcome for the end-user. This makes BPR or other ranking-based loss functions the default choice for any Top-N recommendation task based on implicit feedback.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Rendle, S., Freudenthaler, C., Gantner, Z., &amp; Schmidt-Thieme, L. (2009). <em>BPR: Bayesian personalized ranking from implicit feedback</em>. <a href="https://arxiv.org/abs/1205.2618">https://arxiv.org/abs/1205.2618</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="ItembasedLatentModelsSLIMFISM"></a></p>
<h4 id="123-item-based-latent-models-slim--fism">1.2.3 Item-based Latent Models: SLIM &amp; FISM</h4>

<p><strong>Key concept:</strong> These models combine the interpretability of item-based methods with the power of latent factor models. Instead of relying on simple co-occurrence statistics, they learn an item-item similarity matrix directly from the interaction data using a machine learning model.</p>

<p><strong>Key differentiator:</strong></p>
<ul>
  <li><strong>SLIM (Sparse Linear Methods)</strong> learns a sparse item-item similarity matrix ($W$) by solving a regression problem. A user’s score for an item is a weighted sum of their interactions with other similar items. The sparsity (enforced by L1 regularization) makes the model efficient and interpretable—each item’s score is influenced by only a few other items.</li>
  <li><strong>FISM (Factored Item Similarity Models)</strong> takes a hybrid approach. Instead of learning the full item-item similarity matrix directly, it <em>factorizes</em> it into two lower-dimensional item embedding matrices. This allows it to learn transitive relationships (e.g., if item A is similar to B, and B is similar to C, then A and C might be similar) even if A and C were never co-rated, making it more powerful on extremely sparse datasets.</li>
</ul>

<p><strong>Use cases:</strong> Both models are designed for Top-N recommendation from implicit feedback. SLIM is highly effective and efficient, making it a strong baseline and suitable for production systems where speed and interpretability are critical. FISM is particularly advantageous in scenarios with very high data sparsity, where learning latent relationships is crucial.</p>

<p><strong>When to Consider:</strong> Choose <strong>SLIM</strong> when you need a fast, scalable, and interpretable item-based model that often outperforms more complex methods. It’s an excellent choice when you want a “learned” item-item similarity model. Consider <strong>FISM</strong> when facing extreme data sparsity. Its ability to generalize and find similarities between items that do not co-occur in the training data gives it a distinct advantage in such challenging scenarios.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>SLIM:</strong> Ning, X., &amp; Karypis, G. (2011). <em>SLIM: sparse linear methods for top-n recommender systems</em>. <a href="https://www.researchgate.net/publication/220765374_SLIM_Sparse_Linear_Methods_for_Top-N_Recommender_Systems">https://www.researchgate.net/publication/220765374_SLIM_Sparse_Linear_Methods_for_Top-N_Recommender_Systems</a>.</li>
      <li><strong>FISM:</strong> Kabbur, S., Badrul, S., &amp; Karypis, G. (2013). <em>FISM: factored item similarity models for top-n recommender systems</em>. <a href="http://chbrown.github.io/kdd-2013-usb/kdd/p659.pdf">http://chbrown.github.io/kdd-2013-usb/kdd/p659.pdf</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="PythonFrameworks"></a></p>
<h4 id="python-frameworks-1">Python Frameworks</h4>

<ul>
  <li>
    <p><strong>Surprise</strong> <a href="https://surpriselib.com/">https://surpriselib.com/</a>: Offers popular and well-documented implementations of SVD, Probabilistic Matrix Factorization (PMF), and SVD++, an extension that incorporates implicit feedback.</p>
  </li>
  <li>
    <p><strong>implicit</strong> <a href="https://github.com/benfred/implicit">https://github.com/benfred/implicit</a>: This library’s primary focus is on high-performance matrix factorization for implicit data, providing highly optimized implementations of ALS and BPR</p>
  </li>
  <li>
    <p><strong>Cornac</strong> <a href="https://github.com/preferredAI/cornac-ab">https://github.com/preferredAI/cornac-ab</a> Includes implementations of PMF and other MF variants as part of its comparative framework</p>
  </li>
  <li>
    <p><strong>RecTools</strong> <a href="https://github.com/MobileTeleSystems/RecTools">https://github.com/MobileTeleSystems/RecTools</a> Provides wrappers and its own implementations of matrix factorization models</p>
  </li>
  <li>
    <p><strong>RecBole</strong> <a href="https://github.com/RUCAIBox/RecBole">https://github.com/RUCAIBox/RecBole</a> Provides an implementation of SLIM under the name SLIMElastic, which incorporates the elastic net regularization used in the original paper</p>
  </li>
</ul>

<p><a id="Productionready"></a></p>
<h4 id="production-ready-1">Production-ready?</h4>

<p>Matrix factorization is one of the most influential and widely deployed techniques in the history of recommender systems. Its ability to generalize from sparse data by learning latent representations made it a breakthrough technology, famously popularized by its success in the Netflix Prize competition. It remains a core component of many large-scale production systems and serves as the conceptual foundation for many advanced deep learning architectures, such as Neural Collaborative Filtering.</p>

<p>SLIM and its variants have demonstrated very strong performance in academic studies for the top-N recommendation task, often outperforming more complex methods. However, they are less commonly seen as standalone models in production systems compared to matrix factorization or k-NN. Their principles have influenced subsequent research, and they serve as powerful baselines for evaluating new item-based recommendation algorithms.</p>

<p><a id="13DeepLearningHybridsRepresentationLearning"></a></p>
<h3 id="13-deep-learning-hybrids--representation-learning">1.3 Deep Learning Hybrids &amp; Representation Learning</h3>

<p>This category marks the transition from linear latent factor models to more expressive, non-linear models powered by neural networks. By replacing the simple dot product with deep learning architectures, these models can capture more complex and subtle user-item interaction patterns that traditional methods might miss.</p>

<blockquote>
  <p><strong>What are non-linear relationships?</strong></p>

  <p>Think of it like this: a linear model assumes that if you like action movies twice as much, you’ll get twice the enjoyment from an action scene. A <strong>non-linear model</strong> understands that the relationship is more complex. Maybe you love action movies, but after two hours, your enjoyment plateaus or even drops. Neural networks are excellent at learning these kinds of nuanced, “it depends” relationships from the data automatically.</p>
</blockquote>

<p><a id="NeuralCollaborativeFiltering"></a></p>
<h4 id="131-neural-collaborative-filtering-ncf">1.3.1 Neural Collaborative Filtering (NCF)</h4>

<p><strong>Key concept:</strong> NCF is a framework that generalizes Matrix Factorization (MF) by replacing its dot product with a neural network. Instead of just multiplying user and item latent vectors, NCF concatenates them and feeds them through a Multi-Layer Perceptron (MLP). This allows the model to learn an arbitrary, complex interaction function between users and items.</p>

<p><strong>Key differentiator:</strong> Its primary advantage is the ability to capture <strong>complex, non-linear patterns</strong> in the data. While standard MF is restricted to a linear combination of factors, NCF can model synergistic effects—for example, it can learn that a user’s preference for the “sci-fi” genre and the “Christopher Nolan” director <em>together</em> creates a much stronger signal than the sum of the individual preferences.</p>

<p><strong>Use cases:</strong> NCF is a general-purpose model for collaborative filtering from implicit feedback. It is used for Top-N recommendation in various domains where user-item interactions might have complex patterns that matrix factorization cannot capture.</p>

<p><strong>When to Consider:</strong> Consider using NCF when you suspect that the underlying user-item interactions are too complex to be modeled by a simple dot product. If standard matrix factorization models are hitting a performance plateau, NCF is a logical next step to introduce non-linearity and increase model expressiveness, provided you have enough data to train a deeper model without overfitting.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>He, X., Liao, L., Zhang, H., Nie, L., Hu, X., &amp; Chua, T. S. (2017). <em>Neural Collaborative Filtering</em>. <a href="https://arxiv.org/abs/1708.05031">https://arxiv.org/abs/1708.05031</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="FactorizationMachinebasedDeepFMxDeepFM"></a></p>
<h4 id="132-factorization-machine-based-deepfm--xdeepfm">1.3.2 Factorization Machine-based: DeepFM &amp; xDeepFM</h4>

<p><strong>Key concept:</strong> These models are advanced hybrid architectures designed primarily for Click-Through Rate (CTR) prediction. They  combine a “wide” component for learning simple, memorable feature interactions and a “deep” component for learning complex, generalizable patterns. Both components share the same input embeddings, making training highly efficient.</p>

<blockquote>
  <p><strong>What is Click-Through Rate (CTR) Prediction?</strong></p>

  <p><strong>CTR prediction</strong> is the task of estimating the probability that a user will click on an item (like an ad, a product, or a news article) if it is shown to them. It’s a critical task in online advertising and recommendation, as it directly relates to engagement and revenue. Models that are good at CTR prediction excel at understanding what makes a user click in a specific context.</p>
</blockquote>

<p><strong>Key differentiator:</strong></p>
<ul>
  <li><strong>DeepFM</strong> combines a <strong>Factorization Machine (FM)</strong> for the “wide” part and a standard MLP for the “deep” part. The FM component is highly effective at learning 2nd-order feature interactions (e.g., how the combination of “user is a teenager” and “item is a video game” affects clicks) without manual effort.</li>
  <li><strong>xDeepFM (eXtreme DeepFM)</strong> improves upon this by replacing the standard MLP with a <strong>Compressed Interaction Network (CIN)</strong>. The CIN is specifically designed to explicitly learn high-order feature interactions in a more controlled, vector-wise manner, which can be more powerful and interpretable than the implicit interactions learned by an MLP.</li>
</ul>

<p><strong>Use cases:</strong> Both models are state-of-the-art for CTR prediction in large-scale industrial recommender systems, such as those used in online advertising, e-commerce, and news feeds. They are designed to handle high-dimensional, sparse, and multi-field categorical features (e.g., user demographics, item category, time of day).</p>

<p><strong>When to Consider:</strong> You may consider these models for any feature-rich recommendation task, especially CTR prediction. <strong>DeepFM</strong> is a powerful and widely used baseline. However, if you believe that explicit, high-order feature combinations are particularly important in your domain (e.g., “young user” + “sports category” + “weekend”), <strong>xDeepFM</strong>’s CIN component offers a more targeted mechanism for learning them.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>DeepFM:</strong> Guo, H., Tang, R., Ye, Y., Li, Z., &amp; He, X. (2017). <em>DeepFM: A Factorization-Machine based Neural Network for CTR Prediction</em>. <a href="https://arxiv.org/abs/1703.04247">https://arxiv.org/abs/1703.04247</a>.</li>
      <li><strong>xDeepFM:</strong> Lian, J., Zhou, X., Zhang, F., Chen, Z., Xie, X., &amp; Sun, G. (2018). <em>xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems</em>. <a href="https://arxiv.org/abs/1803.05170">https://arxiv.org/abs/1803.05170</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="AutoencoderbasedDAEVAE"></a></p>
<h4 id="133-autoencoder-based-dae--vae">1.3.3 Autoencoder-based: DAE &amp; VAE</h4>

<p><strong>Key concept:</strong> This approach frames collaborative filtering as a reconstruction task. It takes a user’s entire interaction history (e.g., a sparse vector of all items they’ve clicked on) as input and trains a neural network—the autoencoder—to compress this information into a dense low-dimensional latent vector and then reconstruct the original interaction vector from it.</p>

<blockquote>
  <p><strong>What is an Autoencoder?</strong></p>

  <p>An <strong>autoencoder</strong> is a type of neural network trained to learn a compressed representation of its input data. It has two main parts: an <strong>encoder</strong> that maps the input to a low-dimensional “bottleneck” representation, and a <strong>decoder</strong> that tries to reconstruct the original input from this compressed version. By forcing data through this bottleneck, the network learns the most important and salient features.</p>
</blockquote>

<p><strong>Key differentiator:</strong></p>
<ul>
  <li><strong>DAE (Denoising Autoencoder)</strong> for CF learns robust representations by being trained to reconstruct the <em>original, complete</em> user history from a <em>partially corrupted</em> input (e.g., some of the user’s clicks are randomly set to zero). This forces the model to learn the underlying relationships between items to “fill in the blanks.”</li>
  <li><strong>VAE (Variational Autoencoder)</strong> for CF is a <strong>probabilistic, generative</strong> model. Instead of mapping a user to a single latent vector, it maps them to a full probability distribution. This allows it to better capture the uncertainty and multi-modal nature of user preferences (e.g., a user’s taste might be “80% comedy fan, 20% drama fan”).</li>
</ul>

<p><strong>Use cases:</strong> These models are highly effective for Top-N recommendation from implicit feedback. VAE-CF, in particular, has become a very strong and widely used baseline for collaborative filtering, often achieving state-of-the-art results on benchmark datasets.</p>

<p><strong>When to Consider:</strong> Consider using an autoencoder-based model when linear latent factor models are insufficient. <strong>DAE</strong>s are a good choice for learning robust representations from noisy interaction data. <strong>VAE</strong>s are an even stronger choice for implicit feedback Top-N tasks, as their probabilistic nature and multinomial likelihood objective are exceptionally well-suited for the ranking problem. They are a go-to model for researchers and practitioners aiming for top performance in collaborative filtering.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>DAE (for RecSys):</strong> Wu, Y., DuBois, C., Zheng, A. X., &amp; Ester, M. (2016). <em>Collaborative Denoising Auto-Encoders for Top-N Recommender Systems</em>. <a href="https://dl.acm.org/doi/10.1145/2835776.2835837">https://dl.acm.org/doi/10.1145/2835776.2835837</a>.</li>
      <li><strong>VAE (for RecSys):</strong> Liang, D., Krishnan, R. G., Hoffman, M. D., &amp; Jebara, T. (2018). <em>Variational Autoencoders for Collaborative Filtering</em>. <a href="https://arxiv.org/abs/1802.05814">https://arxiv.org/abs/1802.05814</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="PythonFrameworks"></a></p>
<h4 id="python-frameworks-2">Python Frameworks</h4>

<ul>
  <li>
    <p><strong>Tensorflow</strong> <a href="https://github.com/tensorflow/tensorflow">https://github.com/tensorflow/tensorflow</a> The TensorFlow Model Garden includes an official implementation and tutorial for building an NCF model</p>
  </li>
  <li><strong>Microsoft Recommenders</strong> <a href="https://github.com/recommenders-team/recommenders">https://github.com/recommenders-team/recommenders</a>: Provides a detailed Jupyter notebook implementation of NCF, explaining both the theory and practical application. Also includes an example notebook for xDeepFM.</li>
  <li><strong>Cornac</strong> <a href="https://github.com/PreferredAI/cornac">https://github.com/PreferredAI/cornac</a> Features an implementation of BiVAECF (Bilateral Variational Autoencoder for Collaborative Filtering)</li>
  <li><strong>RecBole</strong> <a href="https://recbole.io/docs/user_guide/model/context/deepfm.html">https://recbole.io/docs/user_guide/model/context/deepfm.html</a> Provides implementations of both DeepFM and xDeepFM</li>
  <li><strong>LibRecommender</strong> <a href="https://github.com/massquantity/LibRecommender">https://github.com/massquantity/LibRecommender</a> Offers a TensorFlow-based implementation of DeepFM with extensive configuration options</li>
</ul>

<p><a id="Productionready"></a></p>
<h4 id="production-ready-2">Production-ready?</h4>

<p>NCF is a seminal deep learning model for recommendation that has had a significant impact on the field. It is widely used in industry, both as a powerful standalone model and as a strong baseline for evaluating more advanced architectures. Its core architectural principles have influenced the design of many subsequent models.</p>

<p>VAE-based models for collaborative filtering, particularly the Mult-VAE variant which uses a multinomial likelihood objective, have proven to be highly effective and often achieve state-of-the-art results on academic benchmarks. They are used in production systems, but also remain a very active area of research, with new extensions being developed for multimodal data , interactive critiquing , and multi-criteria recommendation.</p>

<p>DeepFM and xDeepFM are considered state-of-the-art models for tabular CTR prediction and are widely deployed in production systems for applications like computational advertising, feed ranking, and product recommendation.</p>

<p><a id="14SequentialSessionBasedModels"></a></p>
<h3 id="14-sequential--session-based-models">1.4 Sequential &amp; Session-Based Models</h3>

<p>This paradigm marks a fundamental shift from treating user interactions as an unordered set to modeling them as an ordered sequence. The goal is to predict the user’s <em>next</em> action based on the temporal dynamics of their recent behavior. This shift reflects a powerful conceptual convergence with the field of Natural Language Processing (NLP), where a sequence of user interactions is treated analogously to a sequence of words in a sentence.</p>

<blockquote>
  <p><strong>Why does order matter?</strong></p>

  <p>Imagine a shopping session. A user who clicks on “iPhone -&gt; iPhone Case -&gt; Screen Protector” has a very clear and different intent from a user who clicks on “iPhone -&gt; Laptop -&gt; Headphones.” The first user is accessorizing a specific product, while the second is browsing different categories. Sequential models are designed to understand these ordered patterns to make much more contextually relevant “what’s next” predictions.</p>
</blockquote>

<p><a id="RnnbasedGru4rec"></a></p>
<h4 id="141-rnn-based-gru4rec">1.4.1 RNN-based: GRU4Rec</h4>

<p><strong>Key concept:</strong> GRU4Rec was a pioneering model that applied Recurrent Neural Networks (RNNs) to session-based recommendation. It processes a sequence of user interactions one by one, maintaining a “memory” or hidden state that evolves with each new item. This state captures the user’s current intent, which is then used to predict the very next item they are likely to interact with.</p>

<blockquote>
  <p><strong>What is an RNN?</strong></p>

  <p>A <strong>Recurrent Neural Network (RNN)</strong> is a type of neural network designed for sequential data. Think of it as having a short-term memory. As it reads a sequence (like words in a sentence or items in a session), it passes information from one step to the next. This allows it to understand context and order, making it perfect for predicting what comes next based on what happened before. The <strong>GRU (Gated Recurrent Unit)</strong> is an advanced and efficient type of RNN.</p>
</blockquote>

<p><strong>Key differentiator:</strong> Its core innovation was using RNNs to handle variable-length, anonymous user sessions. Unlike static models, GRU4Rec captures the evolving nature of user intent within a single session. It also introduced ranking-aware loss functions to directly optimize for the quality of the recommended list, not just prediction accuracy.</p>

<p><strong>Use cases:</strong> GRU4Rec is designed for session-based recommendation, where user identity may be unknown or irrelevant (e.g., guest shoppers). It is common in e-commerce for predicting the next product click, in media streaming for the next song or video, and in news for the next article.</p>

<p><strong>When to Consider:</strong> GRU4Rec is a strong baseline for any sequential or session-based task where short-term context and the order of interactions are critical. It’s particularly useful when a user’s intent evolves throughout a session and you need to make real-time, next-step predictions.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Hidasi, B., Karatzoglou, A., Baltrunas, L., &amp; Tikk, D. (2016). <em>Session-based Recommendations with Recurrent Neural Networks</em>. <a href="https://arxiv.org/abs/1511.06939">https://arxiv.org/abs/1511.06939</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="CnnbasedNextitnet"></a></p>
<h4 id="142-cnn-based-nextitnet">1.4.2 CNN-based: NextItNet</h4>

<p><strong>Key concept:</strong> NextItNet applies Convolutional Neural Networks (CNNs), traditionally used for image processing, to model sequences of user interactions. It treats an embedded sequence of items as a 1D “image” and uses stacked layers of <em>dilated convolutions</em> to efficiently identify patterns and long-range dependencies.</p>

<blockquote>
  <p><strong>How can a CNN work on a sequence?</strong></p>

  <p>Imagine the sequence of items is laid out like a single row of pixels. A <strong>CNN</strong> applies “filters” that slide across this row to recognize local patterns (e.g., “item A is often followed by item B”). By using <strong>dilated convolutions</strong>, which skip inputs at varying rates, the network can create a very large receptive field, allowing it to see how an item at the beginning of a long session influences an item at the end, all without the step-by-step processing of an RNN.</p>
</blockquote>

<p><strong>Key differentiator:</strong> The main advantage of NextItNet over RNNs is <strong>efficiency and parallelism</strong>. CNNs can process all parts of a sequence simultaneously, making training much faster. Its use of dilated convolutions and residual blocks allows it to build very deep networks that can capture dependencies across extremely long sequences (hundreds of items) where RNNs might struggle with vanishing gradients.</p>

<p><strong>Use cases:</strong> NextItNet is used for session-based and sequential Top-N item recommendation. It is particularly well-suited for scenarios with very long user interaction sequences and where training efficiency on large datasets is a major concern.</p>

<p><strong>When to Consider:</strong> Consider NextItNet when training speed is a priority or when dealing with very long sequences where capturing long-range dependencies is crucial. It represents a powerful and scalable architectural alternative to RNNs for modeling sequential data.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Yuan, F., Karatzoglou, A., Arapakis, I., Jose, J. M., &amp; He, X. (2019). <em>A Simple Convolutional Generative Network for Next Item Recommendation</em>. <a href="https://dl.acm.org/doi/10.1145/3289600.3290975">https://dl.acm.org/doi/10.1145/3289600.3290975</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="AttentionTransformerbasedSASRecBERT4Rec"></a></p>
<h4 id="143-attentiontransformer-based-sasrec--bert4rec">1.4.3 Attention/Transformer-based: SASRec &amp; BERT4Rec</h4>

<p><strong>Key concept:</strong> This family of models leverages the <strong>self-attention mechanism</strong>, the core component of the Transformer architecture that has revolutionized NLP. Self-attention allows the model to dynamically weigh the importance of <em>all</em> other items in a sequence when making a prediction for the next item, overcoming the sequential processing bottleneck of RNNs and the fixed receptive field of CNNs.</p>

<blockquote>
  <p><strong>What is Self-Attention?</strong></p>

  <p><strong>Self-attention</strong> is a mechanism that allows a model to look at other items in the input sequence and decide which ones are most important for understanding the current item. For recommendation, this means that to predict your next action, the model can pay more attention to the very first item you clicked on, or a specific item you lingered on, regardless of its position in the sequence. It learns to identify the most influential past actions on the fly.</p>
</blockquote>

<p><strong>Key differentiator:</strong> The key innovation is the use of self-attention, providing a global view of the sequence. The distinction between the two main models is crucial:</p>
<ul>
  <li><strong>SASRec (Self-Attentive Sequential Recommendation)</strong> is <strong>unidirectional</strong> (autoregressive). It only considers past items to predict the future, strictly respecting the temporal flow of user actions. It excels at identifying which of the previous items are most relevant for the <em>next</em> choice.</li>
  <li><strong>BERT4Rec (Bidirectional Encoder Representations from Transformers for Recommendation)</strong> is <strong>bidirectional</strong>. Inspired by BERT in NLP, it is trained using a “cloze task” where it predicts a randomly masked item in the sequence using both its left and right context (items that came before and after). This allows it to learn a richer, more holistic representation of user interests.</li>
</ul>

<p><strong>Use cases:</strong> These models represent the state-of-the-art for sequential recommendation tasks. <strong>SASRec</strong> is a powerful general-purpose model for next-item prediction. <strong>BERT4Rec</strong> is particularly effective when a user’s overall interest is a reflection of their entire history, not just a linear progression. <strong>NRMS</strong> is a specialized variant for news recommendation that uses attention to model both the content of articles and the sequence of articles read.</p>

<p><strong>When to Consider:</strong> Transformer-based models should be the default choice for high-performance sequential recommendation. Choose <strong>SASRec</strong> for tasks where strict temporal order is paramount. Consider <strong>BERT4Rec</strong> when you have dense data and believe a user’s intent is better captured by their holistic interaction history.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>SASRec:</strong> Kang, W. C., &amp; McAuley, J. (2018). <em>Self-Attentive Sequential Recommendation</em>. <a href="https://arxiv.org/abs/1808.09781">https://arxiv.org/abs/1808.09781</a>.</li>
      <li><strong>BERT4Rec:</strong> Sun, F., Liu, J., Wu, J., Pei, C., Lin, X., Ou, W., &amp; Jiang, P. (2019). <em>BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer</em>. <a href="https://arxiv.org/abs/1904.06690">https://arxiv.org/abs/1904.06690</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="WithContrastiveLearningCl4srec"></a></p>
<h4 id="144-with-contrastive-learning-cl4srec">1.4.4 With Contrastive Learning: CL4SRec</h4>

<p><strong>Key concept:</strong> CL4SRec is a framework that enhances sequential models by adding a <strong>contrastive self-supervised learning</strong> objective. In addition to the primary task of predicting the next item, the model is trained to recognize that two different <em>augmented</em> views of the same user sequence should have similar representations, while being distinct from the sequences of other users.</p>

<blockquote>
  <p><strong>What is Contrastive Learning?</strong></p>

  <p><strong>Contrastive learning</strong> is a technique where a model learns by comparing things. You teach it what makes two things similar and what makes them different. For sequential recommendation, you take a user’s interaction history, create two slightly modified versions of it (e.g., by hiding or cropping a few items), and tell the model: “These two augmented sequences represent the same underlying preference, so their representations should be close. Push them away from the representations of all other sequences.” This helps the model learn the essential, robust essence of a user’s taste.</p>
</blockquote>

<p><strong>Key differentiator:</strong> Its key innovation lies in designing data augmentation strategies specifically for user interaction sequences (e.g., <strong>Item Crop</strong>, <strong>Item Mask</strong>). This self-supervised task acts as a powerful regularizer, forcing the model to learn more robust and generalizable user representations, which is especially helpful in sparse data scenarios.</p>

<p><strong>Use cases:</strong> CL4SRec is used to enhance any underlying sequential recommendation model (like SASRec). It is particularly effective in scenarios with high data sparsity or noisy interactions, as the additional self-supervised signal helps the model learn meaningful user representations from limited data.</p>

<p><strong>When to Consider:</strong> Consider integrating a contrastive learning framework like CL4SRec when your sequential model is underperforming due to data sparsity or overfitting. It can significantly boost performance by forcing the model to learn the core semantic properties of a user’s preference sequence, often improving recall for long-tail items.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Xie, X., Sun, F., Liu, Z., Wu, J., Zhang, H., &amp; Lin, X. (2020). <em>Contrastive Learning for Sequential Recommendation</em>. <a href="https://arxiv.org/abs/2010.14395">https://arxiv.org/abs/2010.14395</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="PythonFrameworks"></a></p>
<h4 id="python-frameworks-3">Python Frameworks</h4>

<ul>
  <li><strong>GRU4Rec:</strong>
    <ul>
      <li><strong>RecBole:</strong> <a href="https://github.com/RUCAIBox/RecBole">https://github.com/RUCAIBox/RecBole</a> Provides a well-maintained implementation.</li>
      <li><strong>Microsoft Recommenders:</strong> <a href="https://github.com/recommenders-team/recommenders">https://github.com/recommenders-team/recommenders</a> Includes a notebook demonstrating a GRU-based model for sequential recommendation.</li>
      <li>The original authors maintain a <strong>Theano</strong> implementation <a href="https://github.com/pascanur/theano_optimize">https://github.com/pascanur/theano_optimize</a> and strongly caution against using unverified third-party versions.</li>
    </ul>
  </li>
  <li><strong>NextItNet <a href="https://github.com/fajieyuan/WSDM2019-nextitnet">https://github.com/fajieyuan/WSDM2019-nextitnet</a>:</strong>
    <ul>
      <li><strong>RecBole:</strong> <a href="https://github.com/RUCAIBox/RecBole">https://github.com/RUCAIBox/RecBole</a> Includes a supported implementation.</li>
      <li><strong>Microsoft Recommenders:</strong> <a href="https://github.com/recommenders-team/recommenders">https://github.com/recommenders-team/recommenders</a> Provides a notebook showcasing its application.</li>
    </ul>
  </li>
  <li><strong>SASRec &amp; BERT4Rec:</strong>
    <ul>
      <li><strong>RecBole</strong> <a href="https://github.com/RUCAIBox/RecBole">https://github.com/RUCAIBox/RecBole</a> &amp; <strong>SELFRec:</strong> <a href="https://github.com/Coder-Yu/SELFRec">https://github.com/Coder-Yu/SELFRec</a> Offer robust implementations of both models.</li>
      <li><strong>Transformers4Rec (NVIDIA):</strong> https://github.com/NVIDIA-Merlin/Transformers4Rec A powerful library designed to adapt HuggingFace Transformers for recommendation tasks, providing an excellent environment for experimenting with these models.</li>
    </ul>
  </li>
  <li><strong>CL4SRec:</strong>
    <ul>
      <li><strong>SELFRec:</strong> <a href="https://github.com/Coder-Yu/SELFRec">https://github.com/Coder-Yu/SELFRec</a> A Python framework specifically designed for self-supervised recommendation, featuring CL4SRec as one of its flagship implementations.</li>
    </ul>
  </li>
</ul>

<p><a id="Productionready"></a></p>
<h4 id="production-ready-3">Production-ready?</h4>

<ul>
  <li><strong>GRU4Rec:</strong> While often surpassed by Transformers on benchmarks, it remains a <strong>powerful and relevant baseline</strong>. Its recurrent nature can be more efficient during real-time inference for step-by-step predictions, making it a viable production choice.</li>
  <li><strong>NextItNet:</strong> A <strong>strong and efficient</strong> model. Its parallelizable convolutional architecture makes it a competitive choice for production systems, especially for its ability to model long sequences effectively.</li>
  <li><strong>SASRec &amp; BERT4Rec:</strong> <strong>State-of-the-art and Production-Ready.</strong> These models represent the cutting edge for sequential recommendation. Their effectiveness has led to their increasing adoption in industrial production systems at major tech companies.</li>
  <li><strong>CL4SRec:</strong> <strong>Rapidly moving from Research to Production.</strong> Contrastive learning has consistently demonstrated significant performance improvements on academic benchmarks. Its proven ability to enhance model robustness and alleviate data sparsity makes it highly attractive, and its principles are being rapidly integrated into the training pipelines of production models.</li>
</ul>

<p><a id="15GraphbasedModelsGnns"></a></p>
<h3 id="15-graph-based-models-gnns">1.5 Graph-Based Models (GNNs)</h3>

<p>These models represent the user-item interaction data as a <strong>bipartite graph</strong>—a graph with two sets of nodes (users and items)—where an edge connects a user to an item they have interacted with. They then apply Graph Neural Networks (GNNs) to learn user and item embeddings, explicitly modeling the collaborative filtering effect by propagating information through this graph structure.</p>

<blockquote>
  <p><strong>What is a Bipartite Graph in Recommendation?</strong></p>

  <p>Imagine two groups of dots. One group represents all your users, and the other represents all your items. You draw a line (an <strong>edge</strong>) between a user and every item they’ve clicked on, rated, or purchased. The result is a bipartite graph. A GNN can “walk” along these lines to discover patterns. For example, by walking from <code class="language-plaintext highlighter-rouge">User A -&gt; Item 1 -&gt; User B</code>, the model learns that User A and User B have similar tastes, which is the core idea of collaborative filtering.</p>
</blockquote>

<p><a id="StandardGNNsNGCFLightGCN"></a></p>
<h4 id="151-standard-gnns-ngcf--lightgcn">1.5.1 Standard GNNs: NGCF &amp; LightGCN</h4>

<p><strong>Key concept:</strong> These models refine user and item embeddings through a process of <strong>neighborhood aggregation</strong> or <strong>message passing</strong>. The core idea is that a user’s embedding should be influenced by the items they have interacted with, and an item’s embedding by the users who have interacted with it. By stacking multiple GNN layers, the model can capture high-order relationships, allowing influence to propagate across multiple “hops” in the graph (e.g., from a user to the users-who-liked-similar-items).</p>

<p><strong>Key differentiator:</strong> The key difference lies in their complexity and approach to aggregation.</p>
<ul>
  <li><strong>NGCF (Neural Graph Collaborative Filtering)</strong> was a seminal model that used complex feature transformations and non-linear activation functions in each GNN layer to model intricate relationships.</li>
  <li><strong>LightGCN</strong> is its simplified and more powerful successor. The authors found that the feature transformations and non-linearities in NGCF were not essential for collaborative filtering and could even hinder performance. LightGCN removes them, focusing purely on weighted neighborhood aggregation. This simplification makes it faster, less prone to overfitting, and often significantly more accurate.</li>
</ul>

<p><strong>Use cases:</strong> Both models are designed for standard collaborative filtering tasks from implicit feedback. They are used for Top-N recommendation and have shown state-of-the-art performance on many benchmark datasets. <strong>LightGCN</strong>, due to its simplicity and effectiveness, has become a very strong and widely used baseline for graph-based recommendation.</p>

<p><strong>When to Consider:</strong> Graph-based models are a powerful choice when you want to capture the collaborative signal more explicitly than in standard matrix factorization. <strong>Start with LightGCN.</strong> Its simplicity, strong performance, and efficiency make it an excellent choice for most CF tasks. It serves as a crucial lesson: targeted simplicity often trumps general-purpose complexity.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>NGCF:</strong> Wang, X., He, X., Wang, M., Feng, F., &amp; Chua, T. S. (2019). <em>Neural Graph Collaborative Filtering</em>. <a href="https://arxiv.org/abs/1905.08108">https://arxiv.org/abs/1905.08108</a>.</li>
      <li><strong>LightGCN:</strong> He, X., Deng, K., Wang, X., Li, Y., Zhang, Y., &amp; Wang, M. (2020). <em>LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</em>. <a href="https://arxiv.org/abs/2002.02126">https://arxiv.org/abs/2002.02126</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="SessionbasedGnnsSrgnn"></a></p>
<h4 id="152-session-based-gnns-sr-gnn">1.5.2 Session-based GNNs: SR-GNN</h4>

<p><strong>Key concept:</strong> SR-GNN models a user’s session as a small, dynamic graph. For each session sequence, it constructs a directed graph where each unique item is a node and edges connect consecutively clicked items. A Gated Graph Neural Network is then applied to this session graph to learn complex item transition patterns. Finally, it uses the embeddings of items in the session to predict the next item.</p>

<p><strong>Key differentiator:</strong> While sequential models like RNNs process interactions in a strict linear order, SR-GNN can capture more complex, <strong>non-sequential relationships</strong> within a session. For example, in a session <code class="language-plaintext highlighter-rouge">[Phone -&gt; Case -&gt; Charger]</code>, it can directly model the relationship between “Phone” and “Charger” through the graph structure, a connection that an RNN might only capture weakly. This makes it more robust to user behaviors like clicking back and forth between items.</p>

<p><strong>Use cases:</strong> SR-GNN is used for session-based recommendation, particularly in anonymous settings (e.g., for users who are not logged in) where the goal is to predict the next action based only on the interactions in the current session.</p>

<p><strong>When to Consider:</strong> Consider SR-GNN when you are working with session data and believe the relationships between items are more like a web than a straight line. If a user’s behavior within a session is not strictly linear, a graph-based representation can capture these richer dependencies more effectively than a purely sequential model.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Wu, S., Tang, Y., Zhu, Y., Wang, L., Xie, X., &amp; Tan, T. (2019). <em>Session-Based Recommendation with Graph Neural Networks</em>. <a href="https://arxiv.org/abs/1811.00855">https://arxiv.org/abs/1811.00855</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="WithContrastiveLearningSGLSimGCL"></a></p>
<h4 id="153-with-contrastive-learning-sgl--simgcl">1.5.3 With Contrastive Learning: SGL &amp; SimGCL</h4>

<p><strong>Key concept:</strong> This line of work enhances GNN-based recommenders by incorporating a self-supervised, contrastive learning objective. The model learns to generate robust embeddings by ensuring that different augmented “views” of the same user or item are pulled closer together in the embedding space, while being pushed apart from other users or items.</p>

<p><strong>Key differentiator:</strong> The innovation lies in the data augmentation strategy used to create the “views.”</p>
<ul>
  <li><strong>SGL (Self-supervised Graph Learning)</strong> creates views by applying <strong>structural perturbations</strong> to the graph itself, such as randomly dropping nodes or edges. This makes the model’s embeddings robust to missing or noisy interaction data.</li>
  <li><strong>SimGCL (Simple Contrastive Learning on Graphs)</strong> uses a much simpler and often more effective technique: it creates views by adding a small amount of <strong>random noise</strong> directly to the embeddings during training. This avoids the complexity of graph manipulation while achieving a similar regularization effect.</li>
</ul>

<p><strong>Use cases:</strong> These methods are used to improve the performance and robustness of GNN-based collaborative filtering models like LightGCN. They are particularly effective for alleviating popularity bias and improving performance on sparse datasets where the additional self-supervised signal acts as a strong regularizer.</p>

<p><strong>When to Consider:</strong> An engineer should consider using a contrastive learning framework to enhance a GNN-based recommender, especially if the model suffers from popularity bias or performs poorly on long-tail items. Given its simplicity and superior efficiency, <strong>SimGCL</strong> is an excellent starting point.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>SGL:</strong> Wu, J., Wang, X., Feng, F., He, X., Chen, L., Lian, J., &amp; Xie, X. (2021). <em>Self-supervised Graph Learning for Recommendation</em>. <a href="https://arxiv.org/abs/2010.10783">https://arxiv.org/abs/2010.10783</a>.</li>
      <li><strong>SimGCL:</strong> Yu, J., Yin, H., Xia, X., Chen, T., Cui, L., &amp; Nguyen, Q. V. (2022). <em>Are Graph Augmentations Necessary? Simple Graph Contrastive Learning for Recommendation</em>. <a href="https://arxiv.org/abs/2112.08679">https://arxiv.org/abs/2112.08679</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="PythonFrameworks"></a></p>
<h4 id="python-frameworks-4">Python Frameworks</h4>

<ul>
  <li><strong>NGCF &amp; LightGCN:</strong>
    <ul>
      <li><strong>RecBole</strong> (<a href="https://github.com/RUCAIBox/RecBole">https://github.com/RUCAIBox/RecBole</a>): Provides high-quality, configurable implementations of both NGCF and LightGCN.</li>
      <li><strong>Agent4Rec</strong> <a href="https://github.com/LehengTHU/Agent4Rec">https://github.com/LehengTHU/Agent4Rec</a> A recent research framework on generative agents for recommendation uses LightGCN as one of its pre-trained model options</li>
      <li><strong>Microsoft Recommenders</strong> (<a href="https://github.com/recommenders-team/recommenders">https://github.com/recommenders-team/recommenders</a>): Provides a detailed “deep dive” notebook on LightGCN, explaining its theory and implementation.</li>
      <li>The original authors of LightGCN maintain a <strong>PyTorch</strong> implementation at <a href="https://github.com/kuandeng/LightGCN">https://github.com/kuandeng/LightGCN</a>.</li>
    </ul>
  </li>
  <li><strong>SR-GNN:</strong>
    <ul>
      <li>Implementations are available in major frameworks like <strong>RecBole</strong> and in various public GitHub repositories.</li>
    </ul>
  </li>
  <li><strong>SGL &amp; SimGCL:</strong>
    <ul>
      <li><strong>RecBole</strong> includes an implementation for SGL.</li>
      <li>The authors of SimGCL provide a <strong>PyTorch</strong> implementation at <a href="https://github.com/Coder-Yu/RecQ">https://github.com/Coder-Yu/RecQ</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="Productionready"></a></p>
<h4 id="production-ready-4">Production-ready?</h4>

<ul>
  <li><strong>LightGCN:</strong> <strong>Production-Ready and State-of-the-art Baseline.</strong> Its simplicity, efficiency, and strong performance make it one of the most powerful and widely used baselines for collaborative filtering. It is heavily used in both academia and industry.</li>
  <li><strong>SR-GNN:</strong> A <strong>strong, production-viable</strong> model for its specific niche of session-based recommendation. It is a go-to choice when session dynamics are complex and non-linear.</li>
  <li><strong>SGL &amp; SimGCL:</strong> <strong>Rapidly moving from Research to Production.</strong> The principles of contrastive learning on graphs have proven to be highly effective at improving model robustness. While still an active area of research, these techniques are being integrated into production pipelines to boost the performance of GNN-based systems, especially in sparse data environments.</li>
  <li><strong>NGCF</strong> was a breakthrough paper that demonstrated the immense potential of GNNs for collaborative filtering. However, its architecture, which includes feature transformation matrices and non-linear activation functions at each layer, has since been shown to be overly complex for the CF task. It is now primarily considered a foundational work and is used as a key baseline in research to evaluate newer, more streamlined GNN architectures.</li>
</ul>

<p><a id="16DeepGenerativeModels"></a></p>
<h3 id="16-deep-generative-models">1.6 Deep Generative Models</h3>

<p>This frontier of research moves beyond discriminative models to <strong>generative models</strong>, which learn the underlying probability distribution of the data. This allows them to generate plausible user interaction histories or novel item recommendations, rather than just predicting a score for a given user-item pair.</p>

<blockquote>
  <p><strong>Discriminative vs. Generative Models: What’s the difference?</strong></p>

  <p>It’s like the difference between a music critic and a composer.</p>

  <ul>
    <li>A <strong>Discriminative</strong> model is the <strong>critic</strong>. You give it a user and a song, and it <em>discriminates</em> by giving a score or a probability: “This user will like this song with 85% probability.” It learns the boundary between what a user likes and dislikes.</li>
    <li>A <strong>Generative</strong> model is the <strong>composer</strong> 🎼. You give it a user, and it <em>generates</em> a new playlist from scratch that it thinks the user will love. It learns the underlying patterns and structure of a user’s taste so well that it can create new examples.</li>
  </ul>
</blockquote>

<p><a id="GenerativeAdversarialNetworks"></a></p>
<h4 id="161-generative-adversarial-networks-gans-irgan">1.6.1 Generative Adversarial Networks (GANs): IRGAN</h4>

<p><strong>Key concept:</strong> IRGAN adapts the GAN framework to recommendation by setting up a competitive game between two neural networks:</p>
<ol>
  <li>A <strong>Generator</strong>, which acts as the recommender. It tries to learn the true distribution of a user’s preferences and generates “fake” (user, item) pairs that it predicts are relevant.</li>
  <li>A <strong>Discriminator</strong>, which acts as a critic. It is trained to distinguish between the “fake” items suggested by the Generator and the actual items from the user’s real interaction history.</li>
</ol>

<p>Through this adversarial training, the Generator is forced to produce increasingly realistic recommendations to “fool” the Discriminator, thereby learning a more robust model of user preferences.</p>

<p><strong>Key differentiator:</strong> The <strong>adversarial training process</strong> itself is unique. It creates a dynamic optimization landscape where the Generator effectively performs “hard negative mining” by trying to find the most challenging examples to fool the Discriminator. This can help the model learn to recommend more diverse and novel items, overcoming biases in the training data.</p>

<p><strong>Use cases:</strong> IRGAN is a general framework applicable to web search, item recommendation, and other information retrieval tasks. It’s used to learn the distribution of user preferences and generate a ranked list of items, with the potential to improve coverage of long-tail items.</p>

<p><strong>When to Consider:</strong> Consider exploring GANs for research-oriented projects or when traditional models seem to be underperforming due to data bias. While conceptually powerful, GAN-based recommenders are notoriously difficult and unstable to train, which has limited their widespread adoption in production.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Wang, J., Yu, L., Zhang, W., Gong, Y., Xu, Y., Wang, B., Zhang, P., &amp; Zhang, D. (2017). <em>IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models</em>. <a href="https://arxiv.org/abs/1705.10513">https://arxiv.org/abs/1705.10513</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="DiffusionForCfDiffrec"></a></p>
<h4 id="162-diffusion-for-cf-diffrec">1.6.2 Diffusion for CF: DiffRec</h4>

<p><strong>Key concept:</strong> DiffRec adapts the powerful Denoising Diffusion Probabilistic Models (DDPMs) from image generation to recommendation. The process has two stages:</p>
<ol>
  <li><strong>Forward (Diffusion) Process:</strong> It starts with a user’s true interaction vector (e.g., a multi-hot vector of liked items) and gradually adds Gaussian noise over a series of steps, eventually corrupting it into pure noise.</li>
  <li><strong>Reverse (Denoising) Process:</strong> A neural network is trained to reverse this process. It learns to take a noisy vector at any step and predict the noise that was added, thereby iteratively denoising it back to the original, clean interaction vector.</li>
</ol>

<p>To generate recommendations, the model starts with random noise and, conditioned on a user’s profile, runs this reverse process to generate a new, plausible interaction vector.</p>

<p><strong>Key differentiator:</strong> The iterative <strong>denoising process</strong> is a fundamentally different generative paradigm from GANs or VAEs. It is often more stable to train than GANs and can model highly complex data distributions, leading to high-quality and diverse generated outputs. This makes it particularly well-suited for capturing the uncertainty and multi-modal nature of user preferences.</p>

<p><strong>Use cases:</strong> DiffRec is a generative model for Top-N recommendation from implicit feedback. Its strength lies in its ability to model complex preference distributions and its robustness to noisy interactions in the training data.</p>

<p><strong>When to Consider:</strong> Consider DiffRec when you need a powerful generative model that can capture complex user preferences and where recommendation <strong>diversity and novelty</strong> are key objectives. It represents the cutting edge of generative modeling, but be mindful that it is computationally intensive, especially during the iterative sampling process at inference time.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Wang, W., Feng, F., He, X., Wang, X., &amp; Wang, Q. (2023). <em>Diffusion Recommender Model</em>. <a href="https://arxiv.org/abs/2304.04971">https://arxiv.org/abs/2304.04971</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="GflownetsGfn4rec"></a></p>
<h4 id="163-gflownets-gfn4rec">1.6.3 GFlowNets: GFN4Rec</h4>

<p><strong>Key concept:</strong> GFN4Rec uses Generative Flow Networks (GFlowNets) to frame recommendation as a sequential decision problem. It learns to construct a <em>list</em> of recommended items step-by-step. The model is trained to ensure that the probability of generating a particular list is directly proportional to a predefined <strong>reward</strong> function (e.g., the predicted overall quality or utility of that list).</p>

<p><strong>Key differentiator:</strong> Unlike most models that score items individually, GFN4Rec directly optimizes for the utility of an <strong>entire slate of recommendations</strong>. Its training objective inherently promotes <strong>diversity</strong>; if two different lists yield a similar high reward, the GFlowNet learns to assign both a high probability of being generated, rather than collapsing to a single “best” list.</p>

<p><strong>Use cases:</strong> GFN4Rec is specifically designed for <strong>listwise recommendation</strong> tasks where both the relevance and diversity of the recommended set are important. It is well-suited for online environments where exploration and the discovery of novel good recommendations are valuable.</p>

<p><strong>When to Consider:</strong> Consider GFN4Rec when the business objective is to optimize for the utility of an entire slate, not just individual item clicks. If recommendation diversity is a key performance indicator, GFN4Rec’s intrinsic diversity-promoting objective makes it a very compelling choice over models trained with standard cross-entropy loss.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Liu, J., Jin, Z., Liu, D., He, X., &amp; McAuley, J. (2023). <em>Generative Flow Network for Listwise Recommendation</em>. <a href="https://arxiv.org/abs/2306.02239">https://arxiv.org/abs/2306.02239</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="NormalizingFlowsIdnp"></a></p>
<h4 id="164-normalizing-flows-idnp">1.6.4 Normalizing Flows: IDNP</h4>

<p><strong>Key concept:</strong> Normalizing Flows are a class of generative models that learn a complex data distribution by applying a series of <strong>invertible and differentiable transformations</strong> to a simple base distribution (e.g., a standard Gaussian). Because every step is perfectly reversible, they can calculate the exact likelihood of any data point, a property not shared by VAEs or GANs.</p>

<p><strong>Key differentiator:</strong> The ability to compute the <strong>exact log-likelihood</strong> makes Normalizing Flows a principled and powerful tool for precise density estimation. In the context of recommendation, a related model like <strong>IDNP (Interest Dynamics Neural Process)</strong> uses this concept to model a <em>distribution over a user’s preference function over time</em>, allowing it to capture uncertainty and generalize from very few data points.</p>

<p><strong>Use cases:</strong> In recommendation, Normalizing Flows can learn highly expressive models of user or item embedding distributions. They are particularly promising for few-shot or cold-start sequential recommendation tasks, where modeling the uncertainty in a user’s evolving taste is critical.</p>

<p><strong>When to Consider:</strong> Normalizing Flows are an advanced generative modeling technique. Consider them for research purposes or in applications where precise density estimation of user preferences is critical. They are generally more complex to implement and train than other generative models.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>Foundational:</strong> Rezende, D. J., &amp; Mohamed, S. (2015). <em>Variational Inference with Normalizing Flows</em>. <a href="https://arxiv.org/abs/1505.05770">https://arxiv.org/abs/1505.05770</a>.</li>
      <li><strong>IDNP:</strong> Du, W., Wang, H., Xu, C., &amp; Zhang, Y. (2023). <em>Interest Dynamics Modeling with Neural Processes for Sequential Recommendation</em>. <a href="https://arxiv.org/abs/2209.15236">https://arxiv.org/abs/2209.15236</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="PythonFrameworks"></a></p>
<h4 id="python-frameworks-5">Python Frameworks</h4>

<ul>
  <li><strong>IRGAN:</strong> <a href="https://github.com/geek-ai/irgan">https://github.com/geek-ai/irgan</a> The original implementation is at <strong>geek-ai/irgan</strong> on GitHub. Implementations are typically done from scratch in core deep learning libraries.</li>
  <li><strong>DiffRec:</strong> <a href="https://github.com/YiyanXu/DiffRec">https://github.com/YiyanXu/DiffRec</a> Research implementations from the seminal papers are available on GitHub at <strong>YiyanXu/DiffRec</strong> and <strong>WHUIR/DiffuRec</strong>.</li>
  <li><strong>GFN4Rec:</strong> <a href="https://github.com/CharlieMat/GFN4Rec">https://github.com/CharlieMat/GFN4Rec</a> The model whose implementations is primarily found in the authors’ research repositories on GitHub.</li>
</ul>

<p><a id="Productionready"></a></p>
<h4 id="production-ready-5">Production-ready?</h4>

<ul>
  <li><strong>All Models in this Section:</strong> <strong>Research Interest.</strong> This entire category represents the frontier of recommendation research.
    <ul>
      <li><strong>GANs (IRGAN):</strong> While conceptually powerful, they are notoriously difficult to train and stabilize, which has prevented widespread production adoption.</li>
      <li><strong>Diffusion (DiffRec):</strong> This area is generating significant excitement and strong benchmark results. However, the models are computationally intensive, especially the iterative sampling process at inference time, making low-latency production deployment a major challenge.</li>
      <li><strong>GFlowNets &amp; Normalizing Flows:</strong> These are highly promising but complex paradigms that are still in the early stages of exploration for recommendation tasks.</li>
    </ul>
  </li>
</ul>

<p><a id="Section2TextdrivenRecommendationAlgorithms"></a></p>
<h2 id="section-2-text-driven-recommendation-algorithms">Section 2: Text-Driven Recommendation Algorithms</h2>

<p>This section shifts focus to algorithms that explicitly leverage unstructured text, primarily user reviews and item descriptions. The advent of powerful NLP models, especially Large Language Models, has dramatically expanded the capabilities in this domain.</p>

<p><a id="21ReviewbasedModels"></a></p>
<h3 id="21-review-based-models">2.1 Review-Based Models</h3>

<p>These models mine user-generated reviews to extract rich, nuanced information about user preferences and item attributes. This helps to alleviate the data sparsity and cold-start problems inherent in interaction-only models. The use of text provides a powerful bridge, improving performance and offering a natural pathway to explainability.</p>

<blockquote>
  <p><strong>Why read the reviews?</strong></p>

  <p>A 5-star rating tells you <em>what</em> a user liked, but the review tells you <em>why</em>. One user might give a phone 5 stars for its “amazing camera,” while another gives the same rating for its “incredible battery life.” Review-based models “read” this text to understand these nuances, allowing them to differentiate between users with the same ratings but different preferences, leading to far more personalized recommendations.</p>
</blockquote>

<p><a id="Deepconn"></a></p>
<h4 id="211-deepconn-deep-cooperative-neural-networks">2.1.1 DeepCoNN (Deep Cooperative Neural Networks)</h4>

<p><strong>Key concept:</strong> DeepCoNN uses a dual deep learning architecture. One Convolutional Neural Network (CNN) processes the concatenation of all reviews written <em>by</em> a target user to learn a latent user representation. In parallel, a second CNN processes all reviews written <em>for</em> a target item to learn a latent item representation. These two vectors are then combined to predict the final rating.</p>

<p><strong>Key differentiator:</strong> It was a foundational model demonstrating that user and item profiles could be learned <em>end-to-end directly from raw text</em>. Instead of manual feature engineering, it lets the neural networks discover what aspects of language are important for representing users and items.</p>

<p><strong>Use cases:</strong> Rating prediction in review-rich environments like Amazon, Yelp, and other e-commerce or content platforms. It is particularly effective at alleviating the cold-start problem, as it can generate meaningful representations from text even when rating data is sparse.</p>

<p><strong>When to Consider:</strong> Consider DeepCoNN when you need to leverage review text to improve rating prediction, especially for users or items with few ratings. It is a foundational model that serves as a strong baseline for more advanced text-based models.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Zheng, L., Noroozi, V., &amp; Yu, P. (2017). <em>Joint Deep Modeling of Users and Items Using Reviews for Recommendation</em>. <a href="https://arxiv.org/abs/1701.04783">https://arxiv.org/abs/1701.04783</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="NARRE"></a></p>
<h4 id="212-narre-neural-attentional-rating-regression-with-review-level-explanations">2.1.2 NARRE (Neural Attentional Rating Regression with Review-level Explanations)</h4>

<p><strong>Key concept:</strong> NARRE enhances the idea of DeepCoNN by incorporating a dual <strong>attention mechanism</strong>. It learns to identify and assign higher weights to the most useful and informative reviews when constructing the user and item representations, effectively filtering out noisy or irrelevant content.</p>

<p><strong>Key differentiator:</strong> The <strong>attention mechanism</strong> is the key innovation. It not only improves prediction accuracy by focusing on what’s important but also provides a natural path to <strong>explainability</strong>. The model can highlight the specific reviews that were most influential in making a recommendation, which can significantly increase user trust.</p>

<p><strong>Use cases:</strong> NARRE is designed for rating prediction in systems where user reviews are abundant (e-g., e-commerce, service platforms). Its ability to provide explanations makes it valuable for applications where user trust and transparency are important.</p>

<p><strong>When to Consider:</strong> Use NARRE when you have a rich dataset of user reviews and want to improve rating prediction accuracy while also generating explanations. It is a powerful tool for building more transparent and trustworthy recommender systems.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Chen, C., Zhang, M., Liu, Y., &amp; Ma, S. (2018). <em>Neural Attentional Rating Regression with Review-level Explanations</em>. <a href="https://dl.acm.org/doi/10.1145/3178876.3186070">https://dl.acm.org/doi/10.1145/3178876.3186070</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="22LargeLanguageModelLlmbasedParadigms"></a></p>
<h3 id="22-large-language-model-llm-based-paradigms">2.2 Large Language Model (LLM)-Based Paradigms</h3>

<p>The emergence of Large Language Models (LLMs) has created a paradigm shift, reformulating recommendation as a language understanding and generation problem. LLMs can be applied in various ways, from acting as powerful feature extractors to serving as the core recommendation engine itself.</p>

<blockquote>
  <p><strong>The Paradigm Shift: From Pattern Matching to Language Understanding</strong></p>

  <p>Traditional recommenders are expert <strong>pattern matchers</strong>, finding correlations in a huge matrix of clicks and purchases. LLM-based recommenders aim to be <strong>comprehension engines</strong>. They can understand the <em>semantic meaning</em> of an item description, infer intent from a user’s natural language query, and leverage vast world knowledge (e.g., knowing that “cyberpunk” is a theme connecting <em>Blade Runner</em> and <em>Ghost in the Shell</em>) to make recommendations based on a deeper level of understanding.</p>
</blockquote>

<p><a id="RetrievalbasedDenseRetrievalCrossEncoders"></a></p>
<h4 id="221-retrieval-based-dense-retrieval--cross-encoders">2.2.1 Retrieval-based: Dense Retrieval &amp; Cross-Encoders</h4>

<p><strong>Key concept:</strong> This paradigm adopts the two-stage “retrieve-then-rank” architecture common in modern information retrieval.</p>
<ol>
  <li><strong>Dense Retrieval (Bi-Encoder):</strong> A fast “retrieval” stage that uses one model to independently encode the user’s query/profile into a vector and another to encode all items in the catalog. It then uses efficient Approximate Nearest Neighbor (ANN) search to find the top-K most similar items from a massive catalog (millions or billions).</li>
  <li><strong>Cross-Encoder:</strong> A slower but more accurate “ranking” stage. It takes the user query and each of the top-K retrieved items <em>together</em> as a single input to a more powerful model (like BERT) to produce a highly precise relevance score for re-ranking.</li>
</ol>

<p><strong>Key differentiator:</strong> The <strong>separation of concerns</strong> between a scalable-but-less-precise retriever and a precise-but-less-scalable re-ranker. This hybrid approach allows systems to search over enormous item catalogs with very low latency while ensuring the final results shown to the user are highly accurate.</p>

<p><strong>Use cases:</strong> This architecture is the standard for large-scale recommendation and search systems (e.g., Google Search, YouTube recommendations). It is used to retrieve relevant items from massive catalogs in real-time.</p>

<p><strong>When to Consider:</strong> This is the go-to architecture for building scalable and high-performance recommender systems. When you need to serve recommendations from a large item corpus with low latency, a bi-encoder for initial retrieval followed by a cross-encoder for re-ranking is a state-of-the-art approach.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>Dense Retrieval (Foundational):</strong> Karpukhin, V., Oguz, B., Min, S., et al. (2020). <em>Dense Passage Retrieval for Open-Domain Question Answering</em>. <a href="https://arxiv.org/abs/2004.04906">https://arxiv.org/abs/2004.04906</a>.</li>
      <li><strong>Cross-Encoders (Foundational):</strong> Nogueira, R., &amp; Cho, K. (2019). <em>Passage Re-ranking with BERT</em>. <a href="https://arxiv.org/abs/1901.04085">https://arxiv.org/abs/1901.04085</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="GenerativeInstruction"></a></p>
<h4 id="222-generative--instruction-tuned">2.2.2 Generative / Instruction-Tuned</h4>

<p><strong>Key concept:</strong> This approach reframes recommendation as a text generation problem. An instruction-tuned LLM is given a prompt containing the user’s history, profile, and a specific task (e.g., <em>“Given this user’s past movie ratings, recommend 5 new sci-fi movies and explain why they would like each one.”</em>). The LLM then generates the recommendations and explanations as a coherent, natural language response.</p>

<p><strong>Key differentiator:</strong> Its <strong>flexibility and zero-shot reasoning ability</strong>. The LLM can leverage its vast pre-trained world knowledge to make novel connections and provide recommendations for queries or user types it has never seen before, complete with human-like justifications.</p>

<p><strong>Use cases:</strong> Instruction-tuned LLMs are used for a wide range of tasks, including direct item recommendation, generating explanations, and user profiling. Their flexibility makes them suitable for creating more conversational and multi-task recommendation systems.</p>

<p><strong>When to Consider:</strong> Consider this approach when you want to leverage the generative and reasoning power of LLMs. It is particularly promising for cold-start problems and for building systems that can perform multiple recommendation-related tasks within a unified framework.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Geng, S., Liu, J.,, et al. (2022). <em>Recommendation as Language Processing (RLP): A Unified Pretrain, Tine-tune, and Prompt Paradigm</em>. <a href="https://arxiv.org/abs/2203.13366">https://arxiv.org/abs/2203.13366</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="RAGFeatureExtraction"></a></p>
<h4 id="223-rag--feature-extraction">2.2.3 RAG &amp; Feature Extraction</h4>

<p><strong>Key concept:</strong> This paradigm uses LLMs as a powerful <em>component</em> to enhance other recommender systems in two primary ways:</p>
<ol>
  <li><strong>LLM as a Feature Enhancer:</strong> Using an LLM as a sophisticated tool to process unstructured text (reviews, item descriptions) and extract high-quality semantic embeddings or structured features (e.g., “user cares about battery life”) to feed into any downstream recommendation model.</li>
  <li><strong>Retrieval-Augmented Generation (RAG):</strong> Grounding a generative LLM with real-time, factual information. Before generating a recommendation, the system retrieves relevant documents (e.g., up-to-date product specs, user’s recent reviews) and adds them to the LLM’s prompt as context.</li>
</ol>

<p><strong>Key differentiator:</strong> RAG’s key function is to <strong>mitigate hallucinations</strong> and ensure the LLM’s recommendations are factually accurate and based on current information from a trusted knowledge source. Using an LLM for feature extraction is a highly pragmatic way to inject powerful semantic understanding into any existing recommender pipeline.</p>

<p><strong>Use cases:</strong> Use <strong>RAG</strong> for building reliable generative recommender systems where factual accuracy is critical (e.g., recommending technical products, academic papers). Use an <strong>LLM as a feature enhancer</strong> to boost the performance of an existing recommendation model by improving its input features.</p>

<p><strong>When to Consider:</strong> Use RAG when building a generative recommender to mitigate the risk of the model making things up. Use an LLM as a feature extractor when you have rich textual data and want to create powerful semantic features to boost the performance of an existing model.</p>

<ul>
  <li><strong>Seminal Paper (Foundational RAG):</strong> Lewis, P., Perez, E., Piktus, A., et al. (2020). <em>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</em>. <a href="https://arxiv.org/abs/2005.11401">https://arxiv.org/abs/2005.11401</a>.</li>
</ul>

<p><a id="LLMAgentsToolUse"></a></p>
<h4 id="224-llm-agents--tool-use">2.2.4 LLM Agents &amp; Tool Use</h4>

<p><strong>Key concept:</strong> This advanced paradigm treats the LLM as a “reasoning engine” or orchestrator that can use external <strong>tools</strong>. The LLM is given access to a set of functions or APIs (e.g., a search API, a database query, a traditional recommender model). For a complex user request, the LLM devises a multi-step plan and decides which tools to call, in what order, to fulfill the request.</p>

<p><strong>Key differentiator:</strong> The ability to <strong>autonomously plan, reason, and act</strong>. Unlike other paradigms that perform a single, well-defined task, an LLM agent can decompose a complex goal (e.g., <em>“Find me a camera with the image quality of a DSLR but lighter than 500g”</em>) into a sequence of sub-tasks and tool calls.</p>

<p><strong>Use cases:</strong> Building next-generation interactive assistants that can handle complex, multi-step goals, where recommendation is just one part of a larger, problem-solving process. The RecMind framework is a concrete example.</p>

<p><strong>When to Consider:</strong> This is a frontier area of research and development. Consider building an LLM agent-based system when the user’s needs are complex and cannot be met by a single retrieval or ranking call. This is for building sophisticated assistants that help users accomplish complex goals.</p>

<ul>
  <li><strong>Seminal Paper (Example Framework):</strong>
    <ul>
      <li>Wang, W., et al. (2024). <em>RecMind: Large Language Model Powered Agent For Recommendation</em>. <a href="https://arxiv.org/abs/2403.00366">https://arxiv.org/abs/2403.00366</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="23ConversationalRecommenderSystems"></a></p>
<h3 id="23-conversational-recommender-systems">2.3 Conversational Recommender Systems</h3>

<p>This area focuses on creating interactive, multi-turn recommendation experiences, moving beyond the static “recommend and consume” loop.</p>

<blockquote>
  <p><strong>From Monologue to Dialogue</strong></p>

  <p>Traditional recommendation is a monologue: the system presents a list, and the user takes it or leaves it. A conversational recommender turns this into a <strong>dialogue</strong>. It’s an interactive back-and-forth where the system can ask clarifying questions and the user can provide nuanced feedback, creating a collaborative process that feels more like talking to a human expert. 💬</p>
</blockquote>

<p><a id="DialoguebasedPreferenceElicitation"></a></p>
<h4 id="231-dialogue-based-preference-elicitation">2.3.1 Dialogue-based Preference Elicitation</h4>

<p><strong>Key concept:</strong> This is the process of actively asking a user questions in a multi-turn conversation to learn (“elicit”) their needs and preferences, especially when those preferences are unknown (cold-start) or ambiguous. The system maintains an evolving model of the user’s preferences that it updates with each turn of the dialogue.</p>

<p><strong>Key differentiator:</strong> It is an <strong>interactive and guided</strong> discovery process. Instead of expecting the user to know exactly what they want, the system acts like a helpful sales assistant or concierge, asking clarifying questions to progressively narrow down the options and pinpoint the user’s true intent.</p>

<p><strong>Use cases:</strong> Conversational recommenders are used in chatbots, voice assistants, and interactive e-commerce platforms where a guided discovery process is beneficial. They are ideal for complex domains with many attributes, like electronics, travel, or real estate.</p>

<p><strong>When to Consider:</strong> Implement a dialogue-based system when you need to serve users with no prior history (cold-start) or when the user’s intent is ambiguous and requires clarification. It is highly valuable in domains where users may not know exactly what they are looking for.</p>

<ul>
  <li><strong>Key Survey Paper:</strong>
    <ul>
      <li>Gao, C., Li, Y., et al. (2021). <em>A Survey on Conversational Recommender Systems</em>. <a href="https://arxiv.org/abs/2101.06462">https://arxiv.org/abs/2101.06462</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="NaturalLanguageExplanationCritique"></a></p>
<h4 id="232-natural-language-explanation--critique">2.3.2 Natural Language Explanation &amp; Critique</h4>

<p><strong>Key concept:</strong> This focuses on two-way communication <em>about</em> the recommendations themselves.</p>
<ol>
  <li><strong>Explanation:</strong> The system explains <em>why</em> an item was recommended in natural language (e.g., <em>“I’m suggesting this camera because you said you value long battery life.”</em>).</li>
  <li><strong>Critique:</strong> The user can provide feedback on a recommendation in natural language (e.g., <em>“That’s a good start, but can you find something a bit lighter?”</em>), and the system uses this critique to refine its next suggestion.</li>
</ol>

<p><strong>Key differentiator:</strong> It creates a <strong>collaborative feedback loop</strong>. This empowers the user to iteratively steer the recommendation process, which builds trust and leads to a more satisfying outcome than a static, one-shot recommendation. It transforms the interaction from a simple transaction to a partnership.</p>

<p><strong>Use cases:</strong> This is a key feature for advanced conversational agents and recommender systems aiming for a high-quality user experience where building user trust and providing a highly interactive, refined search process is important.</p>

<p><strong>When to Consider:</strong> Implement natural language explanation and critique capabilities when the goal is to create a truly interactive and user-centric recommendation experience. If user trust is a key concern, these features are essential.</p>

<ul>
  <li><strong>Key Survey Paper:</strong>
    <ul>
      <li>Jannach, D., &amp; Jugovac, M. (2019). <em>Explainable and Conversational Recommender Systems</em>. <a href="https://arxiv.org/abs/1902.01735">https://arxiv.org/abs/1902.01735</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="PythonFrameworks"></a></p>
<h4 id="python-frameworks-6">Python Frameworks</h4>

<ul>
  <li><strong>Review-Based:</strong> These models are typically implemented from scratch or using standard deep learning libraries. The <strong>Microsoft Recommenders</strong> repo (<a href="https://github.com/recommenders-team/recommenders">https://github.com/recommenders-team/recommenders</a>) contains conceptually similar text-aware models for news recommendation (e.g., NAML, LSTUR).</li>
  <li><strong>Retrieval-based:</strong>
    <ul>
      <li><strong>Vector Databases &amp; Search Libraries:</strong> <strong>FAISS</strong> (<a href="https://github.com/facebookresearch/faiss">https://github.com/facebookresearch/faiss</a>) and <strong>ScaNN</strong> (<a href="https://github.com/google-research/google-research/tree/master/scann">https://github.com/google-research/google-research/tree/master/scann</a>) are essential for the efficient ANN search in the retrieval stage.</li>
      <li><strong>SentenceTransformers</strong> (<a href="https://github.com/UKPLab/sentence-transformers">https://github.com/UKPLab/sentence-transformers</a>) is a popular library for creating the bi-encoder and cross-encoder models.</li>
    </ul>
  </li>
  <li><strong>LLM-based (Generative, RAG, Agents):</strong>
    <ul>
      <li><strong>Hugging Face Transformers</strong> (<a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a>) is the foundational library for accessing pre-trained LLMs.</li>
      <li><strong>LangChain</strong> (<a href="https://github.com/langchain-ai/langchain">https://github.com/langchain-ai/langchain</a>) and <strong>LlamaIndex</strong> (<a href="https://github.com/run-llama/llama_index">https://github.com/run-llama/llama_index</a>) are powerful frameworks for building RAG pipelines and LLM agents that can use tools.</li>
    </ul>
  </li>
  <li><strong>Conversational:</strong>
    <ul>
      <li><strong>Rasa</strong> (<a href="https://github.com/RasaHQ/rasa">https://github.com/RasaHQ/rasa</a>) and <strong>Google Dialogflow</strong> are comprehensive platforms for building production-grade conversational AI, including preference elicitation and dialogue management.</li>
    </ul>
  </li>
</ul>

<p><a id="Productionready"></a></p>
<h4 id="production-ready-6">Production-ready?</h4>

<ul>
  <li><strong>Review-Based Models:</strong> <strong>Production-Ready.</strong> The core principle of using text from reviews to enrich item and user profiles is a standard and powerful technique in industrial recommender systems, even if specific academic architectures aren’t deployed verbatim.</li>
  <li><strong>Retrieval-based (Dense Retrieval &amp; Cross-Encoders):</strong> <strong>Production-Ready and State-of-the-art.</strong> This two-stage architecture is the gold standard for building modern, large-scale industrial search and recommendation systems.</li>
  <li><strong>LLM-based Paradigms:</strong>
    <ul>
      <li><strong>LLM as Feature Enhancer:</strong> <strong>Production-Ready.</strong> This is a highly pragmatic and increasingly common way to improve existing models.</li>
      <li><strong>RAG:</strong> <strong>Production-Ready.</strong> RAG is quickly becoming the standard for building reliable generative applications, and its use in recommendation is a major focus area.</li>
      <li><strong>Generative / Agents:</strong> <strong>Moving from Research to Production with extreme velocity.</strong> While challenges with latency, cost, and control remain, the potential of these approaches is driving massive investment and rapid progress toward production deployment.</li>
    </ul>
  </li>
  <li><strong>Conversational RecSys:</strong> <strong>Production-Ready.</strong> Conversational AI is a mature field, and dialogue-based systems are widely deployed in customer service chatbots and voice assistants. Integrating them with recommendation backends is a common practice.</li>
</ul>

<p><a id="Section3MultimodalRecommendationAlgorithms"></a></p>
<h2 id="section-3-multimodal-recommendation-algorithms">Section 3: Multimodal Recommendation Algorithms</h2>

<p>This section explores models that fuse information from multiple modalities—typically text, images, and video—to build a richer, more comprehensive understanding of items and user preferences. This is particularly crucial in domains like e-commerce, social media, and streaming, where visual content is a primary driver of user choice.</p>

<p><a id="31ContrastiveLearningForMultimodalAlignment"></a></p>
<h3 id="31-contrastive-learning-for-multimodal-alignment">3.1 Contrastive Learning for Multimodal Alignment</h3>

<p>A foundational step for effective multimodal reasoning is creating a <strong>shared embedding space</strong> where different modalities of the same concept are mapped to nearby points. For example, the image of a cat and the text “a photo of a cat” should have very similar vector representations. Contrastive learning has emerged as the dominant paradigm for achieving this alignment by training models on massive datasets of paired multimodal data.</p>

<blockquote>
  <p><strong>What is a Shared Embedding Space?</strong></p>

  <p>Think of it as a universal, multilingual dictionary for concepts. In this dictionary, the entry for “cat” is a specific point in a high-dimensional space. The power of a shared embedding space is that the picture of a cat (from the “image language”) and the word “cat” (from the “text language”) are both translated to that <em>exact same point</em>. This allows the model to understand that an image and a piece of text are talking about the same thing, enabling powerful cross-modal search and recommendation.</p>
</blockquote>

<p><a id="CLIP"></a></p>
<h4 id="311-clip-contrastive-language-image-pre-training">3.1.1 CLIP (Contrastive Language-Image Pre-Training)</h4>

<p><strong>Key concept:</strong> CLIP is a powerful model pre-trained on a massive dataset of (image, caption) pairs from the internet. It uses a contrastive objective to learn a shared embedding space where an image and its corresponding text description are mapped to nearby points. For example, a picture of a pair of sneakers and the text “casual shoes” will have very similar vector representations in CLIP’s space.</p>

<p><strong>Key differentiator:</strong> Its powerful <strong>zero-shot transfer capability</strong>. Because it’s trained on such a vast and diverse dataset, a pre-trained CLIP model can understand and classify visual concepts it has never been explicitly fine-tuned on, simply by describing them in text. This makes it an incredibly versatile, out-of-the-box tool for semantic understanding.</p>

<p><strong>Use cases:</strong> It’s used to generate rich, semantic embeddings for items from their images. These embeddings can then be used for visual search (“find more dresses like this one”), content-based recommendation, and solving the cold-start item problem. It excels in domains where visual aesthetics are key (e.g., fashion, home decor, social media).</p>

<p><strong>When to Consider:</strong> An engineer should consider using pre-trained CLIP embeddings whenever items have associated images. It is an extremely effective way to incorporate multimodal content information into any recommender system (from k-NN to DeepFM) with minimal effort and often significant performance gains.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., et al. (2021). <em>Learning Transferable Visual Models From Natural Language Supervision</em>. <a href="https://arxiv.org/abs/2103.00020">https://arxiv.org/abs/2103.00020</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="ALBEF"></a></p>
<h4 id="312-albef-align-before-fuse">3.1.2 ALBEF (Align Before Fuse)</h4>

<p><strong>Key concept:</strong> ALBEF is a multimodal architecture that learns to align image and text representations. Its core principle is to first align the features from unimodal encoders (one for images, one for text) using a contrastive loss, and <em>then</em> fuse them using a more complex cross-modal encoder for downstream tasks.</p>

<p><strong>Key differentiator:</strong> The <strong>“Align-Before-Fuse”</strong> strategy and its multi-task training objective, which includes image-text contrastive loss, masked language modeling (MLM), and image-text matching (ITM). The MLM and ITM losses, applied after the initial alignment, enable the model to learn much finer-grained interactions between visual regions and words.</p>

<p><strong>Use cases:</strong> Like CLIP, ALBEF is used to generate powerful multimodal embeddings. Its strong performance on retrieval and visual question answering (VQA) tasks makes it particularly well-suited for building sophisticated multimodal recommender or search systems that require a deep understanding of the relationship between image and text.</p>

<p><strong>When to Consider:</strong> Consider ALBEF or similar models when you need to train a state-of-the-art multimodal encoder from scratch for your specific domain and require top performance on complex multimodal reasoning tasks, rather than just using off-the-shelf embeddings.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Li, J., Li, D., Xiong, C., &amp; Hoi, S. (2021). <em>Align before Fuse: Vision and Language Representation Learning with Momentum Distillation</em>. <a href="https://arxiv.org/abs/2107.07651">https://arxiv.org/abs/2107.07651</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="32GenerativeMultimodalModels"></a></p>
<h3 id="32-generative-multimodal-models">3.2 Generative Multimodal Models</h3>

<p>These models aim to learn the joint probability distribution of multimodal data, enabling them to generate new, personalized multimodal content or perform complex cross-modal inference.</p>

<blockquote>
  <p><strong>From Analysis to Synthesis</strong></p>

  <p>The models above are primarily for <strong>analysis</strong>—they learn to understand and represent existing content. Generative multimodal models are for <strong>synthesis</strong>—they learn to <em>create</em> new content. Instead of just finding an existing product image you might like, a generative model could one day create a brand-new image of a product tailored to your unique style.</p>
</blockquote>

<p><a id="MultimodalVaes"></a></p>
<h4 id="321-multimodal-vaes">3.2.1 Multimodal VAEs</h4>

<p><strong>Key concept:</strong> Multimodal VAEs extend the Variational Autoencoder framework to handle multiple data types simultaneously (e.g., images and text). They learn a <strong>joint latent probability distribution</strong> that captures the shared underlying factors across different modalities for a given item.</p>

<p><strong>Key differentiator:</strong> Their ability to model the joint distribution in a probabilistic way makes them excellent at handling <strong>missing modalities</strong>. If an item has an image but no description, the model can still infer a reasonable joint latent representation from the available data. Their generative nature also allows for cross-modal synthesis (e.g., generating a likely caption for a given image).</p>

<p><strong>Use cases:</strong> Multimodal VAEs can be used in recommendation to learn a holistic representation of items from their text, images, and other attributes. This can improve collaborative filtering performance and enable novel applications like generating a textual description for a recommended product image.</p>

<p><strong>When to Consider:</strong> Consider Multimodal VAEs when you need a generative model for items with multiple modalities, especially if your dataset has missing data that you need to handle gracefully.</p>

<ul>
  <li><strong>Key Survey Paper:</strong>
    <ul>
      <li>Suzuki, M. (2022). <em>A Survey on Multimodal Deep Learning: From a Recommender Systems Perspective</em>. <a href="https://arxiv.org/abs/2201.07008">https://arxiv.org/abs/2201.07008</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="MultimodalDiffusion"></a></p>
<h4 id="322-multimodal-diffusion">3.2.2 Multimodal Diffusion</h4>

<p><strong>Key concept:</strong> This paradigm applies the powerful denoising diffusion process to multimodal data. The model learns to reverse a process where noise is gradually added to data from multiple modalities (e.g., an image and its corresponding text) simultaneously. By learning to denoise them jointly, the model captures their joint distribution with high fidelity.</p>

<p><strong>Key differentiator:</strong> Its ability to generate <strong>exceptionally high-quality</strong>, realistic multimodal content. While other generative models can sometimes produce blurry or incoherent outputs, diffusion models have set a new standard for quality in content generation.</p>

<p><strong>Use cases:</strong> This is a cutting-edge area. Potential applications include enhancing multimodal recommendations by generating more robust representations or creating highly personalized content for users (e.g., generating a custom image and description for a recommended product <em>concept</em>). Frameworks like <strong>CCDRec</strong> use diffusion to guide the recommendation process.</p>

<p><strong>When to Consider:</strong> Consider exploring multimodal diffusion models for applications requiring high-fidelity generative capabilities or for improving the robustness of multimodal representations. Given their computational cost, they are best suited for research-focused projects or large-scale industrial labs exploring the next generation of generative recommendation.</p>

<ul>
  <li><strong>Key Survey Paper:</strong>
    <ul>
      <li>Wei, T. R., &amp; Fang, Y. (2024). <em>A Survey on Diffusion Models for Recommender Systems</em>. <a href="https://arxiv.org/abs/2401.10548">https://arxiv.org/abs/2401.10548</a>.</li>
    </ul>
  </li>
</ul>

<p><a id="PythonFrameworks"></a></p>
<h4 id="python-frameworks-7">Python Frameworks</h4>

<ul>
  <li><strong>Contrastive Models (CLIP/ALBEF):</strong>
    <ul>
      <li><strong>OpenAI CLIP:</strong> The official repository is available at <a href="https://github.com/openai/CLIP">https://github.com/openai/CLIP</a>.</li>
      <li><strong>OpenCLIP:</strong> A popular, high-performance open-source implementation of CLIP is maintained at <a href="https://github.com/mlfoundations/open_clip">https://github.com/mlfoundations/open_clip</a>.</li>
      <li><strong>Hugging Face Transformers:</strong> Provides easy access to pre-trained CLIP and ALBEF models for integration into pipelines.</li>
    </ul>
  </li>
  <li><strong>Generative Models (VAEs/Diffusion):</strong>
    <ul>
      <li>These are typically implemented using core deep learning libraries like <strong>PyTorch</strong> or <strong>TensorFlow</strong>.</li>
      <li><strong>Hugging Face Diffusers</strong> (<a href="https://github.com/huggingface/diffusers">https://github.com/huggingface/diffusers</a>) is a state-of-the-art library for pre-trained diffusion models, which can be adapted for multimodal tasks.</li>
    </ul>
  </li>
</ul>

<p><a id="Productionready"></a></p>
<h4 id="production-ready-7">Production-ready?</h4>

<ul>
  <li><strong>Contrastive Models (CLIP):</strong> <strong>Production-Ready as a Feature Extractor.</strong> Using pre-trained CLIP embeddings to represent visual content is a powerful, common, and highly effective practice in industrial recommender systems. It is one of the best ways to solve the visual cold-start problem.</li>
  <li><strong>Generative Models (VAEs/Diffusion):</strong> <strong>Research Interest.</strong> While generative AI is in production for content creation, its specific application for multimodal <em>recommendation</em> (beyond simple data augmentation) is still an emerging and computationally expensive field. The potential is enormous, but practical, low-latency deployment remains a significant challenge.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>This survey has charted the expansive and rapidly evolving landscape of recommendation algorithms, organized through the lens of the primary data modalities they employ. The journey from simple neighborhood-based methods to complex, generative large language models reveals several overarching themes that define the field’s progress and point toward its future.</p>

<p>First, a persistent and healthy tension exists between model complexity and practical performance. While the field’s frontier is constantly pushed by more sophisticated architectures, foundational models like ItemKNN and simple matrix factorization remain remarkably robust baselines. The success of LightGCN, which achieved superior performance by simplifying its more complex predecessor, NGCF, underscores a critical lesson: for the specific task of collaborative filtering, targeted simplicity often trumps general-purpose complexity. For engineers, this highlights the non-negotiable importance of benchmarking against simple, well-understood models before investing in more intricate solutions.</p>

<p>Second, the evolution of the field can be seen as a continuous search for more effective optimization objectives and representation learning techniques. The shift from pointwise rating prediction (optimizing RMSE) to pairwise ranking (optimizing with BPR) was a pivotal moment, aligning the machine learning objective more closely with the user-facing task of creating a useful ranked list. More recently, the widespread adoption of self-supervised contrastive learning in both sequential (CL4SRec) and graph-based (SGL, SimGCL) models has proven to be a powerful technique for learning robust representations from sparse and noisy data, acting as a potent regularizer and helping to mitigate issues like popularity bias.</p>

<p>Third, the convergence of recommender systems with other domains of AI, particularly Natural Language Processing and Computer Vision, has been a primary engine of innovation. The adoption of RNNs, CNNs, and Transformers for sequential recommendation demonstrates a conceptual reframing of user behavior modeling as a language modeling task. Similarly, the use of multimodal models like CLIP, which learn from natural language supervision, shows that the foundation for rich, content-aware recommendation lies in creating well-aligned, shared embedding spaces across different data types.</p>

<p>Finally, the emergence of Large Language Models is not merely an incremental advance but a potential paradigm shift. LLMs are being explored in a multitude of roles: as powerful feature extractors, as zero-shot generative recommenders, as the reasoning engine in RAG-based systems, and as the core of autonomous, tool-using agents. This trajectory points toward a future where the lines between interaction-driven, text-driven, and multimodal recommendation blur. The ultimate recommender system may not be a single model but a sophisticated, conversational agent that can understand multimodal user queries, reason about complex needs, retrieve and synthesize information from diverse external sources, generate personalized and multimodal recommendations, and explain its reasoning in a transparent, interactive dialogue. Navigating this future will require a deep understanding of the foundational principles outlined in this survey, coupled with a readiness to embrace the new generative and agentic paradigms that are beginning to redefine the field.</p>]]></content><author><name>Rauf Aliev</name></author><category term="Recommender Systems" /><category term="Collaborative Filtering" /><category term="Content-Based Filtering" /><category term="Hybrid Recommenders" /><category term="Matrix Factorization" /><category term="Personalized Ranking" /><category term="Recommendations" /><category term="Retrieval-Augmented Generation (RAG)" /><category term="Generative Search" /><category term="Multimodal Search (Text, Image, Audio)" /><category term="Algorithms &amp; Models" /><category term="Embeddings (Word2Vec, GloVe, etc.)" /><category term="Transformers" /><category term="BERT" /><category term="Dense Retrieval" /><category term="Graph Algorithms" /><category term="Ranking" /><category term="Information Retrieval (IR)" /><summary type="html"><![CDATA[This paper provides a systematic and exhaustive review of recommendation algorithms, charting their evolution from foundational collaborative filtering techniques to the sophisticated deep learning and generative models of the modern era. We organize the landscape into three primary categories based on the dominant data modality: Interaction-Driven, Text-Driven, and Multimodal algorithms. For each paradigm and its key algorithms, we distill the core concepts, highlight key differentiators, identify primary use cases, and offer practical guidance for implementation. Our analysis reveals a recurring tension between model complexity and performance, the transformative impact of self-supervised learning, and the paradigm-shifting potential of Large Language Models. This survey is intended as a cornerstone reference for engineers and researchers seeking to navigate the complex, dynamic, and powerful field of recommender systems.]]></summary></entry><entry><title type="html">The Challenges of Chinese and Japanese Searching</title><link href="https://www.testmysearch.com/blog/2025/09/03/chinese-japanese-search.html" rel="alternate" type="text/html" title="The Challenges of Chinese and Japanese Searching" /><published>2025-09-03T00:00:00-04:00</published><updated>2025-09-03T00:00:00-04:00</updated><id>https://www.testmysearch.com/blog/2025/09/03/chinese-japanese-search</id><content type="html" xml:base="https://www.testmysearch.com/blog/2025/09/03/chinese-japanese-search.html"><![CDATA[<p>Today I want to talk about tailoring website search functionality for Chinese and Japanese languages. When it comes to entering “the East”, companies often face many challenges they could not have experienced before. Everything is different in China and Japan including the way how websites are built and how the users interact with them. In this article, I will cover one aspect of these challenges: how to adapt product/content search to work with Japanese and Chinese languages.</p>

<p>Read/Download PDF: <a href="/pdfs/2025-09-03-chinese-japanese-search.pdf">PDF version</a></p>

<p>Before I start, I thank my colleagues for their help in reviewing linguistic details and extending the analysis. I am grateful to <strong>Timofey Klyubin</strong> for expertise in Japanese and to <strong>Dmitry Antonov</strong> for valuable feedback, practical tips, and pointers on Chinese.</p>

<h2 id="table-of-contents">Table of Contents</h2>
<ul>
  <li><a href="#Introduction">Introduction</a></li>
  <li><a href="#LanguageDetection">Language Detection</a></li>
  <li>Language Variants
    <ul>
      <li><a href="#Dialects">Dialects</a></li>
      <li><a href="#Scripts">Scripts</a></li>
    </ul>
  </li>
  <li><a href="#CharacterVariants">Character Variants</a></li>
  <li><a href="#Conversion">Conversion Between the Systems</a></li>
  <li><a href="#WordSegmentation">Word Segmentation</a>
    <ul>
      <li><a href="#ChineseTokenizers">Chinese Tokenizers</a>
        <ul>
          <li><a href="#CJKAnalyzer">CJKAnalyzer</a></li>
          <li><a href="#SmartChineseAnalyzer">Smart Chinese Analyzer</a></li>
          <li><a href="#HanLPTokenizer">HanLPTokenizer</a></li>
        </ul>
      </li>
      <li><a href="#JapaneseTokenizers">Japanese Tokenizers</a>
        <ul>
          <li><a href="#JapaneseTokenizer">JapaneseTokenizer (Kuromoji)</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#WordNormalization">Word Normalization</a>
    <ul>
      <li><a href="#SolrFilters">Solr Filters for Chinese and Japanese</a>ф
        <ul>
          <li><a href="#JapaneseIterationMarks">Japanese Iteration Marks</a></li>
          <li><a href="#HalfWidthFilter">HalfWidth Filter</a></li>
          <li><a href="#JapaneseBaseFormFilter">Japanese Base Form Filter</a></li>
          <li><a href="#JapaneseNonMeaningfulTermsRemovalFilter">Japanese Non-meaningful Terms Removal Filter</a></li>
          <li><a href="#JapaneseKatakanaStemming">Japanese Katakana Stemming</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#Numerals">Numerals</a></li>
  <li><a href="#Synonyms">Synonyms</a></li>
  <li><a href="#Homophones">Homophones</a></li>
  <li><a href="#SearchByPronunciation">Search by Pronunciation</a></li>
  <li><a href="#PunctuationMarks">Punctuation marks</a></li>
  <li><a href="#SearchUI">Search UI observations</a>
    <ul>
      <li><a href="#ReviewedChineseStores">Reviewed Chinese Online Stores</a></li>
      <li><a href="#ReviewedJapaneseStores">Reviewed Japanese Online Stores</a></li>
      <li><a href="#InputMethods">Quick Overview of Chinese and Japanese Input Methods</a></li>
      <li><a href="#LessSearch">Less search, more navigation</a></li>
      <li><a href="#VoiceSearch">Voice search</a></li>
      <li><a href="#ContextAwareQueryRecommendations">Context-aware query recommendations</a></li>
      <li><a href="#VisualSearch">Visual search</a></li>
      <li><a href="#FacetPanel">Facet panel</a></li>
    </ul>
  </li>
  <li><a href="#Recommendations">Recommendations</a>
    <ul>
      <li><a href="#WebTypography">Web typography recommendations</a></li>
    </ul>
  </li>
</ul>

<hr />
<p><a id="Introduction"></a></p>
<h2 id="introduction">Introduction</h2>
<p>There are three languages traditionally considered together in the context of information retrieval, internationalization, and localization. These languages are Chinese, Japanese, and Korean. Their writing systems are based entirely or partly on Chinese characters.</p>

<p>This research can be useful for the internationalization, localization and information retrieval components and projects. Internationalization is mainly about support for multiple languages and cultures. Localization stands for adaptation of language, content, and design to specific countries, regions, or cultures. Cross-lingual information retrieval deals with documents in one or more different languages, and the techniques for indexing, searching, and retrieving information from large multi-language collections.</p>

<p>From the perspective of information retrieval, the Chinese and Japanese present numerous challenges. The major issue is their highly irregular orthography and language variants. In this article, I collected the most important ones we need to take into account when implementing the language-aware full text search as well as how to address them.</p>

<hr />
<p><a id="LanguageDetection"></a></p>
<h2 id="language-detection">Language Detection</h2>
<p>When and where possible, the website should allow the user to specify unambiguously what language is going to be used for entering a search query and presenting the results. Normally, the users enter search queries in the same language as the website’s interface is set to.</p>

<p>However, our observations show that the customers use their native language if the website is advertised in their country even if the localized version of the website is not pre-selected, automatically or manually. If the first-level domain is from the local pool (.cn for China or .jp for Japan), the user’s intent of using the native language is even stronger. To address this case, there are AI and statistical techniques to determine the likely language.</p>

<p>The automatic language detection is a very challenging task especially if the analyzed string is short. For example, if it is has a mix of Latin and Chinese characters from Japanese Kanji set may indicate that the text is either in Japanese or Chinese which can be too abstract.</p>

<hr />
<p><a id="Dialects"></a></p>
<h2 id="language-variants-dialects">Language variants: Dialects</h2>
<p>There are many more dialects in Chinese than Japanese. Both full of specificities interesting to us in regard to the topic.</p>

<p>The thing is Chinese is not a single language, it is a family of spoken languages. China has a lot of dialects, but the most popular is Mandarin (or “Standard Chinese”, over 1 billion speakers) and Cantonese (or Yue, over 100 million of speakers).</p>

<p>In Japan, there are two major types of the Japanese language: the Tokyo-type (or Eastern) and the Kyoto-Osaka type (or Western). The form that is considered the standard is called “Standard Japanese”. Unlike Traditional and Simplified Chinese, the standard Japanese has become prevalent nationwide.</p>

<hr />
<p><a id="Scripts"></a></p>
<h2 id="language-variants-scripts">Language Variants: Scripts</h2>
<h4 id="japanese-kana-and-kanji">Japanese: Kana and Kanji</h4>
<p>There are two typical Japanese scripts, Kana and Kanji.</p>

<ul>
  <li><strong>Kanji</strong> is logographic Chinese scripts, Chinese characters adapted to write Japanese words. There are thousands of kanji in Japanese</li>
  <li><strong>Kana</strong> is a collective term for Japanese syllabaries, Hiragana (46 characters) and Katakana (48 characters). They are derived by simplifying Chinese characters selected to represent syllables of Japanese.</li>
</ul>

<p>The same Japanese word can be written in either kana or kanji:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left"><strong>English word</strong></th>
      <th style="text-align: left"><strong>Japanese (Kanji)</strong></th>
      <th style="text-align: left"><strong>Japanese (Katakana)</strong></th>
      <th style="text-align: left"><strong>Japanese (Hiragana)</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">fox</td>
      <td style="text-align: left">狐</td>
      <td style="text-align: left">キツネ</td>
      <td style="text-align: left">きつね</td>
    </tr>
  </tbody>
</table>

<p>This complexity is also illustrated by the sentence 金の卵を産む鶏 (“A hen that lays golden eggs”). The word ‘egg’ has four variants (卵, 玉子, たまご, タマゴ), ‘chicken’ has three (鶏, にわとり, ニワトリ) and ‘giving birth to’ has two (産む, 生む), which expands to 24 permutations. In many contexts only one option is correct.</p>

<p>Japanese has a large number of loan words or <a href="https://en.wikipedia.org/wiki/Gairaigo">gairaigo</a>. The considerable portion of them is derived from English. In written Japanese, gairaigos are usually written in katakana. Many gairaigos have native equivalents in Japanese. Sometimes a Japanese person can use either a native form or its English equivalent written in katakana. This is especially the case of proper names or science terms. If you are not familiar with the native variant, you will probably use a syllabic construct.</p>

<p>Some examples:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left"><strong>English word</strong></th>
      <th style="text-align: left"><strong>Japanese (native word)</strong></th>
      <th style="text-align: left"><strong>Japanese (English loan word)</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">door</td>
      <td style="text-align: left">扉 /tobira/, 戸 /to/</td>
      <td style="text-align: left">ドア <em>/doa/</em></td>
    </tr>
    <tr>
      <td style="text-align: left">mobile phone/cell phone</td>
      <td style="text-align: left">携帯 /keitai/ – “mobile phone”, “handheld”, 携帯電話 /keitaidenwa/ – “mobile phone”</td>
      <td style="text-align: left">モバイルフォン /mobairufon/, セルラー電話 /serurā denwa/</td>
    </tr>
  </tbody>
</table>

<p>School kids use hiragana more commonly since they might not have learned the kanji equivalents yet.</p>

<p>Additionally, there is Romaji which uses Latin script to represent Japanese.</p>

<h4 id="chinese-traditional-and-simplified">Chinese: Traditional and Simplified</h4>
<p>Along with the sheer complexity and size of the character set, Chinese has several related language variants. In Taiwan, Hong Kong, and Macao, Traditional Chinese characters are predominant over the Simplified Chinese variant which is used mainly in Mainland China, Singapore, and Malaysia.</p>

<p>Some traditional Chinese characters, or derivatives of them, are also found in Japanese writing. So there is a subset of characters common for different languages. These shared Chinese, Japanese, and Korean characters constitute a set named CJK Unified Ideographs. It is huge: the CJK part of Unicode defines a total of 87,887 characters. The characters needed for everyday use by the users is much smaller.</p>

<p>For the search, queries can be in either traditional or simplified characters or a combination of the two; search results should contain all matching resources, whether traditional or simplified.</p>

<p>Below is a random text to demonstrate the differences between the writing systems. Characters highlighted by yellow marker have different spelling in Simplified (输入简体字点下面繁体字按钮进行在线转换) and Traditional (輸入簡體字點下面繁體字按鈕進行在線轉換) Chinese.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-6.39.18-AM.png" alt="Simplified and Traditional Chinese comparison" /></p>

<hr />
<p><a id="CharacterVariants"></a></p>
<h2 id="character-variants">Character variants</h2>
<p>Chinese and Japanese characters don’t use upper or lower cases. They have only a single representation independent of context.</p>

<p>The majority of letters are monospaced.</p>

<p>There are no additional decorations for the letters as it is in Arabic, for example.</p>

<hr />
<p><a id="Conversion"></a></p>
<h2 id="conversion-between-the-systems">Conversion between the systems</h2>
<p>The conversion is important when either a user or a document use a mix of Chinese writing systems. For example, Given a user query 舊小說 (‘old fiction’ in Traditional Chinese), the results should include matches for 舊小說 (traditional) and 旧小说 (simplified characters for ‘old fiction’). That means that conversion should be done at the query level.</p>

<p>The accurate conversion between Simplified Chinese and Traditional Chinese, a deceptively simple but in fact extremely difficult computational task. If your search is used by millions, the system will be much more resource-intensive comparing with the setup for the European languages.</p>

<p>There are three methods of conversion:</p>

<ul>
  <li><strong>Code conversion (codepoint-to-codepoint)</strong>. This method is based on the mapping table and considered as the most unreliable because of the numerous one-to-many mappings (in both directions). The rate of conversion failure is unacceptably high.</li>
  <li><strong>Orthographic conversion</strong>. In this method, the meaningful linguistic units, especially compounds and phrases, are considered. Orthographic mapping tables enable conversion on the word or phrase level rather than the codepoint level. An excellent example is the Chinese word “computer.” (see examples below).</li>
  <li><strong>Lexemic conversion</strong>. A more sophisticated, and more challenging, approach to conversion. In this method, the mapping table contains lexemes that are semantically, rather than orthographically, equivalent. This is similar to the difference between <em>lorry</em> in British English and <em>truck</em> in American English. The complexity of this method in lexemic differences between Simplified and Traditional Chinese, especially in technical terms and proper nouns.</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: left"><strong>Simplified Chinese</strong></th>
      <th style="text-align: left"><strong>Traditional Chinese</strong></th>
      <th style="text-align: left"><strong>Translation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">干</td>
      <td style="text-align: left">幹 or 乾 or 榦</td>
      <td style="text-align: left">(dry, make, surname)</td>
    </tr>
    <tr>
      <td style="text-align: left">电话</td>
      <td style="text-align: left">電話</td>
      <td style="text-align: left">(telephone)</td>
    </tr>
    <tr>
      <td style="text-align: left">软件</td>
      <td style="text-align: left">軟體 (Taiwan)</td>
      <td style="text-align: left">(software)</td>
    </tr>
    <tr>
      <td style="text-align: left">计算机 (“calculating machine”)</td>
      <td style="text-align: left">電脳 (“electronic brain”)</td>
      <td style="text-align: left">(computer)</td>
    </tr>
  </tbody>
</table>

<p>In Japanese, the kanji characters may or may not have the same-looking Chinese character.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left"><strong>Chinese (Simplified)</strong></th>
      <th style="text-align: left"><strong>Chinese (Traditional)</strong></th>
      <th style="text-align: left"><strong>Japanese</strong></th>
      <th style="text-align: left"><strong>Japanese</strong></th>
      <th style="text-align: left"><strong>Translation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">两</td>
      <td style="text-align: left">兩</td>
      <td style="text-align: left">両</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">(both)</td>
    </tr>
    <tr>
      <td style="text-align: left">龟</td>
      <td style="text-align: left">龜</td>
      <td style="text-align: left">亀</td>
      <td style="text-align: left">カメ</td>
      <td style="text-align: left">(tortoise)</td>
    </tr>
  </tbody>
</table>

<p>It is generally believed that the top priority for Chinese discovery improvements is to equate Traditional characters with simplified characters. For Japanese, equating Modern (<em>Shinjitai</em>) and Traditional (<em>Kyūjitai</em>) Kanji is also important—particularly for historical texts, proper nouns, and names—and should not be overlooked in normalization pipelines. There is a priority for Japanese discovery improvements to equate all scripts used in the language: Kanji, Hiragana, Katakana, and Romaji.</p>

<p>In Apache Solr, the only other relevant ICU script translation is a mapping between Hiragana and Katakana. This is a straightforward one-to-one character mapping working in both directions. For context, Apache Solr is a widely used open-source search engine platform; the recommendations below assume familiarity with Solr’s analysis pipeline.</p>

<p>Consider making Simplified Chinese and traditional Chinese inter-searchable. If one searches for 计算机 (computer, Simplified) or 電脳 (computer, Traditional) , the results should contain the records with both 计算机 and 電脳. At least measure how often each of these writing systems is used by your customers to make an educated decision on how to make search better.</p>

<h2 id="word-segmentation">Word segmentation</h2>

<p>Chinese and Japanese are written in a style that does not delimit word boundaries. Typical Chinese sentences include only Chinese characters, along with a select few punctuation marks and symbols. Typical Japanese sentences include mostly Japanese kana and some adopted Chinese characters that are used in the Japanese writing system. So, how does one decide how to break up the words when there are no separators in between?</p>

<p>As for spaces, they delineate words inconsistently and with variation among writers. Formally, there must always be a space between English words and Chinese words, but in fact this rule is not strict and many neglect it. There is no space between the Arabic numbers and Chinese characters.</p>

<p>Coming back to word segmentation, there are different approaches for splitting the text into the word units. The most common algorithms use dictionaries and, additionally, a set of rules. This topic is still an area of considerable research among the machine learning community. All of these are not perfect: this segmentation cannot be done unambiguously, but different methods show acceptable results for the specific areas. For example, for scientific texts, the dictionary-based methods may show poorer results than the statistical or machine-learning.</p>

<p>For example, the word “中华人民共和国” (People’s Republic of China) is seven characters long and has smaller words within: “人民” (people) and “共和国” (republic country). The first two characters,“中华” are usually not be used as a word independently in modern Chinese, though it can be used as a word in ancient Chinese. Digging further, within the word “人民” (people), “人” is a word (human), but “民” (civilian or folk) is not a standalone word. These components can be organized in the hierarchy. As another example, while the proper segmentation of “中华人民共和国外交部” (Ministry of Foreign Affairs of the PRC) is “中华人民共和国 / 外交 部”, another word, “国外” (overseas), could also be erroneously extracted. Consequently, a search for “国 外” should most likely not match the string “中华人民共和国外交部” but a query for “外 交部” should.</p>

<p>A group of characters might be segmented in different ways resulting in different meanings. For example, In Japanese, the compound 造船所 (shipyard) consists of the word 造船 (‘shipbuilding’, 造 is ‘to make, build’ and 船 is ‘a ship’) followed by the suffix 所 which is ‘a place’. In Chinese, the situation is completely the same. There are Chinese jokes based on these ambiguities. Teahan in its “A compression-based algorithm for Chinese word segmentation” illustrates this with the following funny example:</p>

<table>
  <thead>
    <tr>
      <th>A sentence in Chinese</th>
      <th>我喜欢新西兰花</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Interpretation #1</strong></td>
      <td>I like New Zealand flower</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>我</th>
      <th>喜欢</th>
      <th>新西兰</th>
      <th>花</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>I</td>
      <td>like</td>
      <td>New Zealand</td>
      <td>flower</td>
    </tr>
  </tbody>
</table>

<p>| <strong>Interpretation #2</strong> | I like new broccoli |
|—|—|</p>

<table>
  <thead>
    <tr>
      <th>我</th>
      <th>喜欢</th>
      <th>新</th>
      <th>西兰花</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>I</td>
      <td>like</td>
      <td>new</td>
      <td>broccoli</td>
    </tr>
  </tbody>
</table>

<p>(This situation happens only in speaking language. A Chinese writer will use separator 的 to clarify what he means. 我喜欢新的西兰花 for the case 1 And 我喜欢新西兰的花 for the case 2)</p>

<p>The next example illustrates what happens when each character in a query is treated as a single-character word. The intended query is “physics” or “physicist.” The first character returns documents about such things as “evidence,” “products,” “body,” “image,” “prices”; while the second returns documents about “theory,” “barber,” and so on.</p>

<table>
  <thead>
    <tr>
      <th>物理学 means</th>
      <th>物 means</th>
      <th>理 means</th>
      <th>学 means</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Physics</strong></td>
      <td>Physics <br /> Evidence <br /> Products <br /> Price <br /> Body <br /> Image</td>
      <td>Theory <br /> Barber <br /> Science <br /> Reason <br /> Understand <br /> …</td>
      <td>School <br /> Study <br /> Subject <br /> School</td>
    </tr>
  </tbody>
</table>

<p>It creates a lot of irrelevant documents causing the precision of information retrieval to decrease greatly.</p>

<p>So, the challenge is how to extract the meaningful units of knowledge from the text for indexing to return better results at the query phase.</p>

<p>There are three approaches on how to perform text segmentation for indexing and querying:</p>

<ul>
  <li><strong>Unigrams</strong>: treat individual Chinese characters as tokens</li>
  <li><strong>Bigrams</strong>: treat overlapping groups of two adjacent Chinese characters as tokens</li>
  <li><strong>By part of speech or meaningful words</strong>: performs word segmentation and indexes word units as tokens.</li>
</ul>

<p>For example, for the string “我是中国人” (“I’m a Chinese”),</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th><strong>Unigrams</strong></th>
      <th><strong>Bigrams</strong></th>
      <th><strong>Word segmentation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Token 1</strong></td>
      <td>我</td>
      <td>我是</td>
      <td>我 (“I”)</td>
    </tr>
    <tr>
      <td><strong>Token 2</strong></td>
      <td>是</td>
      <td>是中</td>
      <td>是 (“right”)</td>
    </tr>
    <tr>
      <td><strong>Token 3</strong></td>
      <td>中</td>
      <td>中国</td>
      <td>中国 (“China”)</td>
    </tr>
    <tr>
      <td><strong>Token 4</strong></td>
      <td>国</td>
      <td>国人</td>
      <td>人 (“man”)</td>
    </tr>
    <tr>
      <td><strong>Token 5</strong></td>
      <td>人</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>For the string “私は日本人です” (“I’m Japanese”),</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th><strong>Word segmentation</strong></th>
      <th><strong>Meaning</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Token 1</strong></td>
      <td>私</td>
      <td>“I”</td>
    </tr>
    <tr>
      <td><strong>Token 2</strong></td>
      <td>は</td>
      <td>(particle)</td>
    </tr>
    <tr>
      <td><strong>Token 3</strong></td>
      <td>日本人</td>
      <td>“Japanese”</td>
    </tr>
    <tr>
      <td><strong>Token 4</strong></td>
      <td>です</td>
      <td>“am”</td>
    </tr>
  </tbody>
</table>

<p>The third approach is the most challenging. How to extract word units efficiently?</p>

<p>The simplest method is dictionary-based. This is called the <strong>maximum forward match heuristic</strong>. Given a dictionary of frequently used Chinese words, an input string and the indexing text are compared with words in the dictionary to find the one that matches the greatest number of characters. The alternative approach is maximum backward match heuristic when the text scanned in the backward direction. This method is not accurate enough and creates a lot of false matches.</p>

<p>The alternative method is statistical. This method concentrates on two-character words (because two-character is the most common word length in Chinese) and detects the words based on the frequency of characters and bigrams.</p>

<p>In order to improve the process, there are a lot of other methods too. These methods are based on probabilistic automata and machine learning.</p>

<p>The best and the most universal of these methods are included in Apache Solr, and being part of Solr, in SAP Commerce Cloud as well.</p>

<p>Solr supports various methods of word segmentation both for Chinese and Japanese. Each method treats the text differently.</p>

<h3 id="chinese-tokenizers-for-apache-solr-and-sap-commerce-cloud">Chinese: Tokenizers for Apache Solr (and SAP Commerce Cloud)</h3>

<p>For Chinese,</p>

<ul>
  <li><strong>Standard Analyzer</strong>: character-based (unigram-like) tokenization; useful as a baseline.</li>
  <li><strong>ChineseAnalyzer</strong> (deprecated): retained for backward compatibility in older Lucene/Solr versions and not recommended for new deployments.</li>
  <li><strong>CJKAnalyzer</strong>: indexes bigrams; simple and fast, yielding high recall but low precision as noted below.</li>
  <li><strong>SmartChineseAnalyzer</strong> (Simplified Chinese only): dictionary + HMM-based; effective for general Simplified Chinese, but limited for Traditional Chinese and often outperformed by modern third‑party libraries.</li>
  <li><strong>HanLPTokenizer</strong> (<a href="https://github.com/hankcs/hanlp-lucene-plugin">https://github.com/hankcs/hanlp-lucene-plugin</a>, <a href="http://www.hankcs.com/">http://www.hankcs.com/</a>): modern algorithms (e.g., Viterbi) with strong support for both Simplified and Traditional Chinese; requires separate installation/configuration and typically provides higher accuracy at increased operational complexity.</li>
  <li><strong>Paoding</strong> (<a href="https://stanbol.apache.org/docs/trunk/components/enhancer/nlp/paoding">https://stanbol.apache.org/docs/trunk/components/enhancer/nlp/paoding</a>) (legacy/third‑party): an older analyzer that is no longer commonly maintained; generally not recommended for recent Solr versions.
Let’s have a look at how the analyzers split the “我喜欢新西兰花” (from the example above) into terms.</li>
</ul>

<h4 id="chinese-cjkanalyzer">Chinese: CJKAnalyzer</h4>

<p>This analyzer has a simple bigram tokenizer. It indexes every overlapping two-character sequence without linguistic resources (e.g., “中国人” → “中国”, “国人”). In practice, this yields <em>high recall</em> because many queries will find a matching bigram, but <em>low precision</em> because unrelated strings can share bigrams. For example, a search for “京都” (Kyoto) can match “東京都” (Tokyo Metropolis) due to the shared bigram “京都”. Likewise, as discussed earlier, one would not want “国外” to match “中华人民共和国外交部”, but bigramming tends to over‑match in such cases. A common production practice is to index Chinese simultaneously as words and as overlapping bigrams and combine the methods in a weighted fashion to mitigate noise.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image2.png" alt="CJKAnalyzer example" /></p>

<h4 id="chinese-smartchineseanalyzer">Chinese: SmartChineseAnalyzer</h4>

<p>This analyzer has <strong><em>HMMChineseTokenizer</em></strong> which uses probabilistic knowledge to find the optimal word segmentation for <strong>Simplified Chinese</strong> text. The text is first broken into sentences, then each sentence is segmented into words.</p>

<p>Segmentation is based upon the <a href="http://en.wikipedia.org/wiki/Hidden_Markov_Model">Hidden Markov Model</a>.</p>

<p>A large training corpus was used to calculate Chinese word frequency probability.</p>

<p>This analyzer requires a dictionary to provide statistical data. SmartChineseAnalyzer has an included dictionary out-of-box. The included dictionary data is from <a href="http://www.ictclas.org">ICTCLAS1.0</a>.</p>

<p><strong><em>SmartChineseAnalyzer</em></strong> creates four terms (I + like + New Zealand (新西兰) + flower). It performs well on general Simplified Chinese but does not support Traditional Chinese as effectively as modern external libraries.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image3.png" alt="SmartChineseAnalyzer example" /></p>

<h4 id="chinese-hanlptokenizer-viterbi-algorithm">Chinese: HanLPTokenizer: Viterbi Algorithm</h4>

<p>For our example, <strong>HanLPTokenizer</strong> creates six terms (I + like + New Zealand (新西兰) + Zealand(西兰) + flower):</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image4.png" alt="HanLPTokenizer example" /></p>

<p>HanLPTokenizer supports the following algorithms for word segmentation:</p>

<ul>
  <li><strong>Viterbi</strong> (default): The best balance of efficiency and effectiveness. It is also the shortest path word segmentation, and the HanLP shortest path solution uses the Viterbi algorithm.</li>
  <li><strong>Double array trie tree</strong> (dat): Extreme speed dictionary participle, tens of characters per second (may not get part of speech, depending on your dictionary)</li>
  <li><strong>Conditional random field</strong> (crf): segmentation, part-of-speech tagging and named entity recognition accuracy are high, suitable for higher-demand NLP tasks</li>
  <li><strong>Perceptron</strong>: word segmentation, part-of-speech tagging and named entity recognition, support for online learning</li>
  <li><strong>N shortest</strong> (nshort): Named entity recognition is slightly better, sacrificing speed</li>
</ul>

<p>Unlike SmartChineseAnalyzer, HanLPTokenizer can support Traditional Chinese as well. Deployments typically require adding HanLP as an external dependency and managing its models, which increases operational complexity relative to built‑in analyzers.</p>

<h3 id="domain-specific-dictionaries-and-ongoing-maintenance">Domain-Specific Dictionaries and Ongoing Maintenance</h3>

<p>A critical determinant of segmentation quality is the dictionary itself. General-purpose lexicons perform poorly on specialized corpora such as e-commerce product catalogs, biomedical texts, or legal documents. Production systems should plan for:<br />
(1) <em>Domain customization</em>: seed dictionaries with brand names, SKUs, technical terms, and common compounds;<br />
(2) <em>Feedback loops</em>: mine query and click logs to identify unknown terms and mis-segmentations;<br />
(3) <em>Versioning and evaluation</em>: maintain curated releases of dictionaries with regression tests to prevent quality drift.</p>

<p>These practices usually yield larger gains than swapping tokenizers alone, and they are essential regardless of the analyzer chosen.</p>

<h3 id="japanese-tokenizers-for-apache-solr-and-sap-commerce-cloud">Japanese: Tokenizers for Apache Solr (and SAP Commerce Cloud)</h3>

<p>For Japanese,</p>

<ul>
  <li><strong>CJKAnalyzer</strong> indexes bigrams,</li>
  <li><strong>Japanese Tokenizer</strong> splits the text into word units using morphological analysis, and annotates each term with part-of-speech, base form (a.k.a. lemma), reading and pronunciation.</li>
</ul>

<h4 id="japanese-cjkanalyzer">Japanese: CJKAnalyzer</h4>

<p>This analyzer creates bigrams in the same way as shown above for Chinese.</p>

<h4 id="japanese-japanese-tokenizer-kuromoji">Japanese: Japanese Tokenizer (Kuromoji)</h4>

<p>This morphological tokenizer uses a rolling Viterbi search to find the least cost segmentation (path) of the incoming characters.</p>

<p>This tokenizer is also known as Kuromoji Japanese Morphological Analyzer (<a href="https://www.atilika.org/">https://www.atilika.org/</a>)</p>

<p>For our test query “私は日本人です” (“I’m Japanese”), it returns four terms (“I + particle + Japanese + am)</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image5.png" alt="Kuromoji example 1" /></p>

<p>Let’s take a look at a bit more complicated sentence: 韓国に住んでいていい人に聞いた。(I asked a good person, who lives in South Korea). It consists of the following parts:</p>

<table>
  <thead>
    <tr>
      <th><strong>Element</strong></th>
      <th><strong>Pronounced as</strong></th>
      <th><strong>Meaning</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>韓国</td>
      <td>/kankoku/</td>
      <td>“South Korea”</td>
    </tr>
    <tr>
      <td>に</td>
      <td>/ni/</td>
      <td>/grammatical particle/</td>
    </tr>
    <tr>
      <td>住んでいて</td>
      <td>/sundeite/</td>
      <td>the continuous form of the verb 住む meaning “to live”. It consists of two parts: the conjugation 住んで and a special form of the auxiliary verb いて – to be.</td>
    </tr>
    <tr>
      <td>いい</td>
      <td>/ii/</td>
      <td>adjective, meaning “good”.</td>
    </tr>
    <tr>
      <td>人</td>
      <td>/hito/</td>
      <td>“person”</td>
    </tr>
    <tr>
      <td>に</td>
      <td>/ni/</td>
      <td>/grammatical particle/</td>
    </tr>
    <tr>
      <td>聞いた</td>
      <td>/kiita/</td>
      <td>past form of the verb “to ask”</td>
    </tr>
  </tbody>
</table>

<p>The Japanese Tokenizer gives the following output:</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image6.png" alt="Kuromoji example 2" /></p>

<p>So, actually, we have a bit more parts than we should have, but that is really not a bad thing. The key point is that we still have correct base forms of core words of the original phrase, so that the meaning is preserved. Those additional tokens like て and で can be removed during stop-words filter, along with the grammatical particles.</p>

<p>In Japanese, it’s often useful to do the additional splitting of words to make sure you get hits when searching compounds nouns. For example, if you want to search for 空港 (airport) to match 関西国際空港 (Kansai International Airport), the analyzers won’t allow this since 関西国際空港 tend to be a single token meaning this specific airport. This problems is also applicable to katakana compounds such as シニアソフトウェアエンジニア (Senior Software Engineer). For that, the tokenizer supports different modes:</p>

<ul>
  <li><strong>Normal</strong> – regular segmentation</li>
  <li><strong>Search</strong> – use a heuristic to do additional segmentation useful for search</li>
  <li><strong>Extended</strong> – similar to search mode, but also unigram unknown words (experimental)</li>
</ul>

<p>For some applications, it might be good to use search mode for indexing and normal mode for queries to increase precision and prevent parts of compounds from being matched and highlighted.</p>

<h2 id="word-normalization">Word Normalization</h2>

<p>Word normalization refers to the process that maps a word to some canonical form. For example, in English the canonical form for “are”, “is”, and “being” is “be”. This normalization being performed at both index time and query time improves the accuracy of search results.</p>

<p>Solr uses two approaches to normalize word variations:</p>

<ul>
  <li><strong>Stemming</strong>. The approach to reduce the word to its root form.</li>
  <li><strong>Lemmatization</strong>. The identification of the dictionary form of a word based on its context.</li>
</ul>

<h3 id="solr-filters-for-chinese-and-japanese">Solr Filters for Chinese and Japanese</h3>

<h4 id="japanese-iteration-marks">Japanese Iteration Marks</h4>

<p>For stemming in Japanese, Solr provides <strong><em>JapaneseIterationMarkCharFilter</em></strong> which normalizes horizontal iteration marks (々, odoriji) to their expanded form. These marks are used to represent a duplicated character representing the same morpheme. For example, hitobito, “people”, is usually written 人々, using the kanji for 人 with an iteration mark, 々, rather than 人人, using the same kanji twice (this latter is also allowed, and in this simple case might be used because it is easier to write). By contrast, while 日々 hibi “daily, day after day” is written with the iteration mark, as the morpheme is duplicated, 日日 hinichi “number of days, date” is written with the character duplicated, because it represents different morphemes (hi and nichi).</p>

<h4 id="halfwidth-filter">HalfWidth Filter</h4>

<p>By convention, 1/2 Em wide characters are called “halfwidth”; the others are called correspondingly “fullwidth” characters. <strong><em>CJKWidthFilter</em></strong> folds <a href="https://www.htmlsymbols.xyz/ascii-symbols/fullwidth-ascii-variants">fullwidth ASCII variants</a> into the equivalent basic latin (“ＩｊＩ” -&gt; “IjI”) and <a href="https://en.wikipedia.org/wiki/Half-width_kana">halfwidth Katakana variants</a> into the equivalent Japanese kana (ｶ -&gt; カ).</p>

<h4 id="japanese-base-form-filter">Japanese Base Form Filter</h4>

<p><em>JapaneseBaseFormFilter</em> reduces inflected Japanese verbs and adjectives to their base/dictionary forms.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image7.png" alt="Japanese Base Form Filter example" /></p>

<p>For example, for the phrase “それをください。” (That one, please.), the tokenizer will combine last characters together into a polite form of “ください” (“please do for me”). The BaseFormFilter converts it into the base form, “くださる”.</p>

<table>
  <thead>
    <tr>
      <th><strong>Before</strong></th>
      <th><strong>After</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ください</td>
      <td>くださる</td>
    </tr>
  </tbody>
</table>

<h4 id="japanese-non-meaningful-terms-removal-filter">Japanese Non-meaningful Terms Removal Filter</h4>

<p><em>JapanesePartOfSpeechStopFilterFactory</em> removes token with certain part-of-speech tags (created by the JapaneseTokenizer). For example, “を”, the direct object particle, will be removed by this filter from the token stream.</p>

<table>
  <thead>
    <tr>
      <th><strong>Before</strong></th>
      <th><strong>After</strong></th>
      <th><strong>Comments</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>(それ), (を), (ください)</td>
      <td>(それ), (ください)</td>
      <td>“を” is an auxiliary word, a Japanese particle. It is attached to the end of a word それ to signify that that word is the direct object of the verb.</td>
    </tr>
  </tbody>
</table>

<h4 id="japanese-katakana-stemming">Japanese Katakana Stemming</h4>

<p><em>JapaneseKatakanaStemFilter</em> normalizes common katakana spelling variations ending in a long sound character (U+30FC, “ー “) by removing the long sound character. Only katakana words longer than four characters are processed.</p>

<p>For example, for the phrase “明後日パーティーに行く予定がある。図書館で資料をコピーしました。” (“I plan to go to a party the day after tomorrow. I copied the materials in the library.”), the word パーティー (“party”) has a long sound character in the middle and at the end. The ending symbol is removed by this filter.</p>

<table>
  <thead>
    <tr>
      <th><strong>Before</strong></th>
      <th><strong>After</strong></th>
      <th><strong>Comments</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>パーティー</td>
      <td>パーティ</td>
      <td>This word is “party”. It is borrowed from English.</td>
    </tr>
    <tr>
      <td>コピー</td>
      <td>コピー</td>
      <td>Shorter than 4</td>
    </tr>
  </tbody>
</table>

<h2 id="apache-solr-processing-flow-for-japanese">Apache Solr processing flow for Japanese</h2>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/schem1.png" alt="Solr processing flow for Japanese" /></p>

<h2 id="apache-solr-processing-flow-for-chinese">Apache Solr Processing Flow for Chinese</h2>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/chinese-japanese.png" alt="Solr processing flow for Chinese" /></p>

<h2 id="numerals">Numerals</h2>

<p>In Japan and China, most people and institutions primarily use Arabic numerals. Chinese numerals in the web forms are used too (both in China and Japan) but much less frequently. However, this does not rule out the necessity to support Chinese and Japanese specifics in using numerals.</p>

<p>For Chinese, it is obvious that combinations of numbers and characters can be used, but it is preferred to use the shortest written way:</p>

<table>
  <thead>
    <tr>
      <th><strong>English</strong></th>
      <th><strong>preferable</strong></th>
      <th><strong>secondary preferable</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>one</td>
      <td>一</td>
      <td> </td>
    </tr>
    <tr>
      <td>two</td>
      <td>二</td>
      <td> </td>
    </tr>
    <tr>
      <td>tree</td>
      <td>三</td>
      <td> </td>
    </tr>
    <tr>
      <td>one thousand</td>
      <td>一千</td>
      <td> </td>
    </tr>
    <tr>
      <td>ten thousands</td>
      <td>一万</td>
      <td> </td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>一</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2</td>
      <td>二</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3</td>
      <td>三</td>
    </tr>
    <tr>
      <td>10</td>
      <td>十</td>
      <td>10</td>
    </tr>
    <tr>
      <td>100</td>
      <td>100</td>
      <td>一百</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>一千</td>
      <td>1000</td>
    </tr>
    <tr>
      <td>1500</td>
      <td>1500</td>
      <td>一千五</td>
    </tr>
    <tr>
      <td>2000</td>
      <td>2千</td>
      <td>两千</td>
    </tr>
    <tr>
      <td>10000</td>
      <td>一万</td>
      <td> </td>
    </tr>
    <tr>
      <td>100000</td>
      <td>十万</td>
      <td> </td>
    </tr>
    <tr>
      <td>25000000</td>
      <td>2500万</td>
      <td>两千五百万</td>
    </tr>
  </tbody>
</table>

<p>Japanese numerals are often written using a combination of kanji and Arabic numbers with various kinds of punctuation. For example, ３．２千 means 3200. Other examples are listed in the table below.</p>

<p>Apache Solr comes with the <em>JapaneseNumberFilter</em> which normalizes Japanese numbers to regular Arabic decimal numbers. This filter does this kind of normalization and allows a search for 3200 to match ３．２千 in text, but can also be used to make range facets based on the normalized numbers and so on.</p>

<p>The table below shows the examples of conversions supported by the JapaneseNumberFilter:</p>

<table>
  <thead>
    <tr>
      <th><strong>Before</strong></th>
      <th><strong>After</strong></th>
      <th><strong>Comments</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>〇〇七</td>
      <td>7</td>
      <td><a href="https://en.wiktionary.org/wiki/%E3%80%87">〇</a> <em>(maru) is the same as numeral 0 in English.</em></td>
    </tr>
    <tr>
      <td>一〇〇〇</td>
      <td>1000</td>
      <td> </td>
    </tr>
    <tr>
      <td>三千2百２十三</td>
      <td>3223</td>
      <td> </td>
    </tr>
    <tr>
      <td>兆六百万五千</td>
      <td>1000006005001</td>
      <td> </td>
    </tr>
    <tr>
      <td>３．２千</td>
      <td>3200</td>
      <td>千 means 1000 <br /> “．” is a double-byte point</td>
    </tr>
    <tr>
      <td>１．２万３４５．６７</td>
      <td>12345.67</td>
      <td> </td>
    </tr>
    <tr>
      <td>4,647.100</td>
      <td>4647.1</td>
      <td>“,” is ignored (removed)</td>
    </tr>
    <tr>
      <td>15,7</td>
      <td>157</td>
      <td>“,” is ignored (removed)</td>
    </tr>
    <tr>
      <td>2,500万</td>
      <td>25000000</td>
      <td>万 means 10000</td>
    </tr>
  </tbody>
</table>

<p>The last example shows one of the weaknesses of the filter you need aware of. Commas are almost arbitrary and mean nothing.</p>

<p>This filter may in some cases normalize tokens that are not numbers. For example, 田中京一 is a name and means Tanaka Kyōichi, but 京一 (Kyōichi) out of context can strictly speaking also represent the number 10000000000000001. This filter respects the KeywordAttribute which can be used to prevent specific normalizations from happening.</p>

<p>Japanese formal numbers (daiji), accounting numbers and decimal fractions are currently not supported by the filter.</p>

<h2 id="synonyms">Synonyms</h2>

<p>In Japanese, as well as in many other languages, for the same concept you can find more than one word:</p>

<table>
  <thead>
    <tr>
      <th><strong>Concept: to cause to die</strong> <br /> <strong>English:</strong></th>
      <th><strong>Japanese:</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>to kill</td>
      <td>殺す</td>
    </tr>
    <tr>
      <td>to commit murder</td>
      <td>殺人を犯す</td>
    </tr>
    <tr>
      <td>to murder</td>
      <td>殺害する</td>
    </tr>
    <tr>
      <td>to shoot to death</td>
      <td>射殺する</td>
    </tr>
    <tr>
      <td>to assassinate</td>
      <td>暗殺する</td>
    </tr>
    <tr>
      <td>to execute</td>
      <td>処刑する</td>
    </tr>
  </tbody>
</table>

<p>Apache Solr supports synonyms, but the dictionary of the synonymous words is user-defined.</p>

<h2 id="homophones">Homophones</h2>

<p>Homophones are one of two or more words that are pronounced the same but differ in writing and usually in meaning. In English, the examples are “principal” and “principle”.</p>

<p>Jack Halpern in “The Complexities of Japanese Homophones” illustrates this with the phrase “A Mansion with no Sunshine”. There are twelve legitimate ways (some more likely than others) of how to write this:</p>

<ul>
  <li>日の差さない屋敷 (standard dictionary form)</li>
  <li>日の射さない屋敷</li>
  <li>日のささない屋敷</li>
  <li>日の射さない邸</li>
  <li>日の差さない邸</li>
  <li>日のささない邸</li>
  <li>陽の射さない屋敷</li>
  <li>陽の差さない屋敷</li>
  <li>陽のささない屋敷</li>
  <li>陽の射さない邸</li>
  <li>陽の差さない邸</li>
  <li>陽のささない邸</li>
</ul>

<p>Halpern surveyed six native Japanese speakers, some of whom are professional translators and writers, asking them how they would write the above phrase. He reports that there were six different answers, none of which matched the “standard” form found in dictionaries.</p>

<p>Japanese has orthographic variants based on phonetic substitution. Jack Halpern in its “<a href="http://www.cjk.org/cjk/joa/joapaper.htm#2">The Challenges of Intelligent Japanese Searching</a>” mentioned the following example of that: 盲 is interchangeable with 妄 in such compounds as 妄想 (=盲想) ‘wild idea’, but not in 盲従 moojuu ‘blind obedience’.</p>

<p>Every written Japanese and Chinese word has at least two completely different spellings.</p>

<p>Such diversity naturally causes diversity in the ways how users formulate the query.</p>

<p>Because of a small stock of phonemes in Japanese and Chinese, the number of homophones is very large. Since many homophones are nearly synonymous or even identical in meaning, they are easily confused.</p>

<p>You need to have a semantically classified database of homophones to implement cross-homophone searching. The major issue is that for many homophones, a universally-accepted orthography does not exist. The choice of character should be based on meaning, but in fact it is often unpredictable and governed by the personal preferences of the writer.</p>

<p>For example, Jack Halpern in “The Complexities of Japanese Homophones” illustrates this problem with the following example:</p>

<table>
  <thead>
    <tr>
      <th><strong>English</strong></th>
      <th><strong>Standard</strong></th>
      <th><strong>Sometimes</strong></th>
      <th><strong>Often also</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>to offer</td>
      <td>差す</td>
      <td>さす</td>
      <td> </td>
    </tr>
    <tr>
      <td>to hold up</td>
      <td>差す</td>
      <td>さす</td>
      <td> </td>
    </tr>
    <tr>
      <td>to pour into</td>
      <td>差す</td>
      <td>注す</td>
      <td>さす</td>
    </tr>
    <tr>
      <td>to color</td>
      <td>差す</td>
      <td>注す</td>
      <td>さす</td>
    </tr>
    <tr>
      <td>to shine on</td>
      <td>差す</td>
      <td>射す</td>
      <td>さす</td>
    </tr>
    <tr>
      <td>to aim at</td>
      <td>指す</td>
      <td>差す</td>
      <td> </td>
    </tr>
    <tr>
      <td>to point to</td>
      <td>指す</td>
      <td>さす</td>
      <td> </td>
    </tr>
    <tr>
      <td>to stab</td>
      <td>刺す</td>
      <td>さす</td>
      <td> </td>
    </tr>
    <tr>
      <td>to leave unfinished</td>
      <td>さす</td>
      <td>止す</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>Since similar terms can be spelled different ways, people sometimes purposely use the wrong Kanji because it took too long to type a proper one. The local and global Internet search services (Google Japan, Baidu, Google Hong Kong, and others) can handle such cases. The users are getting used to such a response and use the same pattern at the websites. The search engines integrated into the e-stores are not so smart and the search results aren’t going to be as fruitful.</p>

<table>
  <thead>
    <tr>
      <th><strong>Synonym</strong></th>
      <th><strong>Synonym</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>fox</td>
      <td>フォックス</td>
    </tr>
    <tr>
      <td> </td>
      <td>キツネ</td>
    </tr>
  </tbody>
</table>

<h2 id="search-by-pronunciation">Search by pronunciation</h2>

<p>In Japanese, the pronunciation is directly mapped to the written words. For example, Google, when searching by “とうきょうえ” (tōkyōe) correctly suggests “東京駅” (<strong>tōkyōe</strong>ki) (Tokyo station). While they are written in completely different characters, their pronunciation starts with the same syllables. And the other reason is that this is how Japanese people type: they type words in hiragana and then convert them to kanji or katakana by pressing a hotkey several times until the desired conversion variant is in place.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image8.png" alt="Google suggest for Japanese pronunciation" /></p>

<p>Another example, searching for 京都大学図書館 – “Kyoto University Library”</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image9.png" alt="Kyoto University Library search" /></p>

<h2 id="punctuation-marks">Punctuation marks</h2>

<p>There are punctuation marks specific for Japanese and Chinese. Some of them have similar-looking equivalents in European languages which are not always interchangeable.</p>

<table>
  <thead>
    <tr>
      <th><strong>Punctuation marks</strong></th>
      <th><strong>Example</strong></th>
      <th><strong>Explanation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>〜</td>
      <td>1〜2</td>
      <td>Wavy dash, for ranges</td>
    </tr>
    <tr>
      <td><strong>。</strong></td>
      <td> </td>
      <td>Full stop (=”.”)</td>
    </tr>
    <tr>
      <td><strong>、</strong></td>
      <td>a、b、c</td>
      <td>Enumeration comma</td>
    </tr>
    <tr>
      <td><strong>「　」</strong></td>
      <td>「あいうえお」</td>
      <td>The Japanese equivalent of quotation marks (“”) in other languages.</td>
    </tr>
    <tr>
      <td><strong>・</strong></td>
      <td>ジョン・ドゥ /John Doe/</td>
      <td>Japanese specific: 中点(<em>nakaten</em>) is used to indicate a break in foreign names and phrases. Most commonly it is placed between the first name and the last name written in katakana.</td>
    </tr>
  </tbody>
</table>

<h2 id="search-ui-observations">Search UI observations</h2>

<h3 id="reviewed-chinese-online-stores">Reviewed Chinese Online Stores</h3>

<ul>
  <li><a href="http://suning.com">Suning.com</a>.</li>
  <li><a href="http://gome.com.cn">Gome.com.cn</a></li>
  <li><a href="http://taobao.com">Taobao.com</a></li>
  <li><a href="http://tmall.com">Tmall.com</a></li>
  <li><a href="http://jd.com">Jd.com</a></li>
  <li><a href="http://vip.com">Vip.com</a></li>
  <li><a href="http://dangdang.com">Dangdang.com</a></li>
  <li><a href="http://fanli.com">Fanli.com</a></li>
  <li><a href="http://ly.com">Ly.com</a></li>
  <li><a href="http://1688.com">1688.com</a></li>
  <li><a href="http://zhe800.com">Zhe800.com</a></li>
  <li><a href="http://mizhe.com">mizhe.com</a></li>
</ul>

<h3 id="reviewed-japanese-online-stores">Reviewed Japanese Online Stores</h3>

<ul>
  <li><a href="http://rakuten.co.jp">Rakuten.co.jp</a></li>
  <li><a href="http://zozo.jp">zozo.jp</a></li>
  <li><a href="http://wowma.jp">Wowma.jp</a></li>
  <li><a href="http://qoo10.jp">Qoo10.jp</a></li>
  <li><a href="https://www.mercari.com/jp/">mercari.com/jp/</a></li>
  <li><a href="http://fril.jp">Fril.jp</a></li>
  <li><a href="http://minne.com">Minne.com</a></li>
  <li><a href="http://kakaku.com">Kakaku.com</a></li>
  <li><a href="http://dmm.com">Dmm.com</a></li>
</ul>

<p>There are some points which are differently valued by users when compared with western user interface design.</p>

<p>Chinese and Japanese websites have much less negative space, tiny images (and few of them), and a totally different content presentation with a focus on content rather than on its style. The density of information is higher than we got used to dealing with. Possibly , this layout style is connected to Kanban culture with its tendency to content efficiency: placing a maximum amount of content within a minimum space.</p>

<h3 id="chinese-and-japanese-input-methods">Chinese and Japanese Input Methods</h3>

<h4 id="text-input-in-chinese">Text Input in Chinese</h4>

<p>Chinese websites rely on different ways of input in Chinese characters: Pinyin (a system of Latin transcription of Chinese characters), Sequence of Strokes, Wubi (5 Basic Strokes), Handwriting, Image recognition, and voice input. The computer converts the Pinyin spelled, handwritten, captured or voiced sentence into the correct Chinese character sequence on the screen. Below is functionality offered by the default Chinese version of Android (I should say that it matches input methods in windows):</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-7.54.54-AM.png" alt="Chinese input methods on Android" /></p>

<p>Below I tried to input 2 characters (十 – ten and 百 – hundred) by using a different method.</p>

<p><strong>Wubi (5 strokes).</strong> Wubi is the fastest method, but the most challenging. With Wubi, all characters can be written reliably with no more than 5 keystrokes. The method requires only 2 clicks on a keyboard to spell most of the characters. But it requires to memorize a table to map strokes to keys on keyboard. Pinyin knowledge is not required, so it is widely used among Chinese who don’t know Pinyin.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-7.56.13-AM.png" alt="Wubi input method" /></p>

<p><strong>Pinyin (with 26 English keys).</strong> Pinyin the slowest method, I clicked 4 times before I go get each of the characters. Once a word has been typed in Pinyin, the computer will suggest words matching this pronunciation in a pop-up window. Selecting the intended word from the list can slow down the typing process considerably. But this method is commonly used among young generation who usually learn Pinyin at school. Also, the most popular method among foreigners, because it doesn’t require large vocabulary.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-7.56.13-AM-1.png" alt="Pinyin input method" /></p>

<p><strong>Handwriting.</strong> This method is widely used among them who don’t know Latin alphabets or by those who enjoy calligraphy.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-7.58.03-AM.png" alt="Handwriting input method" /></p>

<p><strong>Stroke sequence.</strong> This method is widely used among them who don’t know Latin alphabets and not that good with handwriting. Originally method used in traditional mobile phones with small non-responsive screens. As far as strokes are grouped, the sequence might be long which slows down the process.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-7.58.57-AM.png" alt="Stroke sequence input method" /></p>

<p><strong>Image recognition</strong>. This method is great for the larger amount of data, doesn’t require any special knowledge.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-8.00.34-AM.png" alt="Image recognition input method" /></p>

<p><strong>Voice recognition</strong></p>

<p>Quite popular in China, but the methodology is facing a challenge because of many variant dialects causing pronunciation differences. Voice recognition projects are presumingly supported by the government as part of countrywide Putonghua popularization. Dmitry Antonov: “In my case, it used Baidu engine (AI/ML) and it smartly returned me it’s brand name Baidu when I pronounced “bai” – hundred in Pinyin, so it is commercialized advertising?”.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-8.01.37-AM.png" alt="Voice recognition input method" /></p>

<h4 id="text-input-in-japanese">Text Input in Japanese</h4>

<p>There are two main methods of inputting Japanese: Romaji, via a romanized version of Japanese, and Kana. The keyboards sold in Japan usually look like this:</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image10.png" alt="Japanese keyboard layout" /></p>

<p>The primary input method is typing words by their reading in kana and then convert them to kanji. For example, let’s see how to type phrase 日本語を勉強するのが好きです — “I like studying Japanese”.</p>

<ol>
  <li>
    <p>You type your sentence in hiragana first, at this step it looks like this:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image011.jpg" alt="Typing in Hiragana" /></p>
  </li>
  <li>
    <p>Then you press the conversion key and it converts the current word to the kanji or katakana representation. Because there are many homonyms, often you will see the little window pop up with a list of conversion variants. It looks like this:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image012.jpg" alt="Converting Hiragana to Kanji" /></p>
  </li>
  <li>
    <p>Then you convert each part until you get the needed result.</p>
  </li>
</ol>

<p>On a typical Japanese keyboard there are five helper keys:</p>

<ul>
  <li>変換 — /henkan/, meaning “conversion”. Converts kana to kanji.</li>
  <li>無変換 — /muhenkan/, “no conversion”. Leaves the kana as it is.</li>
  <li>かな, or simply “kana” — kana mode. Also there may be keys for specific kana modes: ひらがな(hiragana), カタカナ(katakana) or ローマ字(romaji).</li>
  <li>英数 — /eisu/, alphanumeric mode.</li>
  <li>半角/全角 — /hankaku, zenkaku/, half-width and full-width mode for inputting latin characters.</li>
</ul>

<p>If one doesn’t have a keyboard with kana support, they can type in romaji. The process is exactly the same, except the first step: instead of typing hiragana directly, you type kana readings in romaji and they are automatically converted into hiragana:</p>

<ol>
  <li><img src="https://hybrismart.com/wp-content/uploads/2019/08/image013.jpg" alt="Typing Romaji" /></li>
  <li><img src="https://hybrismart.com/wp-content/uploads/2019/08/image014.jpg" alt="Romaji converted to Hiragana" /></li>
</ol>

<p><strong>Less search, more navigation</strong></p>

<p>It is common to find the search field a lot less highlighted on the Japanese and Chinese websites. According to Alex Zito-Wolf, “<a href="https://medium.com/@alexzitowolf/chinese-ui-trends-mobile-application-text-search-flows-4884d5f688a">Chinese UI Trends</a>”, Chinese apps and websites tend to prioritize navigation over search. With the Japanese keyboard, it takes about 20+ keypresses to type a few Japanese characters, so it is often faster to get to a particular link than typing something in search.</p>

<p>Zito-Wolf also highlights that many apps use a focus page which is activated once the user clicks on the search bar. The author believes that “Chinese apps create strong hooks to allow users to be routed away from using text search at the beginning of the search process,  allowing these users a faster search completion and more time spent browsing other pages.” This focus page contains the tags which are meant to help the user find the fastest way to construct a search, as well as educate them on how to effectively write search queries improving search efficiency in the long run.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image15.png" alt="Suning.com search UI" />
(Suning.com)</p>

<p>The mobile version of Suning.com redirects the user to a designated search page (/search.html) when a user clicks on the search bar.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image16.png" alt="Suning.com mobile search page" /></p>

<p>Zito-Wolf draws attention to the high role of tags in the search process. “For the query 咖啡 (“Coffee”) (…) like a guessing tree, the system starts with broad additional tags, 价格比高 “Good cost/value ratio”, 交通方便 “Convenient transportation” and 就餐空间大 “Spacious atmosphere”.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image17.png" alt="Search tags for coffee query" /></p>

<p><strong>Voice search</strong></p>

<p>The UX/UI Designer Pavlo Plakhotia <a href="https://mlsdev.com/blog/mobile-design-for-chinese-market">notices</a> that the implementation of the voice message function is very common for Chinese mobile design. “Voice control is much easier than manual text input, especially for the older audience, who do not always have sufficient skills to work with mobile applications and various ways of entering the set of Chinese hieroglyphs. At present, there is also a trend among users to exploit voice input for search queries instead of typing.”</p>

<p>Gome.com.cn:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image18.png" alt="Voice search icon" /></p>

<h2 id="context-aware-query-recommendations">Context-aware query recommendations</h2>

<p>Many websites show the context/recommended queries under the search bar. This list depends on context and customer behavior. For example, after searching “iphone”, the system understands that the user wants a mobile phone, and recommends other brands too (Huawei, Samsung, Oppo, Vivo)</p>

<p>Tmail.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image21.png" alt="Tmail recommended queries" /></p>

<p>Dianping.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image22.png" alt="Dianping recommended queries" /></p>

<p>The recommendations can be even placed inside the search box (this is travel e-shop, and recommendations are destinations, Suzhou and Shanghai)
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image23.png" alt="In-box recommendations" /></p>

<p>In Japanese stores there are also related queries (qoo10.jp, the query is “vans”):
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image24.png" alt="Qoo10 related queries" /></p>

<h2 id="visual-search">Visual search</h2>

<p>The trend in more and more shops implement visual search.</p>

<p>1688.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image25.png" alt="1688.com visual search icon" /></p>

<p>JD.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image26.png" alt="JD.com visual search icon" /></p>

<p>The image I used for search:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image27.png" alt="Image used for visual search" /></p>

<p>The results:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image28.png" alt="Visual search results" /></p>

<p><strong>No alpha sorting</strong></p>

<p>In Chinese, there is no meaning to sort the search items or facets by alphabet because there is no alphabet. Theoretically, the items can be sorted by the character’s rendering into Pinyin based on Pinyin alphabetical order in the manner as many dictionaries do.</p>

<p>In other aspects, the search box and search results page follow the general market-agnostic UI/UX recommendations.</p>

<h3 id="facet-panel">Facet panel</h3>

<p>Facets are often arranged horizontally because of the Chinese and Japanese script is much denser. However, that is more a characteristic of Chinese websites:</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image29.png" alt="Horizontal facets example 1" /></p>

<p>Zhe800.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image30.png" alt="Zhe800.com horizontal facets" /></p>

<p>JD.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image31.png" alt="JD.com horizontal facets" /></p>

<p>Gone.com.cn:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image32.png" alt="Gone.com.cn horizontal facets" /></p>

<p>All important facets are open by default, all others are collapsed. You can expand them on hover. In the next screenshot, the facet with the list of tags is opened:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image33.png" alt="Expanded facet tags" /></p>

<p>In Japan, vertical facets are more common:</p>

<p>Rakuten.co.jp:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image34.png" alt="Rakuten vertical facets" /></p>

<p>Zozo.jp:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image35.png" alt="Zozo.jp vertical facets" /></p>

<p>Wowma.jp:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image36.png" alt="Wowma.jp vertical facets" /></p>

<p>Horizontal facets are used too on Japan’s websites, but it is not so common.
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image37.png" alt="Horizontal facets on a Japanese site" /></p>

<h3 id="recommendations">Recommendations</h3>

<p>If your website is available in different language versions, you need to have answers to the following questions:</p>

<ul>
  <li>What languages can be used on what language versions? Can I search in Chinese on the English website and vice versa?</li>
  <li>Can we mix English and Chinese in the same query? It is especially important for brands and proper names (Sony / ソニー).</li>
  <li>What language variants are supported?</li>
</ul>

<h2 id="web-typography-recommendations">Web typography recommendations</h2>

<p>The best line length is 15-40 characters per line (CPL) for the computer display and 15-21 CPL for the smartphone display (~2 times shorter than it is recommended for English)</p>

<p>In Japanese, Serif (with decorative elements) is called “Mincho” (明朝) and Sans-Serif (plain) is called “Gothic” (ゴシック).</p>

<p>In Chinese, the two most commonly used classifications are Song (宋體, 宋体) or Ming (明體 / 明体), which you could think of as the Chinese serif, and hei (黑體 / 黑体), similar to a sans-serif.</p>

<p>In English, the 3rd party font files have a very small impact to the page loading speed because the character set is relatively small. And the designers embed them into the pages. In Chinese and Japanese, extra fonts can be one of the reasons for a slow-loading page.</p>

<p>Italics is technically supported, but it not recommended to use it with Japanese and Chinese characters. It skews them so that they become unreadable.</p>

<p>Don’t use a font size smaller than 12pt. It’s always better to set your font size by “em” or “%” and take the user preferences into account. If your website targets older people, consider 16pt font size.</p>

<p>Meiryo, MS Gothic, MS Mincho, Yu Gothic, and Yu Mincho fonts are pre-installed in Windows. “Hiragino Kaku Gothic ProN” and “Hiragino Mincho ProN” are pre-installed in MacOS. “HiraKakuProN-W3” and “HiraMinProN-W3” are used in iOS.</p>

<p>If you want to get typography better, Noto will be a good solution. Noto is a Google font family that supports all languages including Chinese and Japanese.</p>

<h2 id="conclusions">Conclusions</h2>

<p>In the above, we’ve touched different aspects of Japanese and Chinese searching. We demonstrated that the challenges are addressable. We also demonstrated that the solutions are still evolving and there are always matters outstanding for deeper research.</p>

<p>Because of the complexities and irregularities of the Chinese and Japanese writing systems, you need not only computational linguistic tools such as morphological analyzers, but also lexical databases fine-tuned to the needs of particular project goals and content. Both analyzers and databases are constantly improving, and it is important to keep an eye on the latest breakthroughs in information retrieval and apply them to your solution to keep delivering better user experience and</p>]]></content><author><name>Rauf Aliev</name></author><category term="Relevance" /><category term="Ranking" /><category term="Indexing" /><category term="Query Processing" /><category term="Lexical Search" /><category term="Keyword Search" /><category term="Query Understanding (NLU)" /><category term="Search UI/UX" /><summary type="html"><![CDATA[Today I want to talk about tailoring website search functionality for Chinese and Japanese languages. When it comes to entering “the East”, companies often face many challenges they could not have experienced before. Everything is different in China and Japan including the way how websites are built and how the users interact with them. In this article, I will cover one aspect of these challenges: how to adapt product/content search to work with Japanese and Chinese languages.]]></summary></entry><entry><title type="html">Building Trust in Search and Recommendation</title><link href="https://www.testmysearch.com/blog/2025/09/02/search-trust.html" rel="alternate" type="text/html" title="Building Trust in Search and Recommendation" /><published>2025-09-02T00:00:00-04:00</published><updated>2025-09-02T00:00:00-04:00</updated><id>https://www.testmysearch.com/blog/2025/09/02/search-trust</id><content type="html" xml:base="https://www.testmysearch.com/blog/2025/09/02/search-trust.html"><![CDATA[<p>When we think about search engines or recommender systems, the default measure of quality is often relevance: does the system return what I asked for? Yet over time, it has become clear that accuracy alone does not create confidence. These systems don’t just retrieve information—they curate visibility, shape opportunity, and implicitly set the terms of what users come to rely on. That’s why the discussion has shifted toward a broader question: <strong>can we trust the ranking we see?</strong></p>

<h2 id="why-trust-matters">Why Trust Matters</h2>

<p>Every list of results is a sequence of choices. Which job ad appears at the top? Which track lands in a playlist? Which hotel listing takes the first slot? These choices are not neutral: they reinforce patterns, create feedback loops, and shape expectations. If results feel arbitrary, skewed, or manipulated, user trust erodes quickly.</p>

<p>Researchers have begun to unpack what “trust” in ranking really means. It is not reducible to a single formula. Depending on the domain, trust may be about transparency, consistency, representativeness, or accountability.</p>

<h2 id="beyond-relevance-three-dimensions-of-reliability">Beyond Relevance: Three Dimensions of Reliability</h2>

<p>Traditionally, ranking quality is assessed through three lenses:</p>

<ul>
  <li><strong>Relevance</strong>: Does the result actually answer the query?</li>
  <li><strong>Diversity</strong>: Does the list reflect a breadth of perspectives or options?</li>
  <li><strong>Novelty</strong>: Does each additional item bring new value instead of repeating the obvious?</li>
</ul>

<p>Trustworthiness does not replace these but cuts across them. A ranking may be relevant but still untrustworthy if it seems biased or opaque. It may be diverse but untrustworthy if the underlying process is unclear.</p>

<h2 id="different-contexts-different-notions-of-trust">Different Contexts, Different Notions of Trust</h2>

<p>The contours of trust look different depending on the environment in which ranking operates.</p>

<h3 id="non-personalized-rankings">Non-Personalized Rankings</h3>
<p>When personalization is minimal—say, image search for “CEO”—users expect systems to avoid stereotypes and hidden agendas. Measures like balance in representation or neutrality checks help sustain credibility.</p>

<h3 id="crowd-sourced-trends">Crowd-Sourced Trends</h3>
<p>Trending hashtags or popular local businesses raise questions of manipulation. Users must feel confident that influence is not captured by a handful of coordinated actors. Mechanisms like “one account, one vote” or proportional weighting preserve the sense that rankings emerge from genuine collective activity.</p>

<h3 id="personalized-recommendations">Personalized Recommendations</h3>
<p>In highly personalized settings, users must believe the system is not pigeonholing them or overlooking signals unfairly. Metrics around consistency of treatment across demographic slices, or alignment with individual feedback, are essential for sustaining confidence.</p>

<h3 id="advertising">Advertising</h3>
<p>Ads complicate trust, since users know money changes the order. Still, they expect a degree of clarity: are opportunities surfaced consistently across similar users? Are high-value options only shown to select groups? Trust falters if targeting becomes indistinguishable from exclusion.</p>

<h3 id="marketplaces">Marketplaces</h3>
<p>Here, the trust relationship extends to multiple sides: consumers, providers, and sometimes intermediaries. Riders must believe driver ratings are meaningful; providers must believe the platform doesn’t bury them arbitrarily. Trust mechanisms must be multi-directional.</p>

<h2 id="open-challenges">Open Challenges</h2>

<p>What is striking is that there is no universal recipe for trust. Transparency may work in one domain but overwhelm in another. Neutrality may suit generic search, but personalization depends on selective emphasis. And trust is entangled with diversity and novelty: a highly varied set of results may feel unreliable if it lacks coherence, while a very narrow set may feel manipulated even if it is statistically balanced.</p>

<h2 id="looking-ahead">Looking Ahead</h2>

<p>Platforms are beginning to address these issues explicitly. Efforts range from clearer disclosures in advertising to algorithmic audits of recommendation pipelines. The challenge is cultural as much as technical: trust has to be earned continuously, not declared once.</p>

<p>Search and recommendation are not only about retrieval; they are about shaping how people see the world. Framing evaluation through the lens of trust makes us ask harder questions: not only <em>did the system work</em>, but <em>does it deserve to be believed</em>?</p>]]></content><author><name>Rauf Aliev</name></author><category term="Responsible AI" /><category term="Search Ethics" /><category term="Recommender Systems" /><category term="Recommendations" /><category term="Ranking" /><category term="Relevance" /><category term="Personalization" /><summary type="html"><![CDATA[When we think about search engines or recommender systems, the default measure of quality is often relevance: does the system return what I asked for? Yet over time, it has become clear that accuracy alone does not create confidence. These systems don’t just retrieve information—they curate visibility, shape opportunity, and implicitly set the terms of what users come to rely on. That’s why the discussion has shifted toward a broader question: can we trust the ranking we see?]]></summary></entry></feed>