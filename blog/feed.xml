<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://www.testmysearch.com/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.testmysearch.com/blog/" rel="alternate" type="text/html" /><updated>2025-09-17T14:17:20-04:00</updated><id>https://www.testmysearch.com/blog/feed.xml</id><title type="html">TestMySearch Blog</title><subtitle>The official blog for TestMySearch. Articles and insights on search quality,  information retrieval, and relevance engineering from Rauf Aliev.</subtitle><author><name>Rauf Aliev</name></author><entry><title type="html">Automatic Facet Discovery in E-Commerce Search</title><link href="https://www.testmysearch.com/blog/2025/09/06/facet-discovery.html" rel="alternate" type="text/html" title="Automatic Facet Discovery in E-Commerce Search" /><published>2025-09-06T00:00:00-04:00</published><updated>2025-09-06T00:00:00-04:00</updated><id>https://www.testmysearch.com/blog/2025/09/06/facet-discovery</id><content type="html" xml:base="https://www.testmysearch.com/blog/2025/09/06/facet-discovery.html"><![CDATA[<p>This paper addresses a significant challenge in e-commerce information retrieval: the failure of standard keyword search systems to correctly interpret complex user queries that contain product attributes. Queries such as “blue XL Burton jacket” are often processed as a simple set of keywords, leading to irrelevant results and compelling users to engage in a laborious manual filtering process. We present a proof-of-concept (PoC) for an automatic facet discovery system designed to parse user queries, identify terms corresponding to product facets (e.g., color, brand, size), and apply these filters automatically. This research demonstrates a practical methodology for bridging the semantic gap between unstructured free-text search and structured faceted navigation, thereby enhancing result relevance and improving the overall user experience.</p>

<p>A video demonstration of the system, implemented on the Hybris accelerator platform, is provided below.</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
  <iframe src="https://player.vimeo.com/video/223100657" frameborder="0" allowfullscreen="" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
</div>

<h2 id="1-introduction">1. Introduction</h2>

<p>Faceted search is an integral feature of modern e-commerce platforms, fundamentally improving the user’s search and discovery experience. From a user-centric perspective, faceted navigation decomposes search results into multiple, orthogonal categories (facets), each with corresponding value counts. This paradigm enables users to iteratively refine, or “drill down,” into the result set by applying filters in any desired sequence.</p>

<p>The utility of this functionality is particularly evident when interacting with large-scale product catalogs, as it substantially improves product findability, mitigates user frustration, and provides a structured navigational framework. Furthermore, faceted search architectures programmatically generate relevant landing pages for long-tail keyword queries, a long-standing strategy in search engine optimization that was traditionally accomplished through static category pages.</p>

<h2 id="2-a-taxonomy-of-user-search-queries">2. A Taxonomy of User Search Queries</h2>

<p>Empirical research from the Baymard Institute classifies user search behavior into 12 distinct query types, the majority of which are inadequately supported by out-of-the-box e-commerce search engines.</p>

<ol>
  <li><strong>Exact Searches</strong>: Queries for specific products via title or model number (e.g., <em>Keurig K45</em>).</li>
  <li><strong>Product Type Searches</strong>: Broad queries for product categories (e.g., <em>Sandals</em>).</li>
  <li><strong>Symptom Searches</strong>: Problem-based queries where the user seeks a product as a solution (e.g., <em>“stained rug”</em>).</li>
  <li><strong>Non-Product Searches</strong>: Informational queries regarding policies, company details, or help documentation.</li>
  <li><strong>Feature Searches</strong>: Queries specifying particular product attributes (e.g., <em>Waterproof cameras</em>).</li>
  <li><strong>Thematic Searches</strong>: Queries for abstract or conceptual categories with ill-defined boundaries (e.g., <em>“Living room rug”</em>).</li>
  <li><strong>Relational Searches</strong>: Queries based on a product’s association with another entity (e.g., <em>Movies starring Tom Hanks</em>).</li>
  <li><strong>Compatibility Searches</strong>: Queries for products compatible with another item (e.g., <em>Lenses for Nikon D7000</em>).</li>
  <li><strong>Subjective Searches</strong>: Queries using non-objective, qualitative terms (e.g., <em>“High-quality kettles”</em>).</li>
  <li><strong>Slang, Abbreviation, and Symbol Searches</strong>: Queries employing linguistic shortcuts (e.g., <em>Sleeping bag -10 deg</em>).</li>
  <li><strong>Implicit Searches</strong>: Queries that omit context-dependent qualifiers (e.g., searching <em>Pants</em> when intending <em>Women’s Pants</em>).</li>
  <li><strong>Natural Language Searches</strong>: Queries formulated in complete sentences rather than keyword sets (e.g., <em>Women’s shoes that are red and available in size 7.5</em>).</li>
</ol>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/ecommerce-search-01-query-support-e26a0c0f33559b8702edfe2f626a3dba-1.png" alt="A chart from Baymard.com illustrating the poor support for various e-commerce search query types." /></p>

<p>While platforms such as Hybris provide foundational support for some of these query types, the implementation often lacks the necessary sophistication for accurate intent interpretation. Neither Hybris nor its underlying SOLR search engine can natively associate query terms with semantic concepts like product features or categories. By default, all input is treated as a simple keyword query. The proposed PoC serves as a semantic bridge between these free-text queries and the platform’s powerful faceted search capabilities, thereby addressing many of the aforementioned query types more effectively.</p>

<h2 id="3-the-challenge-with-conventional-faceted-search">3. The Challenge with Conventional Faceted Search</h2>

<p>Conventional faceted search implementations present known usability challenges. Although platforms like Hybris display facets relevant to an initial query, the presence of attribute-related terms within the query itself can paradoxically cause those same facets to be excluded from the results.</p>

<p>For instance, in the query “blue armada jacket XXL,” a standard search engine processes all four terms as a free-text request, returning only documents containing all four keywords. This approach is fundamentally flawed, as product attributes are often stored internally in structured formats or with distinct internal codes, necessitating duplicate index fields for their textual representations.</p>

<p>The primary issue is the significant divergence between search results and user expectations. A query for “blue armada jacket XXL” will retrieve products that simply contain these keywords in their title or description, a limitation that encourages merchants to engage in keyword stuffing to improve findability. This leads to a cumbersome, multi-step user journey to locate a specific product:</p>

<ol>
  <li><strong>Execute initial search</strong>: User enters the query “<em>blue female XL Burton jacket</em>.”</li>
  <li><strong>Apply Color facet</strong>: User locates and selects “blue” from the color facet list.</li>
  <li><strong>Apply Brand facet</strong>: User locates and selects “Burton” from the brand facet list.</li>
  <li><strong>Apply Size facet</strong>: User locates and selects “XL” from the size facet list.</li>
  <li><strong>Apply Gender facet</strong>: User locates and selects “Female” from the gender facet list.</li>
</ol>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/searchimproved10.png" alt="A typical e-commerce interface showing multiple facet categories on a sidebar." /></p>

<p>This iterative process requires multiple user interactions and page reloads. While some platforms like Google Shopping have implemented automatic facet application, this functionality is not standard in most e-commerce solutions.</p>

<p>A default SAP Commerce implementation, for example, yields highly irrelevant results for the query “blue female XL Burton jacket”:</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_21h36_23-1.png" alt="Screenshot of a default Hybris search result page showing irrelevant products." />
<em>How SAP Commerce Cloud works out-of-the-box (the default configuration).</em></p>

<ul>
  <li><strong>Observation</strong>: The results include items that are not jackets, not blue, not for women, and mostly not from the specified brand.</li>
</ul>

<p>In contrast, the proposed PoC delivers highly relevant results for the identical query:</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_21h39_15-1.png" alt="Screenshot of the PoC search result page showing highly relevant, correctly filtered products." />
<em>Performance of the proposed PoC for the query “Blue burton female XL jacket”.</em></p>

<ul>
  <li><strong>Observation</strong>: All resulting products are blue, female jackets from the Burton brand.</li>
</ul>

<p>This performance improvement is consistent across different product domains. For an electronics catalog, the query “fixed camera lenses from canon” on a standard system yields irrelevant products:</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_21h45_27-1.png" alt="Standard Hybris search results for an electronics query, showing incorrect product types." />
<em>Standard SAP Commerce search performance for the query “Fixed camera lens from Canon”.</em></p>

<p>The proposed system, however, correctly identifies and filters for the requested products:</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_21h47_181-1.png" alt="PoC results for the electronics query, showing correctly identified and filtered fixed camera lenses." />
<em>Performance of the proposed PoC for the query “Fixed camera lens from Canon”.</em></p>

<p>The system can also interpret numerical ranges. A query for “5 mp kodak camera” correctly applies a filter for the “5-5.9 Mp” facet range.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_21h54_03.png" alt="The PoC system correctly interpreting a numerical value and applying a corresponding range facet." />
<em>The PoC applying a facet range for the query “5 Mp Kodak camera”.</em></p>

<h2 id="4-implementation-strategy-automatic-vs-suggested-queries">4. Implementation Strategy: Automatic vs. Suggested Queries</h2>

<p>While the PoC implements fully automatic query interpretation, a production deployment would benefit from A/B testing to determine the optimal strategy for a specific business context. Factors such as catalog structure, product diversity, and user profiles should inform this decision.</p>

<p>An alternative, non-automatic approach involves presenting the interpreted query as a one-click suggestion alongside the standard keyword search results.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-26_02h13_24-1.png" alt="A conceptual mockup of a search suggestion panel." /></p>

<p>This method provides user control while still leveraging the benefits of query interpretation. If implemented, the suggestion interface should be designed to be both compact and informative.</p>

<h2 id="5-technical-architecture-and-implementation-details">5. Technical Architecture and Implementation Details</h2>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/searchimproved30.png" alt="A diagram illustrating the system architecture for automatic facet discovery." /></p>

<p>The system operates by analyzing the input query to extract terms that correspond to known facet values. A primary technical challenge is resolving ambiguity when a query contains conflicting or mutually exclusive facet terms. For example, the query “<em>Canon flash memory</em>” is ambiguous if the product catalog contains no flash memory manufactured by Canon. The system must then infer user intent: is the brand “Canon” or the category “Flash memory” the primary constraint?</p>

<p>This ambiguity is resolved when the catalog contains products that satisfy all specified attributes. For instance, if the catalog contains Sony-branded flash memory, the query “<em>Sony Flash Memory 32Gb</em>” is unambiguous, allowing the system to confidently apply facets for brand, category, and storage capacity.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_22h24_20-1.png" alt="The system correctly applying multiple facets for an unambiguous query." /></p>

<p>To facilitate this mapping, the system maintains an in-memory representation of all available facet values. These values are retrieved directly from the SOLR index using its built-in “terms” request handler, which provides an efficient method for obtaining a complete and uniform list of facet terms.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/2017-06-25_22h33_17-1.png" alt="The SOLR terms component response, listing all values for a given facet field." /></p>

<p>For optimal performance, this technique requires SOLR fields configured with a <code class="language-plaintext highlighter-rouge">KeywordTokenizer</code> (to preserve multi-word facet values) and without stemming filters (to ensure exact matching). This can be achieved by creating dedicated, non-stemmed copy fields or by changing the field type to <code class="language-plaintext highlighter-rouge">string</code>, though the latter may have minor implications for full-text search relevance.</p>

<p>The PoC employs an efficient strategy by only processing facets that are returned by an initial standard keyword search, rather than analyzing all possible facets in the entire catalog.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/searchimproved2.png" alt="A diagram showing the two-step process: an initial search returns relevant facets, which are then processed." /></p>

<p>Once terms are mapped to facets, the remaining query words are categorized as stopwords, special commands (e.g., “cheap”), or residual keywords for the free-text search component.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/searchimproved3.png" alt="A diagram illustrating the mapping of query terms to facet values." /></p>

<p>The system then constructs a new, hybrid query combining the discovered facet filters with the remaining keywords.</p>

<p><img src="http://hybrismart.com/wp-content/uploads/2017/06/searchimproved4-1.png" alt="The final stage of query construction, combining facet filters with remaining keywords." /></p>

<p>To handle conflicts where a term matches multiple facets (e.g., “red” as a color vs. part of the brand “Red Hat”), the PoC implements a simple disambiguation logic: it executes a count for each interpretation and proceeds with the option that yields a non-zero result set. If both interpretations are valid, or if both yield zero results, the system defaults to a standard keyword search. More advanced implementations could prompt the user for clarification.</p>

<p>The system is designed to support dynamic facet configurations in SAP Commerce without requiring manual reconfiguration. However, it does not yet handle complex natural language constructs (e.g., “with,” “or,” “without”), which would require more advanced natural language processing techniques.</p>

<h2 id="6-conclusion-and-future-work">6. Conclusion and Future Work</h2>

<p>This paper has presented a proof-of-concept for an automatic facet discovery system designed to address a prevalent limitation in e-commerce search engines. By programmatically parsing unstructured user queries to identify and apply corresponding structured facet filters, the proposed system effectively bridges the semantic gap between keyword-based retrieval and faceted navigation. The experimental results demonstrate a significant improvement in result relevance and a more streamlined user experience compared to standard search implementations.</p>

<p>The current implementation, while promising, has several recognized limitations that provide clear directions for future research. The system’s reliance on exact-match string comparisons for facet mapping is inherently brittle and does not account for synonyms, morphological variations, or misspellings. Furthermore, the conflict resolution logic for ambiguous terms is heuristic-based and could be substantially improved. The PoC does not yet support complex linguistic constructs (e.g., conjunctions, prepositions) or handle redundant terminology within queries.</p>

<p>Future work will focus on integrating more sophisticated Natural Language Processing (NLP) techniques to overcome these challenges. The exploration of libraries such as OpenNLP is underway to incorporate capabilities like stemming, synonym expansion, and dependency parsing for a deeper understanding of query syntax and semantics. Further research will also involve developing a more robust disambiguation model, potentially leveraging machine learning trained on historical search logs to predict user intent more accurately. Finally, a quantitative evaluation through rigorous A/B testing and formal user studies is required to measure the system’s impact on key performance indicators, such as search success rate, session duration, and conversion.</p>

<p>Ultimately, the continued development of such intelligent query interpretation systems is a critical step toward creating more intuitive, efficient, and user-centric information retrieval experiences within the e-commerce domain.</p>]]></content><author><name>Rauf Aliev</name></author><category term="Relevance" /><category term="Indexing" /><category term="Query Processing" /><category term="Keyword Search" /><category term="Information Retrieval (IR)" /><category term="Query Understanding (NLU)" /><category term="Faceted Search" /><category term="Filtering" /><category term="Search UI/UX" /><summary type="html"><![CDATA[This paper addresses a significant challenge in e-commerce information retrieval: the failure of standard keyword search systems to correctly interpret complex user queries that contain product attributes. Queries such as “blue XL Burton jacket” are often processed as a simple set of keywords, leading to irrelevant results and compelling users to engage in a laborious manual filtering process. We present a proof-of-concept (PoC) for an automatic facet discovery system designed to parse user queries, identify terms corresponding to product facets (e.g., color, brand, size), and apply these filters automatically. This research demonstrates a practical methodology for bridging the semantic gap between unstructured free-text search and structured faceted navigation, thereby enhancing result relevance and improving the overall user experience.]]></summary></entry><entry><title type="html">A Comprehensive Survey of Recommendation Algorithms: From Collaborative Filtering to Large Language Models</title><link href="https://www.testmysearch.com/blog/2025/09/06/recommerder-algorithms-review.html" rel="alternate" type="text/html" title="A Comprehensive Survey of Recommendation Algorithms: From Collaborative Filtering to Large Language Models" /><published>2025-09-06T00:00:00-04:00</published><updated>2025-09-06T00:00:00-04:00</updated><id>https://www.testmysearch.com/blog/2025/09/06/recommerder-algorithms-review</id><content type="html" xml:base="https://www.testmysearch.com/blog/2025/09/06/recommerder-algorithms-review.html"><![CDATA[<p>This paper provides a systematic and exhaustive review of recommendation algorithms, charting their evolution from foundational collaborative filtering techniques to the sophisticated deep learning and generative models of the modern era. We organize the landscape into three primary categories based on the dominant data modality: Interaction-Driven, Text-Driven, and Multimodal algorithms. For each paradigm and its key algorithms, we distill the core concepts, highlight key differentiators, identify primary use cases, and offer practical guidance for implementation. Our analysis reveals a recurring tension between model complexity and performance, the transformative impact of self-supervised learning, and the paradigm-shifting potential of Large Language Models. This survey is intended as a cornerstone reference for engineers and researchers seeking to navigate the complex, dynamic, and powerful field of recommender systems.</p>

<ul>
  <li><a href="#Abstract">Abstract</a></li>
  <li><a href="#Introduction">Introduction</a></li>
  <li><a href="#Section1FoundationalHeuristicDrivenAlgorithms">Section 1: Foundational and Heuristic-Driven Algorithms</a>
    <ul>
      <li><a href="#11ContentBasedFiltering">1.1 Content-Based Filtering</a>
        <ul>
          <li><a href="#Tfidf">1.1.1 Text Analysis: TF-IDF with Cosine Similarity</a></li>
          <li><a href="#Word2vec">1.1.2 Semantic Similarity: Word2Vec &amp; Doc2Vec</a></li>
          <li><a href="#VectorSpaceModel">1.1.3 Vector Space Model (VSM)</a></li>
        </ul>
      </li>
      <li><a href="#12RuleBasedSystems">1.2 Rule-Based Systems</a>
        <ul>
          <li><a href="#PythonFrameworks">Python Frameworks</a></li>
          <li><a href="#Productionready">Production-ready?</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#Section2InteractionDriven">Section 2: Interaction-Driven Recommendation Algorithms</a>
    <ul>
      <li><a href="#21ClassicNeighborhoodBasedModels">2.1 Classic &amp; Neighborhood-Based Models</a>
        <ul>
          <li><a href="#Userknn">2.1.1 UserKNN (User-based k-Nearest Neighbors)</a></li>
          <li><a href="#Itemknn">2.1.2 ItemKNN (Item-based k-Nearest Neighbors)</a></li>
          <li><a href="#Slopeone">2.1.3 SlopeOne</a></li>
          <li><a href="#AttributeAwareKNN">2.1.4 Attribute-Aware k-Nearest Neighbors</a></li>
          <li><a href="#PythonFrameworks">Python Frameworks</a></li>
          <li><a href="#Productionready">Production-ready?</a></li>
        </ul>
      </li>
      <li><a href="#22LatentFactorModelsMatrixFactorization">2.2 Latent Factor Models (Matrix Factorization)</a>
        <ul>
          <li><a href="#ClassicSolversSVDALS">2.2.1 Classic Solvers: SVD &amp; ALS</a></li>
          <li><a href="#PairwiseRankingObjectiveBprBayesianPersonalizedRanking">2.2.2 Pairwise Ranking Objective: BPR (Bayesian Personalized Ranking)</a></li>
          <li><a href="#ItembasedLatentModelsSLIMFISM">2.2.3 Item-based Latent Models: SLIM &amp; FISM</a></li>
          <li><a href="#FunkSVD">2.2.4 FunkSVD</a></li>
          <li><a href="#PureSVD">2.2.5 PureSVD</a></li>
          <li><a href="#NonNegMF">2.2.6 Non-Negative Matrix Factorization (NonNegMF)</a></li>
          <li><a href="#SVDpp">2.2.7 SVD++</a></li>
          <li><a href="#WRMF">2.2.8 Weighted Regularized Matrix Factorization (WRMF)</a></li>
          <li><a href="#CML">2.2.9 Collaborative Metric Learning (CML)</a></li>
          <li><a href="#PythonFrameworks">Python Frameworks</a></li>
          <li><a href="#Productionready">Production-ready?</a></li>
        </ul>
      </li>
      <li><a href="#23DeepLearningHybridsRepresentationLearning">2.3 Deep Learning Hybrids &amp; Representation Learning</a>
        <ul>
          <li><a href="#NeuralCollaborativeFiltering">2.3.1 Neural Collaborative Filtering (NCF)</a></li>
          <li><a href="#FactorizationMachinebasedDeepFMxDeepFM">2.3.2 Factorization Machine-based: DeepFM &amp; xDeepFM</a></li>
          <li><a href="#AutoencoderbasedDAEVAE">2.3.3 Autoencoder-based: DAE &amp; VAE</a></li>
          <li><a href="#NeuMF">2.3.4 Neural Matrix Factorization (NeuMF)</a></li>
          <li><a href="#PythonFrameworks">Python Frameworks</a></li>
          <li><a href="#Productionready">Production-ready?</a></li>
        </ul>
      </li>
      <li><a href="#24SequentialSessionBasedModels">2.4 Sequential &amp; Session-Based Models</a>
        <ul>
          <li><a href="#RnnbasedGru4rec">2.4.1 RNN-based: GRU4Rec</a></li>
          <li><a href="#CnnbasedNextitnet">2.4.2 CNN-based: NextItNet</a></li>
          <li><a href="#AttentionTransformerbasedSASRecBERT4Rec">2.4.3 Attention/Transformer-based: SASRec &amp; BERT4Rec</a></li>
          <li><a href="#WithContrastiveLearningCl4srec">2.4.4 With Contrastive Learning: CL4SRec</a></li>
        </ul>
      </li>
      <li><a href="#25GraphbasedModelsGnns">2.5 Graph-Based Models (GNNs)</a></li>
      <li><a href="#26DeepGenerativeModels">2.6 Deep Generative Models</a>
        <ul>
          <li><a href="#GenerativeAdversarialNetworks">2.6.1 Generative Adversarial Networks (GANs): IRGAN</a></li>
          <li><a href="#DiffusionForCfDiffrec">2.6.2 Diffusion for CF: DiffRec</a></li>
          <li><a href="#GflownetsGfn4rec">2.6.3 GFlowNets: GFN4Rec</a></li>
          <li><a href="#NormalizingFlowsIdnp">2.6.4 Normalizing Flows: IDNP</a></li>
          <li><a href="#PythonFrameworks">Python Frameworks</a></li>
          <li><a href="#Productionready">Production-ready?</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#Section3TextdrivenRecommendationAlgorithms">Section 3: Text-Driven Recommendation Algorithms</a>
    <ul>
      <li><a href="#31ReviewbasedModels">3.1 Review-Based Models</a>
        <ul>
          <li><a href="#Deepconn">3.1.1 DeepCoNN (Deep Cooperative Neural Networks)</a></li>
          <li><a href="#NARRE">3.1.2 NARRE (Neural Attentional Rating Regression with Review-level Explanations)</a></li>
        </ul>
      </li>
      <li><a href="#32LargeLanguageModelLlmbasedParadigms">3.2 Large Language Model (LLM)-Based Paradigms</a>
        <ul>
          <li><a href="#RetrievalbasedDenseRetrievalCrossEncoders">3.2.1 Retrieval-based: Dense Retrieval &amp; Cross-Encoders</a></li>
          <li><a href="#GenerativeInstruction">3.2.2 Generative / Instruction-Tuned</a></li>
          <li><a href="#RAGFeatureExtraction">3.2.3 RAG &amp; Feature Extraction</a></li>
          <li><a href="#LLMAgentsToolUse">3.2.4 LLM Agents &amp; Tool Use</a></li>
        </ul>
      </li>
      <li><a href="#33ConversationalRecommenderSystems">3.3 Conversational Recommender Systems</a>
        <ul>
          <li><a href="#DialoguebasedPreferenceElicitation">3.3.1 Dialogue-based Preference Elicitation</a></li>
          <li><a href="#NaturalLanguageExplanationCritique">3.3.2 Natural Language Explanation &amp; Critique</a></li>
          <li><a href="#PythonFrameworks">Python Frameworks</a></li>
          <li><a href="#Productionready">Production-ready?</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#Section4MultimodalRecommendationAlgorithms">Section 4: Multimodal Recommendation Algorithms</a>
    <ul>
      <li><a href="#41ContrastiveLearningForMultimodalAlignment">4.1 Contrastive Learning for Multimodal Alignment</a>
        <ul>
          <li><a href="#CLIP">4.1.1 CLIP (Contrastive Language-Image Pre-Training)</a></li>
          <li><a href="#ALBEF">4.1.2 ALBEF (Align Before Fuse)</a></li>
        </ul>
      </li>
      <li><a href="#42GenerativeMultimodalModels">4.2 Generative Multimodal Models</a>
        <ul>
          <li><a href="#MultimodalVaes">4.2.1 Multimodal VAEs</a></li>
          <li><a href="#MultimodalDiffusion">4.2.2 Multimodal Diffusion</a></li>
          <li><a href="#PythonFrameworks">Python Frameworks</a></li>
          <li><a href="#Productionready">Production-ready?</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#Section5ContextAwareRecommendationAlgorithms">Section 5: Context-Aware Recommendation Algorithms</a>
    <ul>
      <li><a href="#51FactorizationMachineFamily">5.1 Factorization Machine Family</a>
        <ul>
          <li><a href="#AMF">5.1.1 AMF (Attentional Factorization Machine)</a></li>
        </ul>
      </li>
      <li><a href="#52CrossNetworkModels">5.2 Cross-Network Models</a></li>
    </ul>
  </li>
  <li><a href="#Section6KnowledgeAwareRecommendationAlgorithms">Section 6: Knowledge-Aware Recommendation Algorithms</a>
    <ul>
      <li><a href="#61EmbeddingbasedPathbasedModels">6.1 Embedding-based &amp; Path-based Models</a></li>
    </ul>
  </li>
  <li><a href="#Section7SpecializedRecommendationTasks">Section 7: Specialized Recommendation Tasks</a>
    <ul>
      <li><a href="#71DebiasingFairness">7.1 Debiasing &amp; Fairness</a></li>
      <li><a href="#72CrossDomainRecommendation">7.2 Cross-Domain Recommendation</a></li>
      <li><a href="#73MetaLearningforColdStart">7.3 Meta-Learning for Cold Start</a></li>
    </ul>
  </li>
  <li><a href="#Section8Conclusion">Section 8: Conclusion</a></li>
</ul>

<h2 id="abstract">Abstract</h2>

<p>This paper provides a systematic and exhaustive review of recommendation algorithms, charting their evolution from foundational collaborative filtering techniques to the sophisticated deep learning and generative models of the modern era. We organize the landscape into three primary categories based on the dominant data modality: Interaction-Driven, Text-Driven, and Multimodal algorithms. For each paradigm and its key algorithms, we distill the core concepts, highlight key differentiators, identify primary use cases, and offer practical guidance for implementation. Our analysis reveals a recurring tension between model complexity and performance, the transformative impact of self-supervised learning, and the paradigm-shifting potential of Large Language Models. This survey is intended as a cornerstone reference for engineers and researchers seeking to navigate the complex, dynamic, and powerful field of recommender systems.</p>

<h2 id="introduction">Introduction</h2>

<p>In the modern digital ecosystem, users are confronted with a virtually infinite selection of items, from products and movies to news articles and music. This phenomenon, often termed “information overload,” presents a significant challenge for both consumers and platforms. Recommender systems have emerged as a critical technology to address this challenge, serving as personalized information filters that guide users toward relevant content, thereby enhancing user experience, engagement, and commerce.</p>

<p>The field of recommendation algorithms has undergone a remarkable evolution. Early systems were built on simple statistical methods that leveraged direct user-item interactions. These foundational techniques, known as collaborative filtering, gave way to more sophisticated latent factor models, which sought to uncover the hidden dimensions of user preference by decomposing the user-item interaction matrix. The deep learning revolution subsequently ushered in a new era, with neural networks enabling the modeling of complex, non-linear relationships that were previously intractable.</p>

<p>This progression continued with the development of specialized architectures to capture the sequential dynamics of user behavior, borrowing heavily from advances in natural language processing. Concurrently, a new perspective emerged that modeled the recommendation problem as a graph, applying Graph Neural Networks to capture high-order relationships between users and items. Most recently, the landscape is being reshaped by the advent of large-scale generative models, including Generative Adversarial Networks, Diffusion Models, and, most notably, Large Language Models (LLMs), which are redefining the boundaries of what recommender systems can achieve.</p>

<p>This paper aims to provide a structured, high-level, and practical overview of this algorithmic landscape. We organize our survey into five principal sections based on the primary data modality and methodological approach each class of algorithms leverages:</p>

<ol>
  <li><strong>Foundational and Heuristic-Driven Algorithms:</strong> Models that rely on intrinsic item attributes (Content-Based) or manually defined heuristics (Rule-Based) to generate recommendations, offering interpretability and effectiveness for cold-start scenarios.</li>
  <li><strong>Interaction-Driven Algorithms:</strong> Models that rely exclusively on user-item interaction data (e.g., ratings, clicks, purchases).</li>
  <li><strong>Text-Driven Algorithms:</strong> Models that incorporate unstructured text, such as user reviews or item descriptions, and are increasingly powered by LLMs.</li>
  <li><strong>Multimodal Algorithms:</strong> Models that fuse information from multiple sources, such as text, images, and video, to create a holistic understanding of items and preferences.</li>
  <li><strong>Context-Aware &amp; Knowledge-Aware Algorithms:</strong> Advanced models that leverage explicit side features, contextual information, and structured knowledge from external sources like knowledge graphs.</li>
  <li><strong>Specialized Recommendation Tasks:</strong> A look at crucial sub-fields like ensuring fairness, mitigating bias, and addressing the cold-start problem.</li>
</ol>

<p>For each algorithm, we provide a concise explanation of its core concept, key differentiators, primary use cases, and practical considerations for implementation, along with a link to its seminal paper. Our objective is to equip engineers and researchers with a comprehensive map to navigate the field, understand its historical trajectory, and make informed decisions when designing and deploying the next generation of recommender systems.</p>

<p>To help navigate this complex field, we present two views of the recommender algorithm landscape. We begin with a high-level classification that organizes the field into three fundamental paradigms based on the primary data modality the algorithms leverage: what they “see.” This initial map provides a clear, foundational understanding of the core approaches.</p>

<p><img src="/Users/raufaliev/Documents/dev/code/personal/raliev.github.io/docs/_posts\/img/recommendation_algorithms.png" alt="" /></p>

<p>While this modality-based view is an excellent starting point, it doesn’t capture the full picture. The field has evolved to include models that integrate more sophisticated information or are designed to solve specific, nuanced problems.</p>

<p>Therefore, we present a second, more comprehensive taxonomy. This detailed map builds upon the first by adding three crucial dimensions: Context-Aware models that use side features (like time or location), Knowledge-Aware models that incorporate structured data from knowledge graphs, and Specialized Tasks that address critical challenges like bias, fairness, and the cold-start problem. Together, these diagrams offer a layered journey from the core principles to the specialized frontiers of modern recommender systems</p>

<p><img src="/Users/raufaliev/Documents/dev/code/personal/raliev.github.io/docs/_posts\/img/recalgdiagram.png" alt="" /></p>

<h2 id="section-1-foundational-and-heuristic-driven-algorithms">Section 1: Foundational and Heuristic-Driven Algorithms</h2>

<p>Before the dominance of collaborative filtering, the recommendation landscape was shaped by foundational approaches that remain relevant today as powerful baselines, components of hybrid systems, and transparent business logic engines. These algorithms operate not on user interaction patterns but on intrinsic item attributes (Content-Based) or manually defined heuristics (Rule-Based). They are highly interpretable, easy to implement, and effectively address the cold-start problem for new items.</p>

<h3 id="11-content-based-filtering">1.1 Content-Based Filtering</h3>

<p>Content-based filtering recommends items that are similar to what a user has liked in the past. It relies on the attributes of the items themselves to generate recommendations, operating on the principle: “Show me more of what I like.” This approach is independent of other users’ data, making it robust against data sparsity and effective for recommending niche items.</p>

<blockquote>
  <p><strong>How it works…</strong> &gt;<br />
Imagine you’ve watched and loved the movie <em>Blade Runner</em>. A content-based system would analyze its attributes: <code class="language-plaintext highlighter-rouge">Genre: Sci-Fi</code>, <code class="language-plaintext highlighter-rouge">Theme: Cyberpunk</code>, <code class="language-plaintext highlighter-rouge">Director: Ridley Scott</code>. It would then search its catalog for other movies with similar attributes, such as <em>Alien</em> (also directed by Ridley Scott) or <em>Ghost in the Shell</em> (also sci-fi and cyberpunk), and recommend them to you. The user’s taste is built as a profile based on the content of items they’ve previously enjoyed.</p>
</blockquote>

<h4 id="111-text-analysis-tf-idf-with-cosine-similarity">1.1.1 Text Analysis: TF-IDF with Cosine Similarity</h4>

<p><strong>Key concept:</strong> This classic approach represents items by the textual content of their descriptions. <strong>TF-IDF (Term Frequency-Inverse Document Frequency)</strong> is used to convert text into a numerical vector. It calculates a score for each word that reflects its importance in a document relative to the entire collection of documents (corpus). Items that have similar important words will have similar vector representations. <strong>Cosine Similarity</strong> is then used to measure the angle between these vectors, with a smaller angle indicating higher similarity.</p>

<p><strong>Key differentiator:</strong> Its simplicity, interpretability, and effectiveness as a baseline. Unlike collaborative filtering, it can recommend a brand-new item to users as long as it has a textual description, completely solving the item cold-start problem.</p>

<p><strong>Use cases:</strong> Recommending articles based on reading history, suggesting products based on item descriptions, or finding similar documents in a large database. It’s a go-to for any domain where items have rich textual metadata.</p>

<p><strong>When to Consider:</strong> Use TF-IDF as a first-pass content-based recommender or a strong baseline. It is excellent when you need a fast, simple, and explainable model that relies purely on item text. It is particularly effective for document-heavy domains.</p>

<h4 id="112-semantic-similarity-word2vec--doc2vec">1.1.2 Semantic Similarity: Word2Vec &amp; Doc2Vec</h4>

<p><strong>Key concept:</strong> This approach moves beyond simple keyword matching to understand the <em>semantic meaning</em> of item attributes. <strong>Word2Vec</strong> and <strong>Doc2Vec</strong> are neural network-based techniques that learn dense vector representations (embeddings) for words and documents, respectively. These embeddings capture context, so words like “king” and “queen” or “running” and “jogging” are mapped to nearby points in the vector space. The item’s content is converted into an average embedding, and similar items are found using a distance metric like cosine similarity.</p>

<p><strong>Key differentiator:</strong> The ability to capture <strong>semantic relationships and context</strong>. A TF-IDF model might not know that “sci-fi” and “space opera” are related, but an embedding-based model would. This allows for more nuanced and serendipitous recommendations that go beyond simple keyword overlap.</p>

<p><strong>Use cases:</strong> Enhancing content-based recommendation for movies, music, or products where semantic understanding is key. For example, it can learn that a user who likes songs with a “funky bassline” might also like songs described with “groovy rhythms,” even if the exact words are different.</p>

<p><strong>When to Consider:</strong> Use semantic similarity models when a deeper understanding of item content is required and simple keyword matching is insufficient. If your item descriptions contain synonyms or context-dependent terms, Word2Vec or Doc2Vec will provide a significant performance boost over TF-IDF.</p>

<h4 id="113-vector-space-model-vsm">1.1.3 Vector Space Model (VSM)</h4>

<p><strong>Key concept:</strong> The Vector Space Model (VSM) represents items and user preferences as vectors in a high-dimensional space based on their textual attributes or metadata. Items are typically encoded using techniques like TF-IDF or simple term frequency, and similarity between items or between an item and a user profile is computed using metrics like cosine similarity.</p>

<p><strong>Key differentiator:</strong> VSM is a foundational framework for content-based filtering, emphasizing simplicity and flexibility. It generalizes TF-IDF by allowing various feature weighting schemes and can incorporate structured metadata (e.g., genres, tags) beyond text, making it adaptable to diverse domains.</p>

<p><strong>Use cases:</strong> Recommending articles, products, or media based on metadata or textual descriptions, such as news articles with similar topics or movies with matching genres. It is effective for cold-start scenarios where item attributes are available but interaction data is sparse.</p>

<p><strong>When to Consider:</strong> Use VSM when you need a lightweight, customizable content-based approach that can handle both textual and structured metadata. It is ideal for quick prototyping or as a baseline when item descriptions are rich but user interaction data is limited.</p>

<ul>
  <li><strong>Seminal Reference:</strong>
    <ul>
      <li>Salton, G., Wong, A., &amp; Yang, C. S. (1975). <em>A Vector Space Model for Automatic Indexing</em>. <a href="https://dl.acm.org/doi/10.1145/361219.361220">https://dl.acm.org/doi/10.1145/361219.361220</a>.</li>
    </ul>
  </li>
</ul>

<h3 id="12-rule-based-systems">1.2 Rule-Based Systems</h3>

<p><strong>Key concept:</strong> Rule-based systems use manually defined, domain-specific “if-then” rules to generate recommendations. These rules are crafted based on business knowledge and do not involve statistical learning from user data. They are direct implementations of business logic.</p>

<p><strong>Key differentiator:</strong> Their complete transparency and control. The reason for a recommendation is never a black box; it’s a direct consequence of a predefined rule (e.g., <code class="language-plaintext highlighter-rouge">IF user is in New York AND season is winter, THEN recommend heavy coats</code>). This makes them predictable, easy to debug, and simple to modify based on changing business needs.</p>

<p><strong>Drawback:</strong> when the number of rules grow, and when they collide, it becomes harder and harder to mange and resolve conflicts.</p>

<p><strong>Use cases:</strong> Implementing business-critical promotions (“Top 10 Bestsellers in Your Region”), strategic recommendations (promoting high-margin items), or providing sensible defaults for new users (e.g., showing the most popular items on the homepage). They are often used as a foundational layer in a hybrid system.</p>

<p><strong>When to Consider:</strong> An engineer should use a rule-based system when recommendations need to be 100% transparent, controllable, and aligned with explicit business goals. They are also invaluable for handling the “coldest start” scenario (a brand new site with no users or interactions) and for creating non-personalized but useful features like “Most Popular” or “New Arrivals” lists.</p>

<h4 id="python-frameworks">Python Frameworks</h4>

<ul>
  <li><strong>Content-Based (TF-IDF, Cosine Similarity):</strong>
    <ul>
      <li><strong>scikit-learn</strong> : The definitive library for these tasks. It provides highly optimized and easy-to-use implementations of <code class="language-plaintext highlighter-rouge">TfidfVectorizer</code> and <code class="language-plaintext highlighter-rouge">cosine_similarity</code>.</li>
    </ul>
  </li>
  <li><strong>Content-Based (Word2Vec, Doc2Vec):</strong>
    <ul>
      <li><strong>Gensim</strong> : The standard, go-to library for training and using Word2Vec and Doc2Vec models.</li>
      <li><strong>spaCy</strong> : A powerful NLP library that provides pre-trained word embeddings and easy access to document vectors.</li>
    </ul>
  </li>
  <li><strong>Rule-Based Systems:</strong>
    <ul>
      <li>These are typically implemented using standard programming constructs (<code class="language-plaintext highlighter-rouge">if/else</code> statements, case switches) and data manipulation libraries like <strong>Pandas</strong> for filtering and sorting data based on the defined rules.</li>
    </ul>
  </li>
</ul>

<h4 id="production-ready">Production-ready?</h4>

<ul>
  <li><strong>Content-Based Filtering:</strong> <strong>Absolutely Production-Ready.</strong> These techniques are robust, scalable, and widely deployed. TF-IDF is a cornerstone of information retrieval and serves as a powerful baseline in many production systems. Semantic models using Word2Vec/Doc2Vec are also common for enriching item representations.</li>
  <li><strong>Rule-Based Systems:</strong> <strong>Production-Ready and Ubiquitous.</strong> While not a “learning” algorithm, rule-based logic is a critical component of virtually every commercial recommender system. It provides a necessary layer of editorial control, business logic, and predictability that complements and governs more complex machine learning models.</li>
</ul>

<h2 id="section-2-interaction-driven-recommendation-algorithms">Section 2: Interaction-Driven Recommendation Algorithms</h2>

<p>These algorithms rely solely on user-item interaction data, such as ratings, clicks, or purchases, without incorporating additional content like text or images. They focus on patterns in how users engage with items to make predictions, forming the foundation of collaborative filtering .</p>

<blockquote>
  <p><strong>A Note on Recommendation Tasks: Rating Prediction vs. Item Ranking</strong></p>

  <p>Before diving into the algorithms, it’s crucial to understand the two fundamentally different tasks they are designed to solve:</p>

  <ol>
    <li>
      <p><strong>Rating Prediction (Explicit Feedback):</strong> The primary goal here is to predict the <strong>exact rating</strong> a user would give an item (e.g., “we predict you would rate this movie 4.2 stars”). Models like SVD, ALS, and various k-NN approaches are designed for this task. Consequently, they are evaluated using error-based metrics like <strong>Root Mean Squared Error (RMSE)</strong> and <strong>Mean Absolute Error (MAE)</strong>, which measure how close the predicted ratings are to the true ratings.</p>
    </li>
    <li>
      <p><strong>Item Ranking (Implicit Feedback):</strong> Here, the goal is not to predict a rating, but to generate an <strong>ordered list</strong> of items the user is most likely to interact with. The model only needs to ensure that preferred items receive higher scores than non-preferred items; the absolute value of the score is irrelevant. Algorithms like BPR, NCF, and SASRec are optimized for this ranking task. They are evaluated using rank-based metrics like <strong>Precision@k and Recall@k</strong>, which measure the quality of the top-k items in the recommended list.</p>
    </li>
  </ol>

  <p>This distinction is why a model designed for ranking cannot be fairly evaluated with RMSE—its scores are not intended to be accurate rating predictions, only to produce a correct ordering.</p>
</blockquote>

<h3 id="21-classic--neighborhood-based-models">2.1 Classic &amp; Neighborhood-Based Models</h3>

<p>These are foundational “memory-based” collaborative filtering approaches that recommend items based on similarities between users or items. They operate directly on the user-item interaction matrix, are simple, interpretable, and work well with sparse data but can struggle with scalability, coverage, and cold-start issues in very large or sparse datasets. They serve as powerful baselines for more complex models.</p>

<h4 id="211-userknn-user-based-k-nearest-neighbors">2.1.1 UserKNN (User-based k-Nearest Neighbors)</h4>

<p><strong>UserKNN</strong> (User-based K-Nearest Neighbors) finds users similar to the target user based on their interaction histories (using similarity measures like cosine or Pearson correlation on rating vectors) and recommends items that those similar users liked.</p>

<p><strong>Key concept:</strong> It assumes similar users have similar tastes, enabling predictions from “neighbors.”</p>

<p><strong>Key differentiator</strong>: Focuses on user similarities, making it intuitive for scenarios where user preferences are stable and interpretability is key (e.g., explaining recommendations via “Users who liked X also liked Y”).</p>

<p><strong>Use cases:</strong> E-commerce sites for personalized suggestions based on similar shoppers, or early recommender systems like GroupLens. Consider it when you have a moderate number of users, ample interaction data, and want quick, explainable recommendations without deep learning overhead.</p>

<p><strong>Seminal Papers:</strong></p>

<ul>
  <li>GroupLens: an open architecture for collaborative filtering of netnews. Resnick, Paul and Iacovou, Neophytos and Suchak, Mitesh and Bergstrom, Peter and Riedl, John. 1994. <a href="https://dl.acm.org/doi/10.1145/192844.192905">https://dl.acm.org/doi/10.1145/192844.192905</a>.</li>
  <li>On the challenges of studying bias in Recommender Systems: A UserKNN case study. Savvina Daniil, Manel Slokom, Mirjam Cuper, Cynthia C.S. Liem, Jacco van Ossenbruggen, Laura Hollink. <a href="https://arxiv.org/abs/2409.08046">https://arxiv.org/abs/2409.08046</a></li>
</ul>

<h4 id="212-itemknn-item-based-k-nearest-neighbors">2.1.2 ItemKNN (Item-based k-Nearest Neighbors)</h4>

<p><strong>ItemKNN</strong> (Item-based K-Nearest Neighbors) recommends items similar to those the user has interacted with in the past, based on item similarity computed from user interactions (often using adjusted cosine similarity to account for user biases).</p>

<p><strong>Key concept:</strong> It builds item similarity matrices, assuming users tend to like items similar to ones they’ve liked before.</p>

<p><strong>Key Differentiator:</strong> More scalable than UserKNN for large item catalogs since item similarities change less frequently; offers transparency via “Because you watched X, you might like Y.”</p>

<p><strong>Use cases:</strong> Streaming services like Netflix for “similar to what you’ve watched,” or Amazon’s early item-based recommender for efficient, real-time suggestions. Consider it when your item set is stable, data is sparse, and you need efficient computation with reasonable accuracy and minimal training.</p>

<p><strong>Hyperparameters</strong></p>

<ul>
  <li>
    <p><strong>k (Number of Neighbors)</strong>: This defines how many of the most similar items will be used to predict a rating for a target item. A small k might lead to recommendations that are highly relevant but less diverse, while a large k can increase diversity but may introduce noise from less similar items.</p>
  </li>
  <li>
    <p><strong>Similarity Metric</strong>: This is the formula used to measure the similarity between pairs of items. Common choices include Cosine Similarity, Adjusted Cosine Similarity (which accounts for user rating scale biases), and Pearson Correlation. The best choice depends on the nature of your data (e.g., explicit vs. implicit feedback).</p>
  </li>
  <li>
    <p><strong>Minimum Support (min_support)</strong>: This sets a threshold for the minimum number of users who must have rated both items in a pair for their similarity to be calculated. It helps ensure that similarity scores are statistically significant and not based on a small, noisy sample.</p>
  </li>
  <li>
    <p><strong>Shrinkage</strong>: This is a regularization parameter used to dampen similarity scores for items with few co-ratings. It “shrinks” these less reliable scores toward zero, preventing noise from items with low support from dominating the recommendations.</p>
  </li>
</ul>

<p><strong>Seminal Papers:</strong></p>

<ul>
  <li>Item-based collaborative filtering recommendation algorithms, Sarwar, Badrul and Karypis, George and Konstan, Joseph and Riedl, John., 2001. <a href="https://dl.acm.org/doi/10.1145/371920.372071">https://dl.acm.org/doi/10.1145/371920.372071</a></li>
  <li>On the challenges of studying bias in Recommender Systems: A UserKNN case study. Savvina Daniil, Manel Slokom, Mirjam Cuper, Cynthia C.S. Liem, Jacco van Ossenbruggen, Laura Hollink. <a href="https://arxiv.org/abs/2409.08046">https://arxiv.org/abs/2409.08046</a></li>
</ul>

<h4 id="213-slopeone">2.1.3 SlopeOne</h4>

<p>SlopeOne is a simple, non-iterative algorithm that predicts ratings by computing average deviations (or “slopes”) between item pairs, assuming linear relationships like f(x) = x + b, where b is the pre-computed average rating deviation.</p>

<p><strong>Key concept:</strong> It models consistent offsets in ratings (e.g., if Item B is rated 0.5 higher than Item A on average, predict accordingly for a new user); new ratings can update averages incrementally.</p>

<p><strong>Differentiator:</strong> Extremely lightweight with no training phase (O(n²) preprocessing for n items), handles cold-start better than KNN, and supports dynamic updates with fast queries.</p>

<p><strong>Use cases:</strong> Quick prototyping, mobile apps, or online systems with limited resources where numerical ratings exist and simplicity/speed trump top accuracy. Consider it when preferences have consistent offsets, you need an incremental model, or engineering overhead must be minimal.</p>

<h4 id="214-attribute-aware-k-nearest-neighbors">2.1.4 Attribute-Aware k-Nearest Neighbors</h4>

<p>Attribute-Aware k-NN is more of a concept or an approach rather than a strictly defined algorithm. Its core idea is to modify the similarity metric calculation to account for not only the history of interactions (e.g., ratings, clicks) but also the attributes (metadata) of users or items.</p>

<p><strong>Key concept:</strong> Attribute-Aware k-Nearest Neighbors, as implemented in the MyMediaLite library, extends UserKNN and ItemKNN by incorporating item or user attributes into the similarity computation. For example, item similarity can combine interaction-based metrics (e.g., cosine similarity on ratings) with content-based features (e.g., genre overlap), creating a hybrid approach.</p>

<p><strong>Key differentiator:</strong> This method bridges collaborative and content-based filtering by integrating attribute information directly into the k-NN framework, improving recommendation quality when interaction data is sparse or when attributes provide complementary signals.</p>

<p><strong>Use cases:</strong> Recommending items in domains like music or movies, where metadata (e.g., artist, genre) can enhance similarity computations. It is particularly useful in hybrid systems where both interaction and content data are available.</p>

<p><strong>When to Consider:</strong> Use Attribute-Aware k-NN when you have access to both interaction data and rich item or user metadata, and you want to leverage both in a simple, interpretable framework. It is a good choice for small to medium datasets where hybrid approaches can outperform pure collaborative filtering.</p>

<ul>
  <li><strong>Reference:</strong>
    <ul>
      <li>MyMediaLite Documentation: <a href="http://www.mymedialite.net/">http://www.mymedialite.net/</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="python-frameworks-1">Python Frameworks</h4>

<ul>
  <li><strong>Surprise</strong> <a href="https://surpriselib.com/">https://surpriselib.com/</a>: Provides robust implementations for explicit data, including KNNBasic, KNNWithMeans, and KNNWithZScore, allowing for various baseline and normalization strategies. It also supports attribute-aware k-NN through custom similarity measures.</li>
  <li><strong>scikit-learn</strong> <a href="https://scikit-learn.org/">https://scikit-learn.org/</a>: While not a dedicated recommender library, its NearestNeighbors module is a common choice for implementing the core similarity search component of a k-NN recommender.</li>
  <li><strong>MyMediaLite</strong> <a href="http://www.mymedialite.net/">http://www.mymedialite.net/</a>: A lightweight library offering implementations of attribute-aware UserKNN and ItemKNN, combining interaction and content-based features.</li>
</ul>

<h4 id="production-ready-1">Production-ready?</h4>

<p>Item-based k-NN, in particular, is a proven, scalable, and effective algorithm that has been a cornerstone of production recommender systems for years. It is famously used by companies like Amazon for their “customers who bought this also bought” feature, demonstrating its real-world utility. While it remains a powerful tool, especially as a baseline or a component in a hybrid system, it can face challenges with data sparsity and, in the case of user-based variants, scalability issues as the number of users grows.</p>

<p>For the Slope One, it is different. The primary advantages of Slope One are its ease of implementation, low storage requirements, and extremely fast prediction time. These characteristics make it an excellent choice for systems with limited computational resources, as a strong and simple-to-debug baseline, or in online settings where the model needs to be updated frequently and dynamically as new ratings arrive.</p>

<h3 id="22-latent-factor-models-matrix-factorization">2.2 Latent Factor Models (Matrix Factorization)</h3>

<p>These “model-based” methods address data sparsity by decomposing the user-item interaction matrix into lower-dimensional latent factor matrices for users and items. The core idea is to represent users and items in a shared latent space where their proximity reflects preference. This condenses complex interaction patterns into a small number of hidden features, moving beyond direct neighbor comparisons to uncover the underlying reasons for preferences.</p>

<p><img src="/img/recommendations/lfm.png" alt="" /></p>

<!-- Note: I use blockquotes (>) to create asides for explanatory text like "Simply put..." to provide additional context for readers who need clarification. -->

<blockquote>
  <p>**Simply put…<br />
**<br />
It’s like creating a “taste profile” for both users and items using the same set of hidden characteristics.</p>

  <p>Imagine you’re recommending movies. Instead of just knowing which movies a person likes, the model tries to figure out why. It creates a handful of underlying characteristics, like “amount of sci-fi,” “level of comedy,” or “degree of romance.”</p>

  <p>Each movie gets a score for each of these characteristics. For example, a rom-com would score high on “comedy” and “romance” but low on “sci-fi.”<br />
Each user gets a matching profile based on the movies they’ve enjoyed. Someone who loves rom-coms would get high scores for “comedy” and “romance” preferences.<br />
To make a recommendation, the system just finds movies whose characteristic scores are a great match for the user’s preference scores. This way, it can recommend a new movie the user has never seen, as long as its “taste profile” fits theirs.</p>
</blockquote>

<h4 id="221-classic-solvers-svd--als">2.2.1 Classic Solvers: SVD &amp; ALS</h4>

<p><strong>Key concept:</strong> These techniques calculate latent factor matrices for users and items by learning vector representations that capture underlying characteristics (e.g., for movies, a factor might represent the “action vs. drama” dimension). The predicted rating is the dot product of a user’s and an item’s latent vectors. The models learn these vectors by minimizing the prediction error on known ratings through different optimization strategies. For example, a user who scores high on the “prefers action” factor will have a high predicted rating for a movie that scores high on the “is an action movie” factor.</p>

<p><strong>Key differentiator:</strong> The main difference lies in how they calculate the optimal latent factors:</p>

<ul>
  <li><strong>SVD (Singular Value Decomposition)</strong>, in the context of recommendation, typically refers to models that use an iterative optimization algorithm like <strong>Stochastic Gradient Descent (SGD)</strong>. The process works by looping through each known rating, calculating the difference between the predicted rating (the current dot product of user and item factors) and the actual rating, and then making a small adjustment to the factor vectors to reduce this error. By repeating this for many iterations, the factors gradually converge to a state that minimizes the overall prediction error.</li>
  <li><strong>ALS (Alternating Least Squares)</strong> calculates the factors in a two-step alternating process. First, it holds the item latent factors constant and solves a standard least-squares problem to find the best user factors. Then, it holds the newly calculated user factors constant and solves for the best item factors. This process repeats for a set number of iterations, alternating back and forth until the factors stabilize. This method is highly parallelizable, making ALS scalable in distributed environments like Spark.</li>
</ul>

<figure>
  <img src="/img/recommendations/svd-d.png" alt="SVD algorithm" />
  <figcaption>SVD algorithm</figcaption>
</figure>

<figure>
  <img src="/img/recommendations/svd.png" alt="SVD algorithm, example" />
  <figcaption>SVD algorithm, example</figcaption>
</figure>

<figure>
  <img src="/img/recommendations/als-d.png" alt="ALS algorithm" />
  <figcaption>ALS algorithm</figcaption>
</figure>

<figure>
  <img src="/img/recommendations/als.png" alt="ALS algorithm, example" />
  <figcaption>ALS algorithm, example</figcaption>
</figure>

<p><strong>Use cases:</strong> These models are workhorses for personalized recommendation, primarily for predicting explicit ratings (e.g., 1-5 stars) in domains like e-commerce (such as Amazon) and media streaming (such as Netflix). ALS is dominant in industrial settings with very large, sparse datasets that require distributed training.</p>

<p><strong>When to Consider:</strong> Matrix factorization is a powerful step up from neighborhood models, especially for sparse data. Use an SVD-like model (trained with SGD) when you need a flexible model and are comfortable with iterative training. Opt for <strong>ALS</strong> when dealing with large-scale, sparse datasets, especially if you have access to a distributed computing framework. ALS is particularly effective for implicit feedback scenarios when using a weighted formulation (WR-ALS).</p>

<blockquote>
  <p><strong>Matrix factorization</strong> is a technique to break down a large user-item interaction matrix (like ratings or clicks) into two smaller matrices that represent users and items in a shared “taste” space. By finding hidden patterns in the data, it assigns scores to users and items based on latent features (e.g., “love for sci-fi” or “preference for comedy”). These scores help predict how much a user will like an item they haven’t interacted with, making recommendations more accurate.</p>
</blockquote>

<p><strong>Hyperparameters</strong></p>

<ul>
  <li><strong>k (Latent Factors / Rank)</strong>: This parameter determines the number of latent factors in the model. A smaller k creates a more generalized model, while a larger k can capture more specific user tastes but is at higher risk of overfitting.</li>
  <li><strong>Iterations</strong>: The number of times the optimization algorithm (SGD or ALS) runs over the dataset. More iterations can lead to a more accurate model but also increase training time and the risk of overfitting.</li>
  <li><strong>Regularization (lambda_reg)</strong>: This parameter is crucial for preventing overfitting. It penalizes large values in the latent factor vectors, encouraging the model to find more general patterns rather than memorizing the training data. The <code class="language-plaintext highlighter-rouge">ALS (Improved)</code> version even allows for separate regularization terms for the latent factors and the user/item bias terms (<code class="language-plaintext highlighter-rouge">lambda_biases</code>).</li>
  <li>
    <p><strong>Learning Rate</strong> (for SGD-based SVD): This parameter controls the step size of the adjustments made to the factors in each iteration. It is critical for ensuring the model converges properly.</p>
  </li>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>SVD (in RecSys context):</strong> Koren, Y., Bell, R., &amp; Volinsky, C. (2009). <em>Matrix factorization techniques for recommender systems</em>. <a href="https://www.researchgate.net/publication/220381329_Matrix_factorization_techniques_for_recommender_systems">https://www.researchgate.net/publication/220381329_Matrix_factorization_techniques_for_recommender_systems</a>.</li>
      <li><strong>ALS:</strong> Zhou, Y., Wilkinson, D., Schreiber, R., &amp; Pan, R. (2008). <em>Large-scale Parallel Collaborative Filtering for the Netflix Prize</em>. <a href="https://www.researchgate.net/publication/221566136_Large-scale_Parallel_Collaborative_Filtering_for_the_Netflix_Prize">https://www.researchgate.net/publication/221566136_Large-scale_Parallel_Collaborative_Filtering_for_the_Netflix_Prize</a>.</li>
    </ul>
  </li>
  <li><strong>Useful links</strong>
    <ul>
      <li><a href="https://www.geeksforgeeks.org/machine-learning/svd-in-recommendation-systems/">SVD in Recommendation Systems: Tutorial (scikit-surprise)</a></li>
      <li><a href="https://ujangriswanto08.medium.com/a-beginners-guide-to-using-svd-for-building-recommender-systems-878de4b66992">“A Beginner’s Guide to Using SVD for Building Recommender Systems” from Ujang Riswanto (using sklearn)</a></li>
      <li><a href="https://medium.com/analytics-vidhya/model-based-recommendation-system-with-matrix-factorization-als-model-and-the-math-behind-fdce8b2ffe6d">“Model-based Recommendation System with Matrix Factorization — ALS Model and The Math behind” from Jeffery Chiang (using pyspark)</a></li>
    </ul>
  </li>
</ul>

<h4 id="222-pairwise-ranking-objective-bpr-bayesian-personalized-ranking">2.2.2 Pairwise Ranking Objective: BPR (Bayesian Personalized Ranking)</h4>

<p><strong>Key concept:</strong> BPR reframes the recommendation problem as a ranking task, focusing on predicting preference orders rather than specific rating scores. It assumes that for a given user, an item they have interacted with (positive item) should rank higher than an item they have not interacted with (negative item). The model maximizes the probability of correctly ordering these item pairs using a pairwise ranking loss.</p>

<p><strong>Key differentiator:</strong> BPR marked a significant shift in recommender systems by prioritizing ranking optimization over traditional rating prediction metrics like RMSE. Unlike earlier models that focused on predicting exact ratings, BPR aligns directly with the practical goal of delivering high-quality ranked lists, making it particularly effective for implicit feedback data (e.g., clicks, purchases) where explicit negative feedback is absent, and only unobserved items are available as negative samples.</p>

<p><strong>Key findings from replicability study:</strong> A 2024 study by Deldjoo et al. revisited BPR’s performance to assess its robustness and replicability across modern datasets and settings (Deldjoo, Y., et al., 2024, <em>Revisiting BPR: A Replicability Study of a Common Recommender System Baseline</em>). The study confirms BPR’s effectiveness as a strong baseline for Top-N recommendation tasks, particularly for implicit feedback. However, it highlights that BPR’s performance can vary significantly depending on dataset characteristics, such as sparsity and item popularity skew. The study also notes that while BPR remains competitive, modern neural models may outperform it in dense datasets or when incorporating side information (e.g., item features). Additionally, hyperparameter tuning, particularly the learning rate and regularization, is critical for achieving optimal performance, and the study emphasizes the importance of standardized evaluation protocols to ensure fair comparisons.</p>

<p><strong>Use cases:</strong> BPR is a standard approach for modeling implicit feedback in scenarios requiring ranked recommendation lists, such as e-commerce (product recommendations), media streaming (movie or music suggestions), and online advertising. It excels in environments where explicit ratings are sparse or unavailable but user interactions are abundant.</p>

<p><strong>When to Consider:</strong> Choose BPR for Top-N recommendation tasks where the goal is to produce a ranked list of items based on implicit feedback. It is particularly effective in sparse data settings and remains a robust baseline, though engineers should consider dataset characteristics and explore modern alternatives for dense datasets or feature-rich environments.</p>

<p><strong>Hyperparameters</strong></p>

<ul>
  <li><strong>k (Latent Factors)</strong>: This defines the dimensionality of the user and item vectors. It controls the complexity of the model, with a higher <code class="language-plaintext highlighter-rouge">k</code> allowing for more nuanced representations at the risk of overfitting.</li>
  <li><strong>Iterations</strong>: The number of passes the algorithm makes through the training data. For BPR, this means iterating over the user-item pairs to update the latent factor vectors.</li>
  <li><strong>Learning Rate</strong>: This parameter controls the step size of the updates made to the latent factors during training. A well-tuned learning rate is critical for the model to converge to an optimal solution without overshooting it.</li>
  <li>
    <p><strong>Regularization (lambda_reg)</strong>: This term is added to the loss function to penalize large values in the user and item factor vectors. It helps prevent the model from overfitting to the training data, ensuring it generalizes better to unseen items.</p>
  </li>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Rendle, S., Freudenthaler, C., Gantner, Z., &amp; Schmidt-Thieme, L. (2009). <em>BPR: Bayesian personalized ranking from implicit feedback</em>. <a href="https://arxiv.org/abs/1205.2618">https://arxiv.org/abs/1205.2618</a>.</li>
    </ul>
  </li>
  <li><strong>Replicability Study:</strong>
    <ul>
      <li>Deldjoo, Y., et al. (2024). <em>Revisiting BPR: A Replicability Study of a Common Recommender System Baseline</em>. <a href="https://arxiv.org/abs/2409.14217">https://arxiv.org/abs/2409.14217</a></li>
    </ul>
  </li>
  <li><strong>Useful Links:</strong>
    <ul>
      <li><a href="https://www.geeksforgeeks.org/machine-learning/recommender-system-using-bayesian-personalized-ranking/">Recommender System using Bayesian Personalized Ranking</a></li>
      <li><a href="https://medium.com/@radleaf/bpr-and-recommendation-system-3d9a3975c132">“BPR and Recommendation System” from Abby Yeh</a></li>
    </ul>
  </li>
</ul>

<h4 id="223-item-based-latent-models-slim--fism">2.2.3 Item-based Latent Models: SLIM &amp; FISM</h4>

<p><strong>Key concept:</strong> These models combine the interpretability of item-based methods with the power of latent factor models. Instead of relying on simple co-occurrence statistics, they learn an item-item similarity matrix directly from the interaction data using a machine learning model.</p>

<p><strong>Key differentiator:</strong></p>

<ul>
  <li><strong>SLIM (Sparse Linear Methods)</strong> learns a sparse item-item similarity matrix (W) by solving a regression problem. A user’s score for an item is a weighted sum of their interactions with other similar items. The sparsity (enforced by L1 regularization) makes the model efficient and interpretable—each item’s score is influenced by only a few other items.</li>
  <li><strong>FISM (Factored Item Similarity Models)</strong> takes a hybrid approach. Instead of learning the full item-item similarity matrix directly, it <em>factorizes</em> it into two lower-dimensional item embedding matrices. This allows it to learn transitive relationships (e.g., if item A is similar to B, and B is similar to C, then A and C might be similar) even if A and C were never co-rated, making it more powerful on extremely sparse datasets.</li>
</ul>

<p><strong>Use cases:</strong> Both models are designed for Top-N recommendation from implicit feedback. SLIM is highly effective and efficient, making it a strong baseline and suitable for production systems where speed and interpretability are critical. FISM is particularly advantageous in scenarios with very high data sparsity, where learning latent relationships is crucial.</p>

<p><strong>When to Consider:</strong> Choose <strong>SLIM</strong> when you need a fast, scalable, and interpretable item-based model that often outperforms more complex methods. It’s an excellent choice when you want a “learned” item-item similarity model. Consider <strong>FISM</strong> when facing extreme data sparsity. Its ability to generalize and find similarities between items that do not co-occur in the training data gives it a distinct advantage in such challenging scenarios.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>SLIM:</strong> Ning, X., &amp; Karypis, G. (2011). <em>SLIM: sparse linear methods for top-n recommender systems</em>. <a href="https://www.researchgate.net/publication/220765374_SLIM_Sparse_Linear_Methods_for_Top-N_Recommender_Systems">https://www.researchgate.net/publication/220765374_SLIM_Sparse_Linear_Methods_for_Top-N_Recommender_Systems</a>.</li>
      <li><strong>FISM:</strong> Kabbur, S., Badrul, S., &amp; Karypis, G. (2013). <em>FISM: factored item similarity models for top-n recommender systems</em>. <a href="http://chbrown.github.io/kdd-2013-usb/kdd/p659.pdf">http://chbrown.github.io/kdd-2013-usb/kdd/p659.pdf</a>.</li>
    </ul>
  </li>
  <li><strong>Useful links:</strong>
    <ul>
      <li><a href="https://roizner.medium.com/slim-a-fast-and-interpretable-baseline-for-recommender-algorithms-559cd73dcc55">“SLIM: A Fast and Interpretable Baseline for Recommender Algorithms” from Michael Roizner</a></li>
      <li><a href="https://github.com/KarypisLab/SLIM">The implementation of SLIM was written by George Karypis with contributions by Xia Ning, Athanasios N. Nikolakopoulos, Zeren Shui and Mohit Sharma.</a></li>
    </ul>
  </li>
</ul>

<h4 id="224-funksvd">2.2.4 FunkSVD</h4>

<p><strong>Key concept:</strong> FunkSVD, popularized by Simon Funk during the Netflix Prize, is an iterative matrix factorization approach that optimizes user and item latent factors using stochastic gradient descent (SGD) on observed ratings only, ignoring missing entries. It predicts ratings as the dot product of user and item vectors, with regularization to prevent overfitting.</p>

<p><strong>Key differentiator:</strong> Unlike traditional SVD, FunkSVD handles sparse matrices efficiently by focusing only on observed data and uses incremental updates, making it computationally lightweight and scalable for large datasets.</p>

<p><strong>Use cases:</strong> Predicting explicit ratings in domains like movie or product recommendation, particularly in large-scale systems where computational efficiency is critical. It is a robust baseline for collaborative filtering tasks.</p>

<p><strong>When to Consider:</strong> Use FunkSVD when you need a fast, scalable matrix factorization method for sparse datasets with explicit ratings. It is ideal for scenarios where computational resources are limited or as a baseline before exploring more complex models.</p>

<p><strong>Hyperparameters</strong></p>

<ul>
  <li><strong>k (Latent Factors)</strong>: Defines the number of latent dimensions for user and item vectors. This controls the model’s complexity and its ability to capture underlying patterns in the data.</li>
  <li><strong>Iterations</strong>: The number of times the algorithm iterates over the entire set of known ratings to update the latent factor vectors.</li>
  <li><strong>Learning Rate</strong>: Controls the step size for the stochastic gradient descent updates. A well-chosen learning rate is crucial for ensuring the model converges to a good solution without diverging.</li>
  <li>
    <p><strong>Regularization (lambda_reg)</strong>: A penalty term applied to the latent factors to prevent their values from becoming too large, which helps to avoid overfitting the training data.</p>
  </li>
  <li><strong>Seminal Reference:</strong>
    <ul>
      <li>Funk, S. (2006). <em>Netflix Update: Try This at Home</em>. <a href="https://sifter.org/~simon/journal/20061211.html">https://sifter.org/~simon/journal/20061211.html</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="225-puresvd">2.2.5 PureSVD</h4>

<p><strong>Key concept:</strong> PureSVD applies traditional Singular Value Decomposition (SVD) to the user-item interaction matrix, treating missing entries as zeros or using a preprocessing step to impute them. It decomposes the matrix into user and item latent factors, capturing the most significant patterns in the data.</p>

<p><strong>Key differentiator:</strong> PureSVD is a non-iterative approach that relies on standard linear algebra, making it simpler to implement than iterative methods like FunkSVD. However, it is less effective for very sparse matrices unless preprocessing is applied.</p>

<p><strong>Use cases:</strong> Recommending items in systems with dense interaction data or when preprocessing can mitigate sparsity. It is often used as a baseline for Top-N recommendation tasks.</p>

<p><strong>When to Consider:</strong> Use PureSVD when you have a relatively dense dataset or can preprocess the matrix to handle sparsity. It is suitable for quick prototyping or when simplicity is prioritized over handling extreme sparsity.</p>

<p><strong>Hyperparameters</strong></p>

<ul>
  <li>
    <p><strong>k (Latent Factors)</strong>: This is the primary hyperparameter for PureSVD. It specifies the number of top singular values (and corresponding vectors) to retain after the decomposition. This directly controls the dimensionality of the latent factor space and the level of detail captured by the model.</p>
  </li>
  <li>
    <p><strong>Reference:</strong></p>
    <ul>
      <li>Cremonesi, P., Koren, Y., &amp; Turrin, R. (2010). <em>Performance of Recommender Algorithms on Top-N Recommendation Tasks</em>. <a href="https://dl.acm.org/doi/10.1145/1864708.1864721">https://dl.acm.org/doi/10.1145/1864708.1864721</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="226-non-negative-matrix-factorization-nonnegmf">2.2.6 Non-Negative Matrix Factorization (NonNegMF)</h4>

<p><strong>Key concept:</strong> Non-Negative Matrix Factorization (NonNegMF) decomposes the user-item matrix into two non-negative matrices representing user and item latent factors. It ensures all latent factors are non-negative, which can lead to more interpretable features (e.g., representing genres or preferences).</p>

<p><strong>Key differentiator:</strong> The non-negativity constraint makes the latent factors more interpretable and can improve performance in domains where negative weights are less meaningful, such as implicit feedback datasets.</p>

<p><strong>Use cases:</strong> Recommending items in domains like e-commerce or media streaming, where interpretable latent factors (e.g., user preference for a specific genre) are valuable. It is effective for both explicit and implicit feedback.</p>

<p><strong>When to Consider:</strong> Use NonNegMF when interpretability of latent factors is important or when dealing with implicit feedback data where non-negative representations align with the domain’s semantics.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Lee, D. D., &amp; Seung, H. S. (1999). <em>Learning the Parts of Objects by Non-Negative Matrix Factorization</em>. <a href="https://www.nature.com/articles/44565">https://www.nature.com/articles/44565</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="227-svd">2.2.7 SVD++</h4>

<p><strong>Key concept:</strong> SVD++ extends traditional SVD by incorporating implicit feedback (e.g., clicks, views) into the matrix factorization process. It models user preferences using both explicit ratings and implicit interactions, adding a set of latent factors for implicit feedback to enhance prediction accuracy.</p>

<p><strong>Key differentiator:</strong> By integrating implicit feedback, SVD++ captures richer user behavior patterns, making it more robust for sparse datasets with both explicit and implicit signals.</p>

<p><strong>Use cases:</strong> Recommending items in systems with mixed feedback, such as movie platforms where users provide ratings and watch histories. It excels in improving prediction accuracy for sparse datasets.</p>

<p><strong>When to Consider:</strong> Use SVD++ when you have both explicit and implicit feedback data and want to leverage both to improve recommendation quality. It is a strong choice for enhancing traditional SVD in hybrid scenarios.</p>

<p><strong>Hyperparameters</strong></p>

<ul>
  <li><strong>k (Latent Factors)</strong>: The dimensionality of the user and item latent factor vectors.</li>
  <li><strong>Iterations</strong>: The number of times the algorithm will iterate over the training data to optimize the latent factors.</li>
  <li><strong>Learning Rate</strong>: The step size used in the stochastic gradient descent (SGD) optimization process to update the model’s parameters.</li>
  <li>
    <p><strong>Regularization (lambda_reg)</strong>: A penalty term applied to the latent factors and biases to prevent overfitting by discouraging overly complex models.</p>
  </li>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Koren, Y. (2008). <em>Factorization Meets the Neighborhood: A Multifaceted Collaborative Filtering Model</em>. <a href="https://dl.acm.org/doi/10.1145/1401890.1401944">https://dl.acm.org/doi/10.1145/1401890.1401944</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="228-weighted-regularized-matrix-factorization-wrmf">2.2.8 Weighted Regularized Matrix Factorization (WRMF)</h4>

<p><strong>Key concept:</strong> Weighted Regularized Matrix Factorization (WRMF) is designed for implicit feedback datasets, treating all non-interacted items as negative examples with lower confidence. It optimizes a weighted loss function, where interactions are weighted higher, and uses regularization to prevent overfitting.</p>

<p><strong>Key differentiator:</strong> WRMF’s focus on implicit feedback and its confidence-weighted loss make it highly effective for datasets with binary or frequency-based interactions, such as clicks or purchase histories. While WRMF defines the objective function, it is commonly optimized using an <strong>Alternating Least Squares (ALS)</strong> algorithm. This means ALS is the method used to find the latent factors that best fit the WRMF model.</p>

<p><strong>Use cases:</strong> Top-N recommendation in domains like e-commerce or streaming, where implicit feedback (e.g., clicks, plays) is abundant but explicit ratings are scarce.</p>

<p><strong>When to Consider:</strong> Use WRMF when working with implicit feedback datasets and aiming for high-quality Top-N recommendations. It is particularly effective in large-scale systems with sparse interaction data.</p>

<p><strong>Hyperparameters</strong></p>

<ul>
  <li><strong>k (Latent Factors)</strong>: The number of latent dimensions used to represent users and items.</li>
  <li><strong>Iterations</strong>: Since WRMF is trained with an iterative solver (ALS), this parameter defines the number of times the algorithm will alternate between solving for user and item factors.</li>
  <li><strong>Regularization (lambda_reg)</strong>: The regularization parameter used to penalize the magnitude of the latent factors, helping to prevent overfitting.</li>
  <li>
    <p><strong>Alpha</strong>: A confidence parameter that scales the importance of positive interactions. A higher alpha value indicates a higher confidence that a user’s interaction with an item is a positive preference.</p>
  </li>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Hu, Y., Koren, Y., &amp; Volinsky, C. (2008). <em>Collaborative Filtering for Implicit Feedback Datasets</em>. <a href="https://dl.acm.org/doi/10.1109/ICDM.2008.22">https://dl.acm.org/doi/10.1109/ICDM.2008.22</a>.
        <h4 id="229-collaborative-metric-learning-cml">2.2.9 Collaborative Metric Learning (CML)</h4>
      </li>
    </ul>
  </li>
</ul>

<p><strong>Key concept:</strong> Collaborative Metric Learning (CML) reframes collaborative filtering as a metric learning problem, learning a shared embedding space where the distance between user and item embeddings reflects their compatibility. It uses a pairwise loss to minimize distances for positive interactions and maximize them for negative ones.</p>

<p><strong>Key differentiator:</strong> Unlike traditional matrix factorization, CML focuses on distances in the embedding space, which can capture more nuanced relationships and is robust to cold-start scenarios when combined with content features.</p>

<p><strong>Use cases:</strong> Top-N recommendation in systems with implicit feedback, such as social media or e-commerce, where capturing fine-grained user-item compatibility is crucial.</p>

<p><strong>When to Consider:</strong> Use CML when you need a flexible approach that can incorporate side information (e.g., item metadata) and handle cold-start problems. It is a strong alternative to BPR for ranking tasks.</p>

<p><strong>Hyperparameters</strong></p>

<ul>
  <li><strong>k (Latent Factors)</strong>: The dimensionality of the embedding space where user and item vectors are represented.</li>
  <li><strong>Iterations</strong>: The number of training epochs, where the model iterates over the user-item interaction pairs.</li>
  <li><strong>Learning Rate</strong>: The step size for the gradient descent updates that adjust the positions of the user and item embeddings.</li>
  <li><strong>Regularization (lambda_reg)</strong>: A penalty applied to the embeddings to prevent them from growing too large, which helps in generalizing the model.</li>
  <li>
    <p><strong>Margin</strong>: A threshold used in the pairwise loss function. It defines how much closer a positive user-item pair should be in the embedding space compared to a negative pair.</p>
  </li>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Hsieh, C. K., Yang, L., Cui, Y., Lin, T. Y., Belongie, S., &amp; Estrin, D. (2017). <em>Collaborative Metric Learning</em>. <a href="https://arxiv.org/abs/1701.02398">https://arxiv.org/abs/1701.02398</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="python-frameworks-2">Python Frameworks</h4>

<ul>
  <li><strong>Surprise</strong> <a href="https://surpriselib.com/">https://surpriselib.com/</a>: Offers popular and well-documented implementations of SVD, SVD++, Probabilistic Matrix Factorization (PMF), and NonNegMF, with support for custom loss functions.</li>
  <li><strong>implicit</strong> <a href="https://github.com/benfred/implicit">https://github.com/benfred/implicit</a>: Provides high-performance implementations of ALS, BPR, and WRMF, optimized for implicit feedback datasets.</li>
  <li><strong>Cornac</strong> <a href="https://github.com/preferredAI/cornac">https://github.com/preferredAI/cornac</a>: Includes implementations of PMF, NonNegMF, and other MF variants as part of its comparative framework.</li>
  <li><strong>RecTools</strong> <a href="https://github.com/MobileTeleSystems/RecTools">https://github.com/MobileTeleSystems/RecTools</a>: Provides wrappers and implementations of matrix factorization models, including PureSVD and FunkSVD.</li>
  <li><strong>RecBole</strong> <a href="https://github.com/RUCAIBox/RecBole">https://github.com/RUCAIBox/RecBole</a>: Offers implementations of SLIM (as SLIMElastic), WRMF, and CML, with support for various regularization techniques.</li>
  <li><strong>LightFM</strong> <a href="https://github.com/lyst/lightfm">https://github.com/lyst/lightfm</a>: Supports WRMF and hybrid models that can incorporate side information, useful for CML.</li>
</ul>

<h4 id="production-ready-2">Production-ready?</h4>

<p>Matrix factorization is one of the most influential and widely deployed techniques in the history of recommender systems. Its ability to generalize from sparse data by learning latent representations made it a breakthrough technology, famously popularized by its success in the Netflix Prize competition. It remains a core component of many large-scale production systems and serves as the conceptual foundation for many advanced deep learning architectures, such as Neural Collaborative Filtering.</p>

<p>SLIM and its variants have demonstrated very strong performance in academic studies for the top-N recommendation task, often outperforming more complex methods. However, they are less commonly seen as standalone models in production systems compared to matrix factorization or k-NN. Their principles have influenced subsequent research, and they serve as powerful baselines for evaluating new item-based recommendation algorithms.</p>

<h3 id="23-deep-learning-hybrids--representation-learning">2.3 Deep Learning Hybrids &amp; Representation Learning</h3>

<p>This category marks the transition from linear latent factor models to more expressive, non-linear models powered by neural networks. By replacing the simple dot product with deep learning architectures, these models can capture more complex and subtle user-item interaction patterns that traditional methods might miss.</p>

<blockquote>
  <p><strong>What are non-linear relationships?</strong></p>

  <p>Think of it like this: a linear model assumes that if you like action movies twice as much, you’ll get twice the enjoyment from an action scene. A <strong>non-linear model</strong> understands that the relationship is more complex. Maybe you love action movies, but after two hours, your enjoyment plateaus or even drops. Neural networks are excellent at learning these kinds of nuanced, “it depends” relationships from the data automatically.</p>
</blockquote>

<h4 id="231-neural-collaborative-filtering-ncf">2.3.1 Neural Collaborative Filtering (NCF)</h4>

<p><strong>Key concept:</strong> NCF is a framework that generalizes Matrix Factorization (MF) by replacing its dot product with a neural network. Instead of just multiplying user and item latent vectors, NCF concatenates them and feeds them through a <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">Multi-Layer Perceptron (MLP)</a>. This allows the model to learn an arbitrary, complex interaction function between users and items.</p>

<p><strong>Key differentiator:</strong> Its primary advantage is the ability to capture <strong>complex, non-linear patterns</strong> in the data. While standard MF is restricted to a linear combination of factors, NCF can model synergistic effects—for example, it can learn that a user’s preference for the “sci-fi” genre and the “Christopher Nolan” director <em>together</em> creates a much stronger signal than the sum of the individual preferences.</p>

<p><strong>Use cases:</strong> NCF is a general-purpose model for collaborative filtering from implicit feedback. It is used for Top-N recommendation in various domains where user-item interactions might have complex patterns that matrix factorization cannot capture.</p>

<p><strong>When to Consider:</strong> Consider using NCF when you suspect that the underlying user-item interactions are too complex to be modeled by a simple dot product. If standard matrix factorization models are hitting a performance plateau, NCF is a logical next step to introduce non-linearity and increase model expressiveness, provided you have enough data to train a deeper model without overfitting.</p>

<p><strong>Training Data for NCF</strong> NCF is a collaborative filtering model, so it learns directly from a history of user-item interactions. The ideal training data is a log or table that records which users have interacted with which items.</p>

<ul>
  <li>Implicit Feedback (Most Common): This is the most common type of data used with NCF. It includes signals like clicks, views, purchases, or time spent on a page. Each interaction is treated as a positive signal. For example, a dataset would look like a simple table with user_id and item_id columns.</li>
  <li>Explicit Feedback: This includes direct ratings, like a 1-5 star review. While NCF can be adapted for this, it’s primarily designed to handle the more common and abundant implicit signals.</li>
</ul>

<p>During training, for each positive interaction (an item a user did interact with), you typically sample one or more negative examples (items the user did not interact with) to help the model learn to distinguish between liked and disliked items.</p>

<p><strong>Input Signals</strong> The core input signals for NCF are very simple: user IDs and item IDs. The model creates two large embedding tables: one for all users and one for all items. When you feed a (user_id, item_id) pair into the model, it looks up the corresponding embedding vector for that specific user and that specific item. An embedding is just a dense vector of numbers that represents the user’s tastes or the item’s characteristics.</p>

<p>These two vectors—the user embedding and the item embedding—are the actual numerical inputs that are then processed by the neural network layers to produce a prediction score.</p>

<p>The model learns the best embedding values for all users and items during the training process. No other features are required for the base NCF model.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>He, X., Liao, L., Zhang, H., Nie, L., Hu, X., &amp; Chua, T. S. (2017). <em>Neural Collaborative Filtering</em>. <a href="https://arxiv.org/abs/1708.05031">https://arxiv.org/abs/1708.05031</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="232-factorization-machine-based-deepfm--xdeepfm">2.3.2 Factorization Machine-based: DeepFM &amp; xDeepFM</h4>

<p><strong>Key concept:</strong> These models are advanced hybrid architectures designed primarily for Click-Through Rate (CTR) prediction. They combine a “wide” component for learning simple, memorable feature interactions and a “deep” component for learning complex, generalizable patterns. Both components share the same input embeddings, making training highly efficient.</p>

<blockquote>
  <p><strong>What is Click-Through Rate (CTR) Prediction?</strong></p>

  <p><strong>CTR prediction</strong> is the task of estimating the probability that a user will click on an item (like an ad, a product, or a news article) if it is shown to them. It’s a critical task in online advertising and recommendation, as it directly relates to engagement and revenue. Models that are good at CTR prediction excel at understanding what makes a user click in a specific context.</p>
</blockquote>

<p><strong>Key differentiator:</strong></p>

<ul>
  <li><strong>DeepFM</strong> combines a <strong>Factorization Machine (FM)</strong> for the “wide” part and a standard MLP for the “deep” part. The FM component is highly effective at learning 2nd-order feature interactions (e.g., how the combination of “user is a teenager” and “item is a video game” affects clicks) without manual effort.</li>
  <li><strong>xDeepFM (eXtreme DeepFM)</strong> improves upon this by replacing the standard MLP with a <strong>Compressed Interaction Network (CIN)</strong>. The CIN is specifically designed to explicitly learn high-order feature interactions in a more controlled, vector-wise manner, which can be more powerful and interpretable than the implicit interactions learned by an MLP.</li>
</ul>

<p><strong>Use cases:</strong> Both models are state-of-the-art for CTR prediction in large-scale industrial recommender systems, such as those used in online advertising, e-commerce, and news feeds. They are designed to handle high-dimensional, sparse, and multi-field categorical features (e.g., user demographics, item category, time of day).</p>

<p><strong>When to Consider:</strong> You may consider these models for any feature-rich recommendation task, especially CTR prediction. <strong>DeepFM</strong> is a powerful and widely used baseline. However, if you believe that explicit, high-order feature combinations are particularly important in your domain (e.g., “young user” + “sports category” + “weekend”), <strong>xDeepFM</strong>’s CIN component offers a more targeted mechanism for learning them.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>DeepFM:</strong> Guo, H., Tang, R., Ye, Y., Li, Z., &amp; He, X. (2017). <em>DeepFM: A Factorization-Machine based Neural Network for CTR Prediction</em>. <a href="https://arxiv.org/abs/1703.04247">https://arxiv.org/abs/1703.04247</a>.</li>
      <li><strong>xDeepFM:</strong> Lian, J., Zhou, X., Zhang, F., Chen, Z., Xie, X., &amp; Sun, G. (2018). <em>xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems</em>. <a href="https://arxiv.org/abs/1803.05170">https://arxiv.org/abs/1803.05170</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="233-autoencoder-based-dae--vae">2.3.3 Autoencoder-based: DAE &amp; VAE</h4>

<p><strong>Key concept:</strong> This approach frames collaborative filtering as a reconstruction task. It takes a user’s entire interaction history (e.g., a sparse vector of all items they’ve clicked on) as input and trains a neural network—the autoencoder—to compress this information into a dense low-dimensional latent vector and then reconstruct the original interaction vector from it.</p>

<blockquote>
  <p><strong>What is an Autoencoder?</strong></p>

  <p>An <strong>autoencoder</strong> is a type of neural network trained to learn a compressed representation of its input data. It has two main parts: an <strong>encoder</strong> that maps the input to a low-dimensional “bottleneck” representation, and a <strong>decoder</strong> that tries to reconstruct the original input from this compressed version. By forcing data through this bottleneck, the network learns the most important and salient features.</p>
</blockquote>

<p><strong>Key differentiator:</strong></p>

<ul>
  <li><strong>CDAE (Collaborative Denoising Autoencoder)</strong> for CF learns robust representations by being trained to reconstruct the <em>original, complete</em> user history from a <em>partially corrupted</em> input. This forces the model to learn the underlying relationships between items to “fill in the blanks.”</li>
  <li><strong>MultiVAE</strong> extends the <strong>VAE (Variational Autoencoder)</strong> framework, a <strong>probabilistic, generative</strong> model, for recommendation. Instead of mapping a user to a single latent vector, it maps them to a probability distribution, which better captures the uncertainty in user preferences. It is particularly effective for implicit feedback due to its use of a multinomial likelihood.</li>
  <li><strong>EASE (Embarrassingly Shallow Autoencoders)</strong> is a non-neural, linear autoencoder that has a closed-form solution. Despite its simplicity, it is an extremely strong baseline that often outperforms complex deep learning models, highlighting the power of the autoencoder concept itself.</li>
</ul>

<p><strong>Use cases:</strong> These models are highly effective for Top-N recommendation from implicit feedback. <strong>MultiVAE</strong>, in particular, has become a very strong and widely used baseline for collaborative filtering, often achieving state-of-the-art results. <strong>EASE</strong> serves as a critical, high-performance baseline for any new collaborative filtering model.</p>

<p><strong>When to Consider:</strong> Consider using an autoencoder-based model when linear latent factor models are insufficient. <strong>DAE</strong>s are a good choice for learning robust representations from noisy interaction data. <strong>VAE</strong>s are an even stronger choice for implicit feedback Top-N tasks, as their probabilistic nature and multinomial likelihood objective are exceptionally well-suited for the ranking problem. They are a go-to model for researchers and practitioners aiming for top performance in collaborative filtering.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>DAE (for RecSys):</strong> Wu, Y., DuBois, C., Zheng, A. X., &amp; Ester, M. (2016). <em>Collaborative Denoising Auto-Encoders for Top-N Recommender Systems</em>. <a href="https://dl.acm.org/doi/10.1145/2835776.2835837">https://dl.acm.org/doi/10.1145/2835776.2835837</a>.</li>
      <li><strong>VAE (for RecSys):</strong> Liang, D., Krishnan, R. G., Hoffman, M. D., &amp; Jebara, T. (2018). <em>Variational Autoencoders for Collaborative Filtering</em>. <a href="https://arxiv.org/abs/1802.05814">https://arxiv.org/abs/1802.05814</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="234-neural-matrix-factorization-neumf">2.3.4 Neural Matrix Factorization (NeuMF)</h4>

<p><strong>Key concept:</strong> Neural Matrix Factorization (NeuMF) is an advanced version of Neural Collaborative Filtering (NCF) that combines a generalized matrix factorization (GMF) component with a multilayer perceptron (MLP). The GMF learns linear interactions similar to traditional matrix factorization, while the MLP captures non-linear patterns, and their outputs are fused to predict user-item compatibility.</p>

<p><strong>Key differentiator:</strong> NeuMF’s hybrid architecture leverages both linear and non-linear modeling, offering superior performance over NCF by balancing the simplicity of matrix factorization with the expressiveness of deep learning.</p>

<p><strong>Use cases:</strong> Top-N recommendation in domains like streaming or e-commerce, where complex interaction patterns require both linear and non-linear modeling for optimal performance.</p>

<p><strong>When to Consider:</strong> Use NeuMF when you need a high-performance model that builds on NCF’s capabilities. It is ideal for scenarios with abundant implicit feedback data and when computational resources allow for training a hybrid neural model.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>He, X., Liao, L., Zhang, H., Nie, L., Hu, X., &amp; Chua, T. S. (2017). <em>Neural Collaborative Filtering</em>. <a href="https://arxiv.org/abs/1708.05031">https://arxiv.org/abs/1708.05031</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="python-frameworks-3">Python Frameworks</h4>

<ul>
  <li><strong>Tensorflow</strong> <a href="https://github.com/tensorflow/tensorflow">https://github.com/tensorflow/tensorflow</a>: The TensorFlow Model Garden includes an official implementation and tutorial for building NCF and NeuMF models.</li>
  <li><strong>Microsoft Recommenders</strong> <a href="https://github.com/recommenders-team/recommenders">https://github.com/recommenders-team/recommenders</a>: Provides a detailed Jupyter notebook implementation of NCF and NeuMF, explaining both theory and practical application. Also includes an example notebook for xDeepFM.</li>
  <li><strong>Cornac</strong> <a href="https://github.com/PreferredAI/cornac">https://github.com/PreferredAI/cornac</a>: Features an implementation of BiVAECF (Bilateral Variational Autoencoder for Collaborative Filtering).</li>
  <li><strong>RecBole</strong> <a href="https://recbole.io/docs/user_guide/model/context/deepfm.html">https://recbole.io/docs/user_guide/model/context/deepfm.html</a>: Provides implementations of DeepFM, xDeepFM, and NeuMF.</li>
  <li><strong>LibRecommender</strong> <a href="https://github.com/massquantity/LibRecommender">https://github.com/massquantity/LibRecommender</a>: Offers a TensorFlow-based implementation of DeepFM and NeuMF with extensive configuration options.</li>
</ul>

<h4 id="production-ready-3">Production-ready?</h4>

<p>NCF is a seminal deep learning model for recommendation that has had a significant impact on the field. It is widely used in industry, both as a powerful standalone model and as a strong baseline for evaluating more advanced architectures. Its core architectural principles have influenced the design of many subsequent models.</p>

<p>VAE-based models for collaborative filtering, particularly the Mult-VAE variant which uses a multinomial likelihood objective, have proven to be highly effective and often achieve state-of-the-art results on academic benchmarks. They are used in production systems, but also remain a very active area of research, with new extensions being developed for multimodal data , interactive critiquing , and multi-criteria recommendation.</p>

<p>DeepFM and xDeepFM are considered state-of-the-art models for tabular CTR prediction and are widely deployed in production systems for applications like computational advertising, feed ranking, and product recommendation.</p>

<h3 id="24-sequential--session-based-models">2.4 Sequential &amp; Session-Based Models</h3>

<p>This paradigm marks a fundamental shift from treating user interactions as an unordered set to modeling them as an ordered sequence. The goal is to predict the user’s <em>next</em> action based on the temporal dynamics of their recent behavior. This shift reflects a powerful conceptual convergence with the field of Natural Language Processing (NLP), where a sequence of user interactions is treated analogously to a sequence of words in a sentence.</p>

<blockquote>
  <p><strong>Why does order matter?</strong></p>

  <p>Imagine a shopping session. A user who clicks on “iPhone -&gt; iPhone Case -&gt; Screen Protector” has a very clear and different intent from a user who clicks on “iPhone -&gt; Laptop -&gt; Headphones.” The first user is accessorizing a specific product, while the second is browsing different categories. Sequential models are designed to understand these ordered patterns to make much more contextually relevant “what’s next” predictions.</p>
</blockquote>

<h4 id="241-rnn-based-gru4rec">2.4.1 RNN-based: GRU4Rec</h4>

<p><strong>Key concept:</strong> GRU4Rec was a pioneering model that applied Recurrent Neural Networks (RNNs) to session-based recommendation. It processes a sequence of user interactions one by one, maintaining a “memory” or hidden state that evolves with each new item. This state captures the user’s current intent, which is then used to predict the very next item they are likely to interact with.</p>

<blockquote>
  <p><strong>What is an RNN?</strong></p>

  <p>A <strong>Recurrent Neural Network (RNN)</strong> is a type of neural network designed for sequential data. Think of it as having a short-term memory. As it reads a sequence (like words in a sentence or items in a session), it passes information from one step to the next. This allows it to understand context and order, making it perfect for predicting what comes next based on what happened before. The <strong>GRU (Gated Recurrent Unit)</strong> is an advanced and efficient type of RNN.</p>
</blockquote>

<p><strong>Key differentiator:</strong> Its core innovation was using RNNs to handle variable-length, anonymous user sessions. Unlike static models, GRU4Rec captures the evolving nature of user intent within a single session. It also introduced ranking-aware loss functions to directly optimize for the quality of the recommended list, not just prediction accuracy.</p>

<p><strong>Use cases:</strong> GRU4Rec is designed for session-based recommendation, where user identity may be unknown or irrelevant (e.g., guest shoppers). It is common in e-commerce for predicting the next product click, in media streaming for the next song or video, and in news for the next article.</p>

<p><strong>When to Consider:</strong> GRU4Rec is a strong baseline for any sequential or session-based task where short-term context and the order of interactions are critical. It’s particularly useful when a user’s intent evolves throughout a session and you need to make real-time, next-step predictions.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Hidasi, B., Karatzoglou, A., Baltrunas, L., &amp; Tikk, D. (2016). <em>Session-based Recommendations with Recurrent Neural Networks</em>. <a href="https://arxiv.org/abs/1511.06939">https://arxiv.org/abs/1511.06939</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="242-cnn-based-nextitnet">2.4.2 CNN-based: NextItNet</h4>

<p><strong>Key concept:</strong> NextItNet applies Convolutional Neural Networks (CNNs), traditionally used for image processing, to model sequences of user interactions. It treats an embedded sequence of items as a 1D “image” and uses stacked layers of <em>dilated convolutions</em> to efficiently identify patterns and long-range dependencies.</p>

<blockquote>
  <p><strong>How can a CNN work on a sequence?</strong></p>

  <p>Imagine the sequence of items is laid out like a single row of pixels. A <strong>CNN</strong> applies “filters” that slide across this row to recognize local patterns (e.g., “item A is often followed by item B”). By using <strong>dilated convolutions</strong>, which skip inputs at varying rates, the network can create a very large receptive field, allowing it to see how an item at the beginning of a long session influences an item at the end, all without the step-by-step processing of an RNN.</p>
</blockquote>

<p><strong>Key differentiator:</strong> The main advantage of NextItNet over RNNs is <strong>efficiency and parallelism</strong>. CNNs can process all parts of a sequence simultaneously, making training much faster. Its use of dilated convolutions and residual blocks allows it to build very deep networks that can capture dependencies across extremely long sequences (hundreds of items) where RNNs might struggle with vanishing gradients.</p>

<p><strong>Use cases:</strong> NextItNet is used for session-based and sequential Top-N item recommendation. It is particularly well-suited for scenarios with very long user interaction sequences and where training efficiency on large datasets is a major concern.</p>

<p><strong>When to Consider:</strong> Consider NextItNet when training speed is a priority or when dealing with very long sequences where capturing long-range dependencies is crucial. It represents a powerful and scalable architectural alternative to RNNs for modeling sequential data.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Yuan, F., Karatzoglou, A., Arapakis, I., Jose, J. M., &amp; He, X. (2019). <em>A Simple Convolutional Generative Network for Next Item Recommendation</em>. <a href="https://dl.acm.org/doi/10.1145/3289600.3290975">https://dl.acm.org/doi/10.1145/3289600.3290975</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="243-attentiontransformer-based-sasrec--bert4rec">2.4.3 Attention/Transformer-based: SASRec &amp; BERT4Rec</h4>

<p><strong>Key concept:</strong> This family of models leverages the <strong>self-attention mechanism</strong>, the core component of the Transformer architecture that has revolutionized NLP. Self-attention allows the model to dynamically weigh the importance of <em>all</em> other items in a sequence when making a prediction for the next item, overcoming the sequential processing bottleneck of RNNs and the fixed receptive field of CNNs.</p>

<blockquote>
  <p><strong>What is Self-Attention?</strong></p>

  <p><strong>Self-attention</strong> is a mechanism that allows a model to look at other items in the input sequence and decide which ones are most important for understanding the current item. For recommendation, this means that to predict your next action, the model can pay more attention to the very first item you clicked on, or a specific item you lingered on, regardless of its position in the sequence. It learns to identify the most influential past actions on the fly.</p>
</blockquote>

<p><strong>Key differentiator:</strong> The key innovation is the use of self-attention, providing a global view of the sequence. The distinction between the two main models is crucial:</p>

<ul>
  <li><strong>SASRec (Self-Attentive Sequential Recommendation)</strong> is <strong>unidirectional</strong> (autoregressive). It only considers past items to predict the future, strictly respecting the temporal flow of user actions. It excels at identifying which of the previous items are most relevant for the <em>next</em> choice.</li>
  <li><strong>BERT4Rec (Bidirectional Encoder Representations from Transformers for Recommendation)</strong> is <strong>bidirectional</strong>. Inspired by BERT in NLP, it is trained using a “cloze task” where it predicts a randomly masked item in the sequence using both its left and right context (items that came before and after). This allows it to learn a richer, more holistic representation of user interests.</li>
</ul>

<p><strong>Use cases:</strong> These models represent the state-of-the-art for sequential recommendation tasks. <strong>SASRec</strong> is a powerful general-purpose model for next-item prediction. <strong>BERT4Rec</strong> is particularly effective when a user’s overall interest is a reflection of their entire history. Specialized variants extend this architecture for specific domains; for example, <strong>NRMS</strong> is designed for news recommendation, using attention to model article content, while <strong>TiSASRec</strong> incorporates timestamps to better model the time intervals between user interactions.</p>

<p><strong>When to Consider:</strong> Transformer-based models should be the default choice for high-performance sequential recommendation. Choose <strong>SASRec</strong> for tasks where strict temporal order is paramount. Consider <strong>BERT4Rec</strong> when you have dense data and believe a user’s intent is better captured by their holistic interaction history.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>SASRec:</strong> Kang, W. C., &amp; McAuley, J. (2018). <em>Self-Attentive Sequential Recommendation</em>. <a href="https://arxiv.org/abs/1808.09781">https://arxiv.org/abs/1808.09781</a>.</li>
      <li><strong>BERT4Rec:</strong> Sun, F., Liu, J., Wu, J., Pei, C., Lin, X., Ou, W., &amp; Jiang, P. (2019). <em>BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer</em>. <a href="https://arxiv.org/abs/1904.06690">https://arxiv.org/abs/1904.06690</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="244-with-contrastive-learning-cl4srec">2.4.4 With Contrastive Learning: CL4SRec</h4>

<p><strong>Key concept:</strong> CL4SRec is a framework that enhances sequential models by adding a <strong>contrastive…(truncated 118149 characters)…ence?</strong></p>

<blockquote>
  <p>It’s like the difference between a music critic and a composer.</p>

  <ul>
    <li>A <strong>Discriminative</strong> model is the <strong>critic</strong>. You give it a user and a song, and it <em>discriminates</em> by giving a score or a probability: “This user will like this song with 85% probability.” It learns the boundary between what a user likes and dislikes.</li>
    <li>A <strong>Generative</strong> model is the <strong>composer</strong> 🎼. You give it a user, and it <em>generates</em> a new playlist from scratch that it thinks the user will love. It learns the underlying patterns and structure of a user’s taste so well that it can create new examples.</li>
  </ul>

</blockquote>

<h4 id="261-generative-adversarial-networks-gans-irgan">2.6.1 Generative Adversarial Networks (GANs): IRGAN</h4>

<p><strong>Key concept:</strong> IRGAN adapts the GAN framework to recommendation by setting up a competitive game between two neural networks:</p>

<ol>
  <li>A <strong>Generator</strong>, which acts as the recommender. It tries to learn the true distribution of a user’s preferences and generates “fake” (user, item) pairs that it predicts are relevant.</li>
  <li>A <strong>Discriminator</strong>, which acts as a critic. It is trained to distinguish between the “fake” items suggested by the Generator and the actual items from the user’s real interaction history.</li>
</ol>

<p>Through this adversarial training, the Generator is forced to produce increasingly realistic recommendations to “fool” the Discriminator, thereby learning a more robust model of user preferences.</p>

<p><strong>Key differentiator:</strong> The <strong>adversarial training process</strong> itself is unique. It creates a dynamic optimization landscape where the Generator effectively performs “hard negative mining” by trying to find the most challenging examples to fool the Discriminator. This can help the model learn to recommend more diverse and novel items, overcoming biases in the training data.</p>

<p><strong>Use cases:</strong> IRGAN is a general framework applicable to web search, item recommendation, and other information retrieval tasks. It’s used to learn the distribution of user preferences and generate a ranked list of items, with the potential to improve coverage of long-tail items.</p>

<p><strong>When to Consider:</strong> Consider exploring GANs for research-oriented projects or when traditional models seem to be underperforming due to data bias. While conceptually powerful, GAN-based recommenders are notoriously difficult and unstable to train, which has limited their widespread adoption in production.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Wang, J., Yu, L., Zhang, W., Gong, Y., Xu, Y., Wang, B., Zhang, P., &amp; Zhang, D. (2017). <em>IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models</em>. <a href="https://arxiv.org/abs/1705.10513">https://arxiv.org/abs/1705.10513</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="262-diffusion-for-cf-diffrec">2.6.2 Diffusion for CF: DiffRec</h4>

<p><strong>Key concept:</strong> DiffRec adapts the powerful Denoising Diffusion Probabilistic Models (DDPMs) from image generation to recommendation. The process has two stages:</p>

<ol>
  <li><strong>Forward (Diffusion) Process:</strong> It starts with a user’s true interaction vector (e.g., a multi-hot vector of liked items) and gradually adds Gaussian noise over a series of steps, eventually corrupting it into pure noise.</li>
  <li><strong>Reverse (Denoising) Process:</strong> A neural network is trained to reverse this process. It learns to take a noisy vector at any step and predict the noise that was added, thereby iteratively denoising it back to the original, clean interaction vector.</li>
</ol>

<p>To generate recommendations, the model starts with random noise and, conditioned on a user’s profile, runs this reverse process to generate a new, plausible interaction vector.</p>

<p><strong>Key differentiator:</strong> The iterative <strong>denoising process</strong> is a fundamentally different generative paradigm from GANs or VAEs. It is often more stable to train than GANs and can model highly complex data distributions, leading to high-quality and diverse generated outputs. This makes it particularly well-suited for capturing the uncertainty and multi-modal nature of user preferences.</p>

<p><strong>Use cases:</strong> DiffRec is a generative model for Top-N recommendation from implicit feedback. Its strength lies in its ability to model complex preference distributions and its robustness to noisy interactions in the training data.</p>

<p><strong>When to Consider:</strong> Consider DiffRec when you need a powerful generative model that can capture complex user preferences and where recommendation <strong>diversity and novelty</strong> are key objectives. It represents the cutting edge of generative modeling, but be mindful that it is computationally intensive, especially during the iterative sampling process at inference time.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Wang, W., Feng, F., He, X., Wang, X., &amp; Wang, Q. (2023). <em>Diffusion Recommender Model</em>. <a href="https://arxiv.org/abs/2304.04971">https://arxiv.org/abs/2304.04971</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="263-gflownets-gfn4rec">2.6.3 GFlowNets: GFN4Rec</h4>

<p><strong>Key concept:</strong> GFN4Rec uses Generative Flow Networks (GFlowNets) to frame recommendation as a sequential decision problem. It learns to construct a <em>list</em> of recommended items step-by-step. The model is trained to ensure that the probability of generating a particular list is directly proportional to a predefined <strong>reward</strong> function (e.g., the predicted overall quality or utility of that list).</p>

<p><strong>Key differentiator:</strong> Unlike most models that score items individually, GFN4Rec directly optimizes for the utility of an <strong>entire slate of recommendations</strong>. Its training objective inherently promotes <strong>diversity</strong>; if two different lists yield a similar high reward, the GFlowNet learns to assign both a high probability of being generated, rather than collapsing to a single “best” list.</p>

<p><strong>Use cases:</strong> GFN4Rec is specifically designed for <strong>listwise recommendation</strong> tasks where both the relevance and diversity of the recommended set are important. It is well-suited for online environments where exploration and the discovery of novel good recommendations are valuable.</p>

<p><strong>When to Consider:</strong> Consider GFN4Rec when the business objective is to optimize for the utility of an entire slate, not just individual item clicks. If recommendation diversity is a key performance indicator, GFN4Rec’s intrinsic diversity-promoting objective makes it a very compelling choice over models trained with standard cross-entropy loss.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Liu, J., Jin, Z., Liu, D., He, X., &amp; McAuley, J. (2023). <em>Generative Flow Network for Listwise Recommendation</em>. <a href="https://arxiv.org/abs/2306.02239">https://arxiv.org/abs/2306.02239</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="264-normalizing-flows-idnp">2.6.4 Normalizing Flows: IDNP</h4>

<p><strong>Key concept:</strong> Normalizing Flows are a class of generative models that learn a complex data distribution by applying a series of <strong>invertible and differentiable transformations</strong> to a simple base distribution (e.g., a standard Gaussian). Because every step is perfectly reversible, they can calculate the exact likelihood of any data point, a property not shared by VAEs or GANs.</p>

<p><strong>Key differentiator:</strong> The ability to compute the <strong>exact log-likelihood</strong> makes Normalizing Flows a principled and powerful tool for precise density estimation. In the context of recommendation, a related model like <strong>IDNP (Interest Dynamics Neural Process)</strong> uses this concept to model a <em>distribution over a user’s preference function over time</em>, allowing it to capture uncertainty and generalize from very few data points.</p>

<p><strong>Use cases:</strong> In recommendation, Normalizing Flows can learn highly expressive models of user or item embedding distributions. They are particularly promising for few-shot or cold-start sequential recommendation tasks, where modeling the uncertainty in a user’s evolving taste is critical.</p>

<p><strong>When to Consider:</strong> Normalizing Flows are an advanced generative modeling technique. Consider them for research purposes or in applications where precise density estimation of user preferences is critical. They are generally more complex to implement and train than other generative models.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>Foundational:</strong> Rezende, D. J., &amp; Mohamed, S. (2015). <em>Variational Inference with Normalizing Flows</em>. <a href="https://arxiv.org/abs/1505.05770">https://arxiv.org/abs/1505.05770</a>.</li>
      <li><strong>IDNP:</strong> Du, W., Wang, H., Xu, C., &amp; Zhang, Y. (2023). <em>Interest Dynamics Modeling with Neural Processes for Sequential Recommendation</em>. <a href="https://arxiv.org/abs/2209.15236">https://arxiv.org/abs/2209.15236</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="python-frameworks-4">Python Frameworks</h4>

<ul>
  <li><strong>IRGAN:</strong> <a href="https://github.com/geek-ai/irgan">https://github.com/geek-ai/irgan</a> The original implementation is at <strong>geek-ai/irgan</strong> on GitHub. Implementations are typically done from scratch in core deep learning libraries.</li>
  <li><strong>DiffRec:</strong> <a href="https://github.com/YiyanXu/DiffRec">https://github.com/YiyanXu/DiffRec</a> Research implementations from the seminal papers are available on GitHub at <strong>YiyanXu/DiffRec</strong> and <strong>WHUIR/DiffuRec</strong>.</li>
  <li><strong>GFN4Rec:</strong> <a href="https://github.com/CharlieMat/GFN4Rec">https://github.com/CharlieMat/GFN4Rec</a> The model whose implementations is primarily found in the authors’ research repositories on GitHub.</li>
</ul>

<h4 id="production-ready-4">Production-ready?</h4>

<ul>
  <li><strong>All Models in this Section:</strong> <strong>Research Interest.</strong> This entire category represents the frontier of recommendation research.
    <ul>
      <li><strong>GANs (IRGAN):</strong> While conceptually powerful, they are notoriously difficult to train and stabilize, which has prevented widespread production adoption.</li>
      <li><strong>Diffusion (DiffRec):</strong> This area is generating significant excitement and strong benchmark results. However, the models are computationally intensive, especially the iterative sampling process at inference time, making low-latency production deployment a major challenge.</li>
      <li><strong>GFlowNets &amp; Normalizing Flows:</strong> These are highly promising but complex paradigms that are still in the early stages of exploration for recommendation tasks.</li>
    </ul>
  </li>
</ul>

<h2 id="section-3-text-driven-recommendation-algorithms">Section 3: Text-Driven Recommendation Algorithms</h2>

<p>This section shifts focus to algorithms that explicitly leverage unstructured text, primarily user reviews and item descriptions. The advent of powerful NLP models, especially Large Language Models, has dramatically expanded the capabilities in this domain.</p>

<h3 id="31-review-based-models">3.1 Review-Based Models</h3>

<p>These models mine user-generated reviews to extract rich, nuanced information about user preferences and item attributes. This helps to alleviate the data sparsity and cold-start problems inherent in interaction-only models. The use of text provides a powerful bridge, improving performance and offering a natural pathway to explainability.</p>

<blockquote>
  <p><strong>Why read the reviews?</strong></p>

  <p>A 5-star rating tells you <em>what</em> a user liked, but the review tells you <em>why</em>. One user might give a phone 5 stars for its “amazing camera,” while another gives the same rating for its “incredible battery life.” Review-based models “read” this text to understand these nuances, allowing them to differentiate between users with the same ratings but different preferences, leading to far more personalized recommendations.</p>
</blockquote>

<h4 id="311-deepconn-deep-cooperative-neural-networks">3.1.1 DeepCoNN (Deep Cooperative Neural Networks)</h4>

<p><strong>Key concept:</strong> DeepCoNN uses a dual deep learning architecture. One Convolutional Neural Network (CNN) processes the concatenation of all reviews written <em>by</em> a target user to learn a latent user representation. In parallel, a second CNN processes all reviews written <em>for</em> a target item to learn a latent item representation. These two vectors are then combined to predict the final rating.</p>

<p><strong>Key differentiator:</strong> It was a foundational model demonstrating that user and item profiles could be learned <em>end-to-end directly from raw text</em>. Instead of manual feature engineering, it lets the neural networks discover what aspects of language are important for representing users and items.</p>

<p><strong>Use cases:</strong> Rating prediction in review-rich environments like Amazon, Yelp, and other e-commerce or content platforms. It is particularly effective at alleviating the cold-start problem, as it can generate meaningful representations from text even when rating data is sparse.</p>

<p><strong>When to Consider:</strong> Consider DeepCoNN when you need to leverage review text to improve rating prediction, especially for users or items with few ratings. It is a foundational model that serves as a strong baseline for more advanced text-based models.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Zheng, L., Noroozi, V., &amp; Yu, P. (2017). <em>Joint Deep Modeling of Users and Items Using Reviews for Recommendation</em>. <a href="https://arxiv.org/abs/1701.04783">https://arxiv.org/abs/1701.04783</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="312-narre-neural-attentional-rating-regression-with-review-level-explanations">3.1.2 NARRE (Neural Attentional Rating Regression with Review-level Explanations)</h4>

<p><strong>Key concept:</strong> NARRE enhances the idea of DeepCoNN by incorporating a dual <strong>attention mechanism</strong>. It learns to identify and assign higher weights to the most useful and informative reviews when constructing the user and item representations, effectively filtering out noisy or irrelevant content.</p>

<p><strong>Key differentiator:</strong> The <strong>attention mechanism</strong> is the key innovation. It not only improves prediction accuracy by focusing on what’s important but also provides a natural path to <strong>explainability</strong>. The model can highlight the specific reviews that were most influential in making a recommendation, which can significantly increase user trust.</p>

<p><strong>Use cases:</strong> NARRE is designed for rating prediction in systems where user reviews are abundant (e-g., e-commerce, service platforms). Its ability to provide explanations makes it valuable for applications where user trust and transparency are important.</p>

<p><strong>When to Consider:</strong> Use NARRE when you have a rich dataset of user reviews and want to improve rating prediction accuracy while also generating explanations. It is a powerful tool for building more transparent and trustworthy recommender systems.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Chen, C., Zhang, M., Liu, Y., &amp; Ma, S. (2018). <em>Neural Attentional Rating Regression with Review-level Explanations</em>. <a href="https://dl.acm.org/doi/10.1145/3178876.3186070">https://dl.acm.org/doi/10.1145/3178876.3186070</a>.</li>
    </ul>
  </li>
</ul>

<h3 id="32-large-language-model-llm-based-paradigms">3.2 Large Language Model (LLM)-Based Paradigms</h3>

<p>The emergence of Large Language Models (LLMs) has created a paradigm shift, reformulating recommendation as a language understanding and generation problem. LLMs can be applied in various ways, from acting as powerful feature extractors to serving as the core recommendation engine itself.</p>

<blockquote>
  <p><strong>The Paradigm Shift: From Pattern Matching to Language Understanding</strong></p>

  <p>Traditional recommenders are expert <strong>pattern matchers</strong>, finding correlations in a huge matrix of clicks and purchases. LLM-based recommenders aim to be <strong>comprehension engines</strong>. They can understand the <em>semantic meaning</em> of an item description, infer intent from a user’s natural language query, and leverage vast world knowledge (e.g., knowing that “cyberpunk” is a theme connecting <em>Blade Runner</em> and <em>Ghost in the Shell</em>) to make recommendations based on a deeper level of understanding.</p>
</blockquote>

<h4 id="321-retrieval-based-dense-retrieval--cross-encoders">3.2.1 Retrieval-based: Dense Retrieval &amp; Cross-Encoders</h4>

<p><strong>Key concept:</strong> This paradigm adopts the two-stage “retrieve-then-rank” architecture common in modern information retrieval.</p>

<ol>
  <li><strong>Dense Retrieval (Bi-Encoder):</strong> A fast “retrieval” stage that uses one model to independently encode the user’s query/profile into a vector and another to encode all items in the catalog. It then uses efficient Approximate Nearest Neighbor (ANN) search to find the top-K most similar items from a massive catalog (millions or billions).</li>
  <li><strong>Cross-Encoder:</strong> A slower but more accurate “ranking” stage. It takes the user query and each of the top-K retrieved items <em>together</em> as a single input to a more powerful model (like BERT) to produce a highly precise relevance score for re-ranking.</li>
</ol>

<p><strong>Key differentiator:</strong> The <strong>separation of concerns</strong> between a scalable-but-less-precise retriever and a precise-but-less-scalable re-ranker. This hybrid approach allows systems to search over enormous item catalogs with very low latency while ensuring the final results shown to the user are highly accurate.</p>

<p><strong>Use cases:</strong> This architecture is the standard for large-scale recommendation and search systems (e.g., Google Search, YouTube recommendations). It is used to retrieve relevant items from massive catalogs in real-time.</p>

<p><strong>When to Consider:</strong> This is the go-to architecture for building scalable and high-performance recommender systems. When you need to serve recommendations from a large item corpus with low latency, a bi-encoder for initial retrieval followed by a cross-encoder for re-ranking is a state-of-the-art approach.</p>

<ul>
  <li><strong>Seminal Papers:</strong>
    <ul>
      <li><strong>Dense Retrieval (Foundational):</strong> Karpukhin, V., Oguz, B., Min, S., et al. (2020). <em>Dense Passage Retrieval for Open-Domain Question Answering</em>. <a href="https://arxiv.org/abs/2004.04906">https://arxiv.org/abs/2004.04906</a>.</li>
      <li><strong>Cross-Encoders (Foundational):</strong> Nogueira, R., &amp; Cho, K. (2019). <em>Passage Re-ranking with BERT</em>. <a href="https://arxiv.org/abs/1901.04085">https://arxiv.org/abs/1901.04085</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="322-generative--instruction-tuned">3.2.2 Generative / Instruction-Tuned</h4>

<p><strong>Key concept:</strong> This approach reframes recommendation as a text generation problem. An instruction-tuned LLM is given a prompt containing the user’s history, profile, and a specific task (e.g., <em>“Given this user’s past movie ratings, recommend 5 new sci-fi movies and explain why they would like each one.”</em>). The LLM then generates the recommendations and explanations as a coherent, natural language response.</p>

<p><strong>Key differentiator:</strong> Its <strong>flexibility and zero-shot reasoning ability</strong>. The LLM can leverage its vast pre-trained world knowledge to make novel connections and provide recommendations for queries or user types it has never seen before, complete with human-like justifications.</p>

<p><strong>Use cases:</strong> Instruction-tuned LLMs are used for a wide range of tasks, including direct item recommendation, generating explanations, and user profiling. Their flexibility makes them suitable for creating more conversational and multi-task recommendation systems.</p>

<p><strong>When to Consider:</strong> Consider this approach when you want to leverage the generative and reasoning power of LLMs. It is particularly promising for cold-start problems and for building systems that can perform multiple recommendation-related tasks within a unified framework.</p>

<p><strong>Need GPU?</strong> Any system that uses a Large Language Model for generating or ranking recommendations will almost certainly require a GPU to have acceptable latency.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Geng, S., Liu, J.,, et al. (2022). <em>Recommendation as Language Processing (RLP): A Unified Pretrain, Tine-tune, and Prompt Paradigm</em>. <a href="https://arxiv.org/abs/2203.13366">https://arxiv.org/abs/2203.13366</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="323-rag--feature-extraction">3.2.3 RAG &amp; Feature Extraction</h4>

<p><strong>Key concept:</strong> This paradigm uses LLMs as a powerful <em>component</em> to enhance other recommender systems in two primary ways:</p>

<ol>
  <li><strong>LLM as a Feature Enhancer:</strong> Using an LLM as a sophisticated tool to process unstructured text (reviews, item descriptions) and extract high-quality semantic embeddings or structured features (e.g., “user cares about battery life”) to feed into any downstream recommendation model.</li>
  <li><strong>Retrieval-Augmented Generation (RAG):</strong> Grounding a generative LLM with real-time, factual information. Before generating a recommendation, the system retrieves relevant documents (e.g., up-to-date product specs, user’s recent reviews) and adds them to the LLM’s prompt as context.</li>
</ol>

<p><strong>Key differentiator:</strong> RAG’s key function is to <strong>mitigate hallucinations</strong> and ensure the LLM’s recommendations are factually accurate and based on current information from a trusted knowledge source. Using an LLM for feature extraction is a highly pragmatic way to inject powerful semantic understanding into any existing recommender pipeline.</p>

<p><strong>Use cases:</strong> Use <strong>RAG</strong> for building reliable generative recommender systems where factual accuracy is critical (e.g., recommending technical products, academic papers). Use an <strong>LLM as a feature enhancer</strong> to boost the performance of an existing recommendation model by improving its input features.</p>

<p><strong>When to Consider:</strong> Use RAG when building a generative recommender to mitigate the risk of the model making things up. Use an LLM as a feature extractor when you have rich textual data and want to create powerful semantic features to boost the performance of an existing model.</p>

<ul>
  <li><strong>Seminal Paper (Foundational RAG):</strong> Lewis, P., Perez, E., Piktus, A., et al. (2020). <em>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</em>. <a href="https://arxiv.org/abs/2005.11401">https://arxiv.org/abs/2005.11401</a>.</li>
</ul>

<h4 id="324-llm-agents--tool-use">3.2.4 LLM Agents &amp; Tool Use</h4>

<p><strong>Key concept:</strong> This advanced paradigm treats the LLM as a “reasoning engine” or orchestrator that can use external <strong>tools</strong>. The LLM is given access to a set of functions or APIs (e.g., a search API, a database query, a traditional recommender model). For a complex user request, the LLM devises a multi-step plan and decides which tools to call, in what order, to fulfill the request.</p>

<p><strong>Key differentiator:</strong> The ability to <strong>autonomously plan, reason, and act</strong>. Unlike other paradigms that perform a single, well-defined task, an LLM agent can decompose a complex goal (e.g., <em>“Find me a camera with the image quality of a DSLR but lighter than 500g”</em>) into a sequence of sub-tasks and tool calls.</p>

<p><strong>Use cases:</strong> Building next-generation interactive assistants that can handle complex, multi-step goals, where recommendation is just one part of a larger, problem-solving process. The RecMind framework is a concrete example.</p>

<p><strong>When to Consider:</strong> This is a frontier area of research and development. Consider building an LLM agent-based system when the user’s needs are complex and cannot be met by a single retrieval or ranking call. This is for building sophisticated assistants that help users accomplish complex goals.</p>

<ul>
  <li><strong>Seminal Paper (Example Framework):</strong>
    <ul>
      <li>Wang, W., et al. (2024). <em>RecMind: Large Language Model Powered Agent For Recommendation</em>. <a href="https://arxiv.org/abs/2403.00366">https://arxiv.org/abs/2403.00366</a>.</li>
    </ul>
  </li>
</ul>

<h3 id="33-conversational-recommender-systems">3.3 Conversational Recommender Systems</h3>

<p>This area focuses on creating interactive, multi-turn recommendation experiences, moving beyond the static “recommend and consume” loop.</p>

<blockquote>
  <p><strong>From Monologue to Dialogue</strong></p>

  <p>Traditional recommendation is a monologue: the system presents a list, and the user takes it or leaves it. A conversational recommender turns this into a <strong>dialogue</strong>. It’s an interactive back-and-forth where the system can ask clarifying questions and the user can provide nuanced feedback, creating a collaborative process that feels more like talking to a human expert. 💬</p>
</blockquote>

<h4 id="331-dialogue-based-preference-elicitation">3.3.1 Dialogue-based Preference Elicitation</h4>

<p><strong>Key concept:</strong> This is the process of actively asking a user questions in a multi-turn conversation to learn (“elicit”) their needs and preferences, especially when those preferences are unknown (cold-start) or ambiguous. The system maintains an evolving model of the user’s preferences that it updates with each turn of the dialogue.</p>

<p><strong>Key differentiator:</strong> It is an <strong>interactive and guided</strong> discovery process. Instead of expecting the user to know exactly what they want, the system acts like a helpful sales assistant or concierge, asking clarifying questions to progressively narrow down the options and pinpoint the user’s true intent.</p>

<p><strong>Use cases:</strong> Conversational recommenders are used in chatbots, voice assistants, and interactive e-commerce platforms where a guided discovery process is beneficial. They are ideal for complex domains with many attributes, like electronics, travel, or real estate.</p>

<p><strong>When to Consider:</strong> Implement a dialogue-based system when you need to serve users with no prior history (cold-start) or when the user’s intent is ambiguous and requires clarification. It is highly valuable in domains where users may not know exactly what they are looking for.</p>

<ul>
  <li><strong>Key Survey Paper:</strong>
    <ul>
      <li>Gao, C., Li, Y., et al. (2021). <em>A Survey on Conversational Recommender Systems</em>. <a href="https://arxiv.org/abs/2101.06462">https://arxiv.org/abs/2101.06462</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="332-natural-language-explanation--critique">3.3.2 Natural Language Explanation &amp; Critique</h4>

<p><strong>Key concept:</strong> This focuses on two-way communication <em>about</em> the recommendations themselves.</p>

<ol>
  <li><strong>Explanation:</strong> The system explains <em>why</em> an item was recommended in natural language (e.g., <em>“I’m suggesting this camera because you said you value long battery life.”</em>).</li>
  <li><strong>Critique:</strong> The user can provide feedback on a recommendation in natural language (e.g., <em>“That’s a good start, but can you find something a bit lighter?”</em>), and the system uses this critique to refine its next suggestion.</li>
</ol>

<p><strong>Key differentiator:</strong> It creates a <strong>collaborative feedback loop</strong>. This empowers the user to iteratively steer the recommendation process, which builds trust and leads to a more satisfying outcome than a static, one-shot recommendation. It transforms the interaction from a simple transaction to a partnership.</p>

<p><strong>Use cases:</strong> This is a key feature for advanced conversational agents and recommender systems aiming for a high-quality user experience where building user trust and providing a highly interactive, refined search process is important.</p>

<p><strong>When to Consider:</strong> Implement natural language explanation and critique capabilities when the goal is to create a truly interactive and user-centric recommendation experience. If user trust is a key concern, these features are essential.</p>

<ul>
  <li><strong>Key Survey Paper:</strong>
    <ul>
      <li>Jannach, D., &amp; Jugovac, M. (2019). <em>Explainable and Conversational Recommender Systems</em>. <a href="https://arxiv.org/abs/1902.01735">https://arxiv.org/abs/1902.01735</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="python-frameworks-5">Python Frameworks</h4>

<ul>
  <li><strong>Review-Based:</strong> These models are typically implemented from scratch or using standard deep learning libraries. The <strong>Microsoft Recommenders</strong> repo contains conceptually similar text-aware models for news recommendation (e.g., NAML, LSTUR).</li>
  <li><strong>Retrieval-based:</strong>
    <ul>
      <li><strong>Vector Databases &amp; Search Libraries:</strong> <strong>FAISS</strong> are essential for the efficient ANN search in the retrieval stage.</li>
      <li><strong>SentenceTransformers</strong> is a popular library for creating the bi-encoder and cross-encoder models.</li>
    </ul>
  </li>
  <li><strong>LLM-based (Generative, RAG, Agents):</strong>
    <ul>
      <li><strong>Hugging Face Transformers</strong> is the foundational library for accessing pre-trained LLMs.</li>
      <li><strong>LangChain</strong> are powerful frameworks for building RAG pipelines and LLM agents that can use tools.</li>
    </ul>
  </li>
  <li><strong>Conversational:</strong>
    <ul>
      <li><strong>Rasa</strong> and <strong>Google Dialogflow</strong> are comprehensive platforms for building production-grade conversational AI, including preference elicitation and dialogue management.</li>
    </ul>
  </li>
</ul>

<h4 id="production-ready-5">Production-ready?</h4>

<ul>
  <li><strong>Review-Based Models:</strong> <strong>Production-Ready.</strong> The core principle of using text from reviews to enrich item and user profiles is a standard and powerful technique in industrial recommender systems, even if specific academic architectures aren’t deployed verbatim.</li>
  <li><strong>Retrieval-based (Dense Retrieval &amp; Cross-Encoders):</strong> <strong>Production-Ready and State-of-the-art.</strong> This two-stage architecture is the gold standard for building modern, large-scale industrial search and recommendation systems.</li>
  <li><strong>LLM-based Paradigms:</strong>
    <ul>
      <li><strong>LLM as Feature Enhancer:</strong> <strong>Production-Ready.</strong> This is a highly pragmatic and increasingly common way to improve existing models.</li>
      <li><strong>RAG:</strong> <strong>Production-Ready.</strong> RAG is quickly becoming the standard for building reliable generative applications, and its use in recommendation is a major focus area.</li>
      <li><strong>Generative / Agents:</strong> <strong>Moving from Research to Production with extreme velocity.</strong> While challenges with latency, cost, and control remain, the potential of these approaches is driving massive investment and rapid progress toward production deployment.</li>
    </ul>
  </li>
  <li><strong>Conversational RecSys:</strong> <strong>Production-Ready.</strong> Conversational AI is a mature field, and dialogue-based systems are widely deployed in customer service chatbots and voice assistants. Integrating them with recommendation backends is a common practice.</li>
</ul>

<h2 id="section-4-multimodal-recommendation-algorithms">Section 4: Multimodal Recommendation Algorithms</h2>

<p>This section explores models that fuse information from multiple modalities—typically text, images, and video—to build a richer, more comprehensive understanding of items and user preferences. This is particularly crucial in domains like e-commerce, social media, and streaming, where visual content is a primary driver of user choice.</p>

<h3 id="41-contrastive-learning-for-multimodal-alignment">4.1 Contrastive Learning for Multimodal Alignment</h3>

<p>A foundational step for effective multimodal reasoning is creating a <strong>shared embedding space</strong> where different modalities of the same concept are mapped to nearby points. For example, the image of a cat and the text “a photo of a cat” should have very similar vector representations. Contrastive learning has emerged as the dominant paradigm for achieving this alignment by training models on massive datasets of paired multimodal data.</p>

<blockquote>
  <p><strong>What is a Shared Embedding Space?</strong></p>

  <p>Think of it as a universal, multilingual dictionary for concepts. In this dictionary, the entry for “cat” is a specific point in a high-dimensional space. The power of a shared embedding space is that the picture of a cat (from the “image language”) and the word “cat” (from the “text language”) are both translated to that <em>exact same point</em>. This allows the model to understand that an image and a piece of text are talking about the same thing, enabling powerful cross-modal search and recommendation.</p>
</blockquote>

<h4 id="411-clip-contrastive-language-image-pre-training">4.1.1 CLIP (Contrastive Language-Image Pre-Training)</h4>

<p><strong>Key concept:</strong> CLIP is a powerful model pre-trained on a massive dataset of (image, caption) pairs from the internet. It uses a contrastive objective to learn a shared embedding space where an image and its corresponding text description are mapped to nearby points. For example, a picture of a pair of sneakers and the text “casual shoes” will have very similar vector representations in CLIP’s space.</p>

<p><strong>Key differentiator:</strong> Its powerful <strong>zero-shot transfer capability</strong>. Because it’s trained on such a vast and diverse dataset, a pre-trained CLIP model can understand and classify visual concepts it has never been explicitly fine-tuned on, simply by describing them in text. This makes it an incredibly versatile, out-of-the-box tool for semantic understanding.</p>

<p><strong>Use cases:</strong> It’s used to generate rich, semantic embeddings for items from their images. These embeddings can then be used for visual search (“find more dresses like this one”), content-based recommendation, and solving the cold-start item problem. It excels in domains where visual aesthetics are key (e.g., fashion, home decor, social media).</p>

<p><strong>When to Consider:</strong> An engineer should consider using pre-trained CLIP embeddings whenever items have associated images. It is an extremely effective way to incorporate multimodal content information into any recommender system (from k-NN to DeepFM) with minimal effort and often significant performance gains.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., et al. (2021). <em>Learning Transferable Visual Models From Natural Language Supervision</em>. <a href="https://arxiv.org/abs/2103.00020">https://arxiv.org/abs/2103.00020</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="412-albef-align-before-fuse">4.1.2 ALBEF (Align Before Fuse)</h4>

<p><strong>Key concept:</strong> ALBEF is a multimodal architecture that learns to align image and text representations. Its core principle is to first align the features from unimodal encoders (one for images, one for text) using a contrastive loss, and <em>then</em> fuse them using a more complex cross-modal encoder for downstream tasks.</p>

<p><strong>Key differentiator:</strong> The <strong>“Align-Before-Fuse”</strong> strategy and its multi-task training objective, which includes image-text contrastive loss, masked language modeling (MLM), and image-text matching (ITM). The MLM and ITM losses, applied after the initial alignment, enable the model to learn much finer-grained interactions between visual regions and words.</p>

<p><strong>Use cases:</strong> Like CLIP, ALBEF is used to generate powerful multimodal embeddings. Its strong performance on retrieval and visual question answering (VQA) tasks makes it particularly well-suited for building sophisticated multimodal recommender or search systems that require a deep understanding of the relationship between image and text.</p>

<p><strong>When to Consider:</strong> Consider ALBEF or similar models when you need to train a state-of-the-art multimodal encoder from scratch for your specific domain and require top performance on complex multimodal reasoning tasks, rather than just using off-the-shelf embeddings.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Li, J., Li, D., Xiong, C., &amp; Hoi, S. (2021). <em>Align before Fuse: Vision and Language Representation Learning with Momentum Distillation</em>. <a href="https://arxiv.org/abs/2107.07651">https://arxiv.org/abs/2107.07651</a>.</li>
    </ul>
  </li>
</ul>

<h3 id="42-generative-multimodal-models">4.2 Generative Multimodal Models</h3>

<p>These models aim to learn the joint probability distribution of multimodal data, enabling them to generate new, personalized multimodal content or perform complex cross-modal inference.</p>

<blockquote>
  <p><strong>From Analysis to Synthesis</strong></p>

  <p>The models above are primarily for <strong>analysis</strong>—they learn to understand and represent existing content. Generative multimodal models are for <strong>synthesis</strong>—they learn to <em>create</em> new content. Instead of just finding an existing product image you might like, a generative model could one day create a brand-new image of a product tailored to your unique style.</p>
</blockquote>

<h4 id="421-multimodal-vaes">4.2.1 Multimodal VAEs</h4>

<p><strong>Key concept:</strong> Multimodal VAEs extend the Variational Autoencoder framework to handle multiple data types simultaneously (e.g., images and text). They learn a <strong>joint latent probability distribution</strong> that captures the shared underlying factors across different modalities for a given item.</p>

<p><strong>Key differentiator:</strong> Their ability to model the joint distribution in a probabilistic way makes them excellent at handling <strong>missing modalities</strong>. If an item has an image but no description, the model can still infer a reasonable joint latent representation from the available data. Their generative nature also allows for cross-modal synthesis (e.g., generating a likely caption for a given image).</p>

<p><strong>Use cases:</strong> Multimodal VAEs can be used in recommendation to learn a holistic representation of items from their text, images, and other attributes. This can improve collaborative filtering performance and enable novel applications like generating a textual description for a recommended product image.</p>

<p><strong>When to Consider:</strong> Consider Multimodal VAEs when you need a generative model for items with multiple modalities, especially if your dataset has missing data that you need to handle gracefully.</p>

<ul>
  <li><strong>Key Survey Paper:</strong>
    <ul>
      <li>Suzuki, M. (2022). <em>A Survey on Multimodal Deep Learning: From a Recommender Systems Perspective</em>. <a href="https://arxiv.org/abs/2201.07008">https://arxiv.org/abs/2201.07008</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="422-multimodal-diffusion">4.2.2 Multimodal Diffusion</h4>

<p><strong>Key concept:</strong> This paradigm applies the powerful denoising diffusion process to multimodal data. The model learns to reverse a process where noise is gradually added to data from multiple modalities (e.g., an image and its corresponding text) simultaneously. By learning to denoise them jointly, the model captures their joint distribution with high fidelity.</p>

<p><strong>Key differentiator:</strong> Its ability to generate <strong>exceptionally high-quality</strong>, realistic multimodal content. While other generative models can sometimes produce blurry or incoherent outputs, diffusion models have set a new standard for quality in content generation.</p>

<p><strong>Use cases:</strong> This is a cutting-edge area. Potential applications include enhancing multimodal recommendations by generating more robust representations or creating highly personalized content for users (e.g., generating a custom image and description for a recommended product <em>concept</em>). Frameworks like <strong>CCDRec</strong> use diffusion to guide the recommendation process.</p>

<p><strong>When to Consider:</strong> Consider exploring multimodal diffusion models for applications requiring high-fidelity generative capabilities or for improving the robustness of multimodal representations. Given their computational cost, they are best suited for research-focused projects or large-scale industrial labs exploring the next generation of generative recommendation.</p>

<ul>
  <li><strong>Key Survey Paper:</strong>
    <ul>
      <li>Wei, T. R., &amp; Fang, Y. (2024). <em>A Survey on Diffusion Models for Recommender Systems</em>. <a href="https://arxiv.org/abs/2401.10548">https://arxiv.org/abs/2401.10548</a>.</li>
    </ul>
  </li>
</ul>

<h4 id="python-frameworks-6">Python Frameworks</h4>

<ul>
  <li><strong>Contrastive Models (CLIP/ALBEF):</strong>
    <ul>
      <li><strong>OpenAI CLIP:</strong> The official repository is available at <a href="https://github.com/openai/CLIP">https://github.com/openai/CLIP</a>.</li>
      <li><strong>OpenCLIP:</strong> A popular, high-performance open-source implementation of CLIP is maintained at <a href="https://github.com/mlfoundations/open_clip">https://github.com/mlfoundations/open_clip</a>.</li>
      <li><strong>Hugging Face Transformers:</strong> Provides easy access to pre-trained CLIP and ALBEF models for integration into pipelines.</li>
    </ul>
  </li>
  <li><strong>Generative Models (VAEs/Diffusion):</strong>
    <ul>
      <li>These are typically implemented using core deep learning libraries like <strong>PyTorch</strong> or <strong>TensorFlow</strong>.</li>
      <li><strong>Hugging Face Diffusers</strong> is a state-of-the-art library for pre-trained diffusion models, which can be adapted for multimodal tasks.</li>
    </ul>
  </li>
</ul>

<h4 id="production-ready-6">Production-ready?</h4>

<ul>
  <li><strong>Contrastive Models (CLIP):</strong> <strong>Production-Ready as a Feature Extractor.</strong> Using pre-trained CLIP embeddings to represent visual content is a powerful, common, and highly effective practice in industrial recommender systems. It is one of the best ways to solve the visual cold-start problem.</li>
  <li><strong>Generative Models (VAEs/Diffusion):</strong> <strong>Research Interest.</strong> While generative AI is in production for content creation, its specific application for multimodal <em>recommendation</em> (beyond simple data augmentation) is still an emerging and computationally expensive field. The potential is enormous, but practical, low-latency deployment remains a significant challenge.</li>
</ul>

<h2 id="section-5-context-aware-recommendation-algorithms">Section 5: Context-Aware Recommendation Algorithms</h2>

<p>While interaction-driven models focus on the user-item matrix, context-aware algorithms achieve higher performance by leveraging additional side features. These models are the workhorses of industrial systems, especially for predicting click-through rates (CTR), as they can incorporate rich information about users, items, and the context of the interaction.</p>

<h3 id="51-factorization-machine-family">5.1 Factorization Machine Family</h3>

<p><strong>Key concept:</strong> Factorization Machines (FMs) and their successors are designed to efficiently model feature interactions in high-dimensional sparse data.</p>

<ul>
  <li><strong>FM &amp; FFM (Field-aware Factorization Machine):</strong> These classic models extend matrix factorization to work with any real-valued feature vector, making them highly effective for context-rich data.</li>
  <li><strong>DeepFM &amp; xDeepFM:</strong> As detailed in Section 2.3.2, these models combine the strengths of FMs for low-order interactions with deep neural networks for high-order interactions, becoming a standard for CTR prediction.</li>
  <li><strong>NFM &amp; AFM (Neural/Attentional Factorization Machine):</strong> These variants incorporate neural networks and attention mechanisms, respectively, to more powerfully learn the importance of different feature interactions.</li>
</ul>

<h4 id="511-amf-attentional-factorization-machine">5.1.1 AMF (Attentional Factorization Machine)</h4>

<p><strong>Key concept:</strong> Attentional Factorization Machine (AFM) extends Factorization Machines by incorporating an attention mechanism to weigh the importance of different feature interactions. It learns a sparse, weighted combination of second-order feature interactions, improving both accuracy and interpretability.</p>

<p><strong>Key differentiator:</strong> The attention mechanism allows AFM to focus on the most relevant feature interactions, reducing noise from less informative combinations and providing insights into which features drive predictions.</p>

<p><strong>Use cases:</strong> Click-through rate (CTR) prediction in online advertising or e-commerce, where high-dimensional, sparse feature sets (e.g., user demographics, item categories) are common, and interpretability is valuable.</p>

<p><strong>When to Consider:</strong> Use AFM when you need a context-aware model that balances performance and interpretability for CTR prediction tasks. It is a strong choice when feature interactions are complex but only a subset significantly impacts predictions.</p>

<ul>
  <li><strong>Seminal Paper:</strong>
    <ul>
      <li>Xiao, J., Ye, H., He, X., Zhang, H., Wu, F., &amp; Chua, T. S. (2017). <em>Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks</em>. <a href="https://arxiv.org/abs/1708.04617">https://arxiv.org/abs/1708.04617</a>.</li>
    </ul>
  </li>
</ul>

<h3 id="52-cross-network-models">5.2 Cross-Network Models</h3>

<p><strong>Key concept:</strong> This family of models focuses on explicitly and automatically learning high-order feature interactions, which is a major challenge in feature-rich recommendation.</p>

<ul>
  <li><strong>Wide &amp; Deep:</strong> A pioneering Google model that jointly trains a simple linear model (the “wide” part for memorization) and a deep neural network (the “deep” part for generalization).</li>
  <li><strong>DCN &amp; DCNv2 (Deep &amp; Cross Network):</strong> This architecture introduces a novel cross-network that is more efficient than a standard MLP for learning explicit feature interactions at each layer.</li>
</ul>

<h2 id="section-6-knowledge-aware-recommendation-algorithms">Section 6: Knowledge-Aware Recommendation Algorithms</h2>

<p>These algorithms enhance recommendations by incorporating data from external knowledge graphs (KGs), which provide structured information about items and their relationships (e.g., a movie is directed by a certain director, who also directed other movies).</p>

<h3 id="61-embedding-based--path-based-models">6.1 Embedding-based &amp; Path-based Models</h3>

<p><strong>Key concept:</strong> Knowledge-aware models leverage the structure and semantics of KGs to enrich item representations and find new recommendation pathways.</p>

<ul>
  <li><strong>Embedding-based (CKE, KTUP):</strong> These methods jointly learn embeddings for entities and relations in the KG along with user and item embeddings from interaction data, creating a unified representation space.</li>
  <li><strong>Path-based (RippleNet):</strong> This model propagates user preferences along paths in the KG, explicitly modeling how interests can spread from one item to another through shared attributes.</li>
  <li><strong>GNN-based (KGCN, KGAT, KGIN):</strong> These state-of-the-art models apply Graph Neural Networks directly to the knowledge graph, allowing for more powerful and flexible aggregation of neighborhood information to enrich item embeddings.</li>
</ul>

<h4 id="python-frameworks-7">Python Frameworks</h4>

<ul>
  <li><strong>TensorFlow</strong> <a href="https://github.com/tensorflow/tensorflow">https://github.com/tensorflow/tensorflow</a>: Provides flexible implementations for FM, FFM, DeepFM, and AFM through custom model building.</li>
  <li><strong>RecBole</strong> <a href="https://github.com/RUCAIBox/RecBole">https://github.com/RUCAIBox/RecBole</a>: Includes implementations of DeepFM, xDeepFM, and AFM for context-aware recommendation tasks.</li>
  <li><strong>LibRecommender</strong> <a href="https://github.com/massquantity/LibRecommender">https://github.com/massquantity/LibRecommender</a>: Offers a TensorFlow-based implementation of AFM with support for attention mechanisms.</li>
</ul>

<h2 id="section-7-specialized-recommendation-tasks">Section 7: Specialized Recommendation Tasks</h2>

<p>Beyond standard recommendation accuracy, several critical sub-fields focus on making recommender systems more robust, fair, and practical.</p>

<h3 id="71-debiasing--fairness">7.1 Debiasing &amp; Fairness</h3>

<p><strong>Key concept:</strong> Standard recommendation algorithms can inadvertently learn and amplify biases present in historical data (e.g., popularity bias, where popular items get recommended even more). This area develops methods to mitigate these issues.</p>

<ul>
  <li><strong>Debiasing (MF-IPS, CausE):</strong> These methods use techniques like inverse propensity scoring (IPS) or causal inference to train models that are less susceptible to biases in the data.</li>
  <li><strong>Fairness (FairGo):</strong> These algorithms aim to ensure that recommendations are equitable across different groups of users or item producers.</li>
</ul>

<h3 id="72-cross-domain-recommendation">7.2 Cross-Domain Recommendation</h3>

<p><strong>Key concept:</strong> This task addresses the challenge of providing recommendations in a target domain with sparse data by leveraging knowledge from a source domain with richer data (e.g., using book ratings to improve movie recommendations). Models like <strong>CMF</strong> and <strong>CoNet</strong> learn to transfer user preferences across different domains.</p>

<h3 id="73-meta-learning-for-cold-start">7.3 Meta-Learning for Cold Start</h3>

<p><strong>Key concept:</strong> The “cold-start” problem—making recommendations for new users or items with no interaction history—is a major challenge. Meta-learning, or “learning to learn,” offers a powerful solution.</p>

<ul>
  <li>Models like <strong>MeLU</strong> and <strong>MAMO</strong> are trained on a variety of tasks in a way that allows them to quickly adapt and make reasonable predictions for a new user with just a few interactions.</li>
</ul>

<h2 id="section-8-conclusion">Section 8: Conclusion</h2>

<p>This survey has charted the expansive and rapidly evolving landscape of recommendation algorithms, organized through the lens of the primary data modalities they employ. The journey from simple neighborhood-based methods to complex, generative large language models reveals several overarching themes that define the field’s progress and point toward its future.</p>

<p>First, a persistent and healthy tension exists between model complexity and practical performance. While the field’s frontier is constantly pushed by more sophisticated architectures, foundational models like ItemKNN and simple matrix factorization remain remarkably robust baselines. The success of LightGCN, which achieved superior performance by simplifying its more complex predecessor, NGCF, underscores a critical lesson: for the specific task of collaborative filtering, targeted simplicity often trumps general-purpose complexity. For engineers, this highlights the non-negotiable importance of benchmarking against simple, well-understood models before investing in more intricate solutions.</p>

<p>Second, the evolution of the field can be seen as a continuous search for more effective optimization objectives and representation learning techniques. The shift from pointwise rating prediction (optimizing RMSE) to pairwise ranking (optimizing with BPR) was a pivotal moment, aligning the machine learning objective more closely with the user-facing task of creating a useful ranked list. More recently, the widespread adoption of self-supervised contrastive learning in both sequential (CL4SRec) and graph-based (SGL, SimGCL) models has proven to be a powerful technique for learning robust representations from sparse and noisy data, acting as a potent regularizer and helping to mitigate issues like popularity bias.</p>

<p>Third, the convergence of recommender systems with other domains of AI, particularly Natural Language Processing and Computer Vision, has been a primary engine of innovation. The adoption of RNNs, CNNs, and Transformers for sequential recommendation demonstrates a conceptual reframing of user behavior modeling as a language modeling task. Similarly, the use of multimodal models like CLIP, which learn from natural language supervision, shows that the foundation for rich, content-aware recommendation lies in creating well-aligned, shared embedding spaces across different data types.</p>

<p>Finally, the emergence of Large Language Models is not merely an incremental advance but a potential paradigm shift. LLMs are being explored in a multitude of roles: as powerful feature extractors, as zero-shot generative recommenders, as the reasoning engine in RAG-based systems, and as the core of autonomous, tool-using agents. This trajectory points toward a future where the lines between interaction-driven, text-driven, and multimodal recommendation blur. The ultimate recommender system may not be a single model but a sophisticated, conversational agent that can understand multimodal user queries, reason about complex needs, retrieve and synthesize information from diverse external sources, generate personalized and multimodal recommendations, and explain its reasoning in a transparent, interactive dialogue. Navigating this future will require a deep understanding of the foundational principles outlined in this survey—from collaborative filtering to context-aware, knowledge-infused, and fair-minded systems—coupled with a readiness to embrace the new generative and agentic paradigms that are beginning to redefine the field.</p>]]></content><author><name>Rauf Aliev</name></author><category term="Recommender Systems" /><category term="Collaborative Filtering" /><category term="Content-Based Filtering" /><category term="Hybrid Recommenders" /><category term="Matrix Factorization" /><category term="Personalized Ranking" /><category term="Recommendations" /><category term="Retrieval-Augmented Generation (RAG)" /><category term="Generative Search" /><category term="Multimodal Search (Text, Image, Audio)" /><category term="Algorithms &amp; Models" /><category term="Embeddings (Word2Vec, GloVe, etc.)" /><category term="Transformers" /><category term="BERT" /><category term="Dense Retrieval" /><category term="Graph Algorithms" /><category term="Ranking" /><category term="Information Retrieval (IR)" /><summary type="html"><![CDATA[This paper provides a systematic and exhaustive review of recommendation algorithms, charting their evolution from foundational collaborative filtering techniques to the sophisticated deep learning and generative models of the modern era. We organize the landscape into three primary categories based on the dominant data modality: Interaction-Driven, Text-Driven, and Multimodal algorithms. For each paradigm and its key algorithms, we distill the core concepts, highlight key differentiators, identify primary use cases, and offer practical guidance for implementation. Our analysis reveals a recurring tension between model complexity and performance, the transformative impact of self-supervised learning, and the paradigm-shifting potential of Large Language Models. This survey is intended as a cornerstone reference for engineers and researchers seeking to navigate the complex, dynamic, and powerful field of recommender systems.]]></summary></entry><entry><title type="html">The Challenges of Chinese and Japanese Searching</title><link href="https://www.testmysearch.com/blog/2025/09/03/chinese-japanese-search.html" rel="alternate" type="text/html" title="The Challenges of Chinese and Japanese Searching" /><published>2025-09-03T00:00:00-04:00</published><updated>2025-09-03T00:00:00-04:00</updated><id>https://www.testmysearch.com/blog/2025/09/03/chinese-japanese-search</id><content type="html" xml:base="https://www.testmysearch.com/blog/2025/09/03/chinese-japanese-search.html"><![CDATA[<p>Today I want to talk about tailoring website search functionality for Chinese and Japanese languages. When it comes to entering “the East”, companies often face many challenges they could not have experienced before. Everything is different in China and Japan including the way how websites are built and how the users interact with them. In this article, I will cover one aspect of these challenges: how to adapt product/content search to work with Japanese and Chinese languages.</p>

<p>Read/Download PDF: <a href="/pdfs/2025-09-03-chinese-japanese-search.pdf">PDF version</a></p>

<p>Before I start, I thank my colleagues for their help in reviewing linguistic details and extending the analysis. I am grateful to <strong>Timofey Klyubin</strong> for expertise in Japanese and to <strong>Dmitry Antonov</strong> for valuable feedback, practical tips, and pointers on Chinese.</p>

<h2 id="table-of-contents">Table of Contents</h2>
<ul>
  <li><a href="#Introduction">Introduction</a></li>
  <li><a href="#LanguageDetection">Language Detection</a></li>
  <li>Language Variants
    <ul>
      <li><a href="#Dialects">Dialects</a></li>
      <li><a href="#Scripts">Scripts</a></li>
    </ul>
  </li>
  <li><a href="#CharacterVariants">Character Variants</a></li>
  <li><a href="#Conversion">Conversion Between the Systems</a></li>
  <li><a href="#WordSegmentation">Word Segmentation</a>
    <ul>
      <li><a href="#ChineseTokenizers">Chinese Tokenizers</a>
        <ul>
          <li><a href="#CJKAnalyzer">CJKAnalyzer</a></li>
          <li><a href="#SmartChineseAnalyzer">Smart Chinese Analyzer</a></li>
          <li><a href="#HanLPTokenizer">HanLPTokenizer</a></li>
        </ul>
      </li>
      <li><a href="#JapaneseTokenizers">Japanese Tokenizers</a>
        <ul>
          <li><a href="#JapaneseTokenizer">JapaneseTokenizer (Kuromoji)</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#WordNormalization">Word Normalization</a>
    <ul>
      <li><a href="#SolrFilters">Solr Filters for Chinese and Japanese</a>ф
        <ul>
          <li><a href="#JapaneseIterationMarks">Japanese Iteration Marks</a></li>
          <li><a href="#HalfWidthFilter">HalfWidth Filter</a></li>
          <li><a href="#JapaneseBaseFormFilter">Japanese Base Form Filter</a></li>
          <li><a href="#JapaneseNonMeaningfulTermsRemovalFilter">Japanese Non-meaningful Terms Removal Filter</a></li>
          <li><a href="#JapaneseKatakanaStemming">Japanese Katakana Stemming</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#Numerals">Numerals</a></li>
  <li><a href="#Synonyms">Synonyms</a></li>
  <li><a href="#Homophones">Homophones</a></li>
  <li><a href="#SearchByPronunciation">Search by Pronunciation</a></li>
  <li><a href="#PunctuationMarks">Punctuation marks</a></li>
  <li><a href="#SearchUI">Search UI observations</a>
    <ul>
      <li><a href="#ReviewedChineseStores">Reviewed Chinese Online Stores</a></li>
      <li><a href="#ReviewedJapaneseStores">Reviewed Japanese Online Stores</a></li>
      <li><a href="#InputMethods">Quick Overview of Chinese and Japanese Input Methods</a></li>
      <li><a href="#LessSearch">Less search, more navigation</a></li>
      <li><a href="#VoiceSearch">Voice search</a></li>
      <li><a href="#ContextAwareQueryRecommendations">Context-aware query recommendations</a></li>
      <li><a href="#VisualSearch">Visual search</a></li>
      <li><a href="#FacetPanel">Facet panel</a></li>
    </ul>
  </li>
  <li><a href="#Recommendations">Recommendations</a>
    <ul>
      <li><a href="#WebTypography">Web typography recommendations</a></li>
    </ul>
  </li>
</ul>

<hr />
<p><a id="Introduction"></a></p>
<h2 id="introduction">Introduction</h2>
<p>There are three languages traditionally considered together in the context of information retrieval, internationalization, and localization. These languages are Chinese, Japanese, and Korean. Their writing systems are based entirely or partly on Chinese characters.</p>

<p>This research can be useful for the internationalization, localization and information retrieval components and projects. Internationalization is mainly about support for multiple languages and cultures. Localization stands for adaptation of language, content, and design to specific countries, regions, or cultures. Cross-lingual information retrieval deals with documents in one or more different languages, and the techniques for indexing, searching, and retrieving information from large multi-language collections.</p>

<p>From the perspective of information retrieval, the Chinese and Japanese present numerous challenges. The major issue is their highly irregular orthography and language variants. In this article, I collected the most important ones we need to take into account when implementing the language-aware full text search as well as how to address them.</p>

<hr />
<p><a id="LanguageDetection"></a></p>
<h2 id="language-detection">Language Detection</h2>
<p>When and where possible, the website should allow the user to specify unambiguously what language is going to be used for entering a search query and presenting the results. Normally, the users enter search queries in the same language as the website’s interface is set to.</p>

<p>However, our observations show that the customers use their native language if the website is advertised in their country even if the localized version of the website is not pre-selected, automatically or manually. If the first-level domain is from the local pool (.cn for China or .jp for Japan), the user’s intent of using the native language is even stronger. To address this case, there are AI and statistical techniques to determine the likely language.</p>

<p>The automatic language detection is a very challenging task especially if the analyzed string is short. For example, if it is has a mix of Latin and Chinese characters from Japanese Kanji set may indicate that the text is either in Japanese or Chinese which can be too abstract.</p>

<hr />
<p><a id="Dialects"></a></p>
<h2 id="language-variants-dialects">Language variants: Dialects</h2>
<p>There are many more dialects in Chinese than Japanese. Both full of specificities interesting to us in regard to the topic.</p>

<p>The thing is Chinese is not a single language, it is a family of spoken languages. China has a lot of dialects, but the most popular is Mandarin (or “Standard Chinese”, over 1 billion speakers) and Cantonese (or Yue, over 100 million of speakers).</p>

<p>In Japan, there are two major types of the Japanese language: the Tokyo-type (or Eastern) and the Kyoto-Osaka type (or Western). The form that is considered the standard is called “Standard Japanese”. Unlike Traditional and Simplified Chinese, the standard Japanese has become prevalent nationwide.</p>

<hr />
<p><a id="Scripts"></a></p>
<h2 id="language-variants-scripts">Language Variants: Scripts</h2>
<h4 id="japanese-kana-and-kanji">Japanese: Kana and Kanji</h4>
<p>There are two typical Japanese scripts, Kana and Kanji.</p>

<ul>
  <li><strong>Kanji</strong> is logographic Chinese scripts, Chinese characters adapted to write Japanese words. There are thousands of kanji in Japanese</li>
  <li><strong>Kana</strong> is a collective term for Japanese syllabaries, Hiragana (46 characters) and Katakana (48 characters). They are derived by simplifying Chinese characters selected to represent syllables of Japanese.</li>
</ul>

<p>The same Japanese word can be written in either kana or kanji:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left"><strong>English word</strong></th>
      <th style="text-align: left"><strong>Japanese (Kanji)</strong></th>
      <th style="text-align: left"><strong>Japanese (Katakana)</strong></th>
      <th style="text-align: left"><strong>Japanese (Hiragana)</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">fox</td>
      <td style="text-align: left">狐</td>
      <td style="text-align: left">キツネ</td>
      <td style="text-align: left">きつね</td>
    </tr>
  </tbody>
</table>

<p>This complexity is also illustrated by the sentence 金の卵を産む鶏 (“A hen that lays golden eggs”). The word ‘egg’ has four variants (卵, 玉子, たまご, タマゴ), ‘chicken’ has three (鶏, にわとり, ニワトリ) and ‘giving birth to’ has two (産む, 生む), which expands to 24 permutations. In many contexts only one option is correct.</p>

<p>Japanese has a large number of loan words or <a href="https://en.wikipedia.org/wiki/Gairaigo">gairaigo</a>. The considerable portion of them is derived from English. In written Japanese, gairaigos are usually written in katakana. Many gairaigos have native equivalents in Japanese. Sometimes a Japanese person can use either a native form or its English equivalent written in katakana. This is especially the case of proper names or science terms. If you are not familiar with the native variant, you will probably use a syllabic construct.</p>

<p>Some examples:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left"><strong>English word</strong></th>
      <th style="text-align: left"><strong>Japanese (native word)</strong></th>
      <th style="text-align: left"><strong>Japanese (English loan word)</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">door</td>
      <td style="text-align: left">扉 /tobira/, 戸 /to/</td>
      <td style="text-align: left">ドア <em>/doa/</em></td>
    </tr>
    <tr>
      <td style="text-align: left">mobile phone/cell phone</td>
      <td style="text-align: left">携帯 /keitai/ – “mobile phone”, “handheld”, 携帯電話 /keitaidenwa/ – “mobile phone”</td>
      <td style="text-align: left">モバイルフォン /mobairufon/, セルラー電話 /serurā denwa/</td>
    </tr>
  </tbody>
</table>

<p>School kids use hiragana more commonly since they might not have learned the kanji equivalents yet.</p>

<p>Additionally, there is Romaji which uses Latin script to represent Japanese.</p>

<h4 id="chinese-traditional-and-simplified">Chinese: Traditional and Simplified</h4>
<p>Along with the sheer complexity and size of the character set, Chinese has several related language variants. In Taiwan, Hong Kong, and Macao, Traditional Chinese characters are predominant over the Simplified Chinese variant which is used mainly in Mainland China, Singapore, and Malaysia.</p>

<p>Some traditional Chinese characters, or derivatives of them, are also found in Japanese writing. So there is a subset of characters common for different languages. These shared Chinese, Japanese, and Korean characters constitute a set named CJK Unified Ideographs. It is huge: the CJK part of Unicode defines a total of 87,887 characters. The characters needed for everyday use by the users is much smaller.</p>

<p>For the search, queries can be in either traditional or simplified characters or a combination of the two; search results should contain all matching resources, whether traditional or simplified.</p>

<p>Below is a random text to demonstrate the differences between the writing systems. Characters highlighted by yellow marker have different spelling in Simplified (输入简体字点下面繁体字按钮进行在线转换) and Traditional (輸入簡體字點下面繁體字按鈕進行在線轉換) Chinese.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-6.39.18-AM.png" alt="Simplified and Traditional Chinese comparison" /></p>

<hr />
<p><a id="CharacterVariants"></a></p>
<h2 id="character-variants">Character variants</h2>
<p>Chinese and Japanese characters don’t use upper or lower cases. They have only a single representation independent of context.</p>

<p>The majority of letters are monospaced.</p>

<p>There are no additional decorations for the letters as it is in Arabic, for example.</p>

<hr />
<p><a id="Conversion"></a></p>
<h2 id="conversion-between-the-systems">Conversion between the systems</h2>
<p>The conversion is important when either a user or a document use a mix of Chinese writing systems. For example, Given a user query 舊小說 (‘old fiction’ in Traditional Chinese), the results should include matches for 舊小說 (traditional) and 旧小说 (simplified characters for ‘old fiction’). That means that conversion should be done at the query level.</p>

<p>The accurate conversion between Simplified Chinese and Traditional Chinese, a deceptively simple but in fact extremely difficult computational task. If your search is used by millions, the system will be much more resource-intensive comparing with the setup for the European languages.</p>

<p>There are three methods of conversion:</p>

<ul>
  <li><strong>Code conversion (codepoint-to-codepoint)</strong>. This method is based on the mapping table and considered as the most unreliable because of the numerous one-to-many mappings (in both directions). The rate of conversion failure is unacceptably high.</li>
  <li><strong>Orthographic conversion</strong>. In this method, the meaningful linguistic units, especially compounds and phrases, are considered. Orthographic mapping tables enable conversion on the word or phrase level rather than the codepoint level. An excellent example is the Chinese word “computer.” (see examples below).</li>
  <li><strong>Lexemic conversion</strong>. A more sophisticated, and more challenging, approach to conversion. In this method, the mapping table contains lexemes that are semantically, rather than orthographically, equivalent. This is similar to the difference between <em>lorry</em> in British English and <em>truck</em> in American English. The complexity of this method in lexemic differences between Simplified and Traditional Chinese, especially in technical terms and proper nouns.</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: left"><strong>Simplified Chinese</strong></th>
      <th style="text-align: left"><strong>Traditional Chinese</strong></th>
      <th style="text-align: left"><strong>Translation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">干</td>
      <td style="text-align: left">幹 or 乾 or 榦</td>
      <td style="text-align: left">(dry, make, surname)</td>
    </tr>
    <tr>
      <td style="text-align: left">电话</td>
      <td style="text-align: left">電話</td>
      <td style="text-align: left">(telephone)</td>
    </tr>
    <tr>
      <td style="text-align: left">软件</td>
      <td style="text-align: left">軟體 (Taiwan)</td>
      <td style="text-align: left">(software)</td>
    </tr>
    <tr>
      <td style="text-align: left">计算机 (“calculating machine”)</td>
      <td style="text-align: left">電脳 (“electronic brain”)</td>
      <td style="text-align: left">(computer)</td>
    </tr>
  </tbody>
</table>

<p>In Japanese, the kanji characters may or may not have the same-looking Chinese character.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left"><strong>Chinese (Simplified)</strong></th>
      <th style="text-align: left"><strong>Chinese (Traditional)</strong></th>
      <th style="text-align: left"><strong>Japanese</strong></th>
      <th style="text-align: left"><strong>Japanese</strong></th>
      <th style="text-align: left"><strong>Translation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">两</td>
      <td style="text-align: left">兩</td>
      <td style="text-align: left">両</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">(both)</td>
    </tr>
    <tr>
      <td style="text-align: left">龟</td>
      <td style="text-align: left">龜</td>
      <td style="text-align: left">亀</td>
      <td style="text-align: left">カメ</td>
      <td style="text-align: left">(tortoise)</td>
    </tr>
  </tbody>
</table>

<p>It is generally believed that the top priority for Chinese discovery improvements is to equate Traditional characters with simplified characters. For Japanese, equating Modern (<em>Shinjitai</em>) and Traditional (<em>Kyūjitai</em>) Kanji is also important—particularly for historical texts, proper nouns, and names—and should not be overlooked in normalization pipelines. There is a priority for Japanese discovery improvements to equate all scripts used in the language: Kanji, Hiragana, Katakana, and Romaji.</p>

<p>In Apache Solr, the only other relevant ICU script translation is a mapping between Hiragana and Katakana. This is a straightforward one-to-one character mapping working in both directions. For context, Apache Solr is a widely used open-source search engine platform; the recommendations below assume familiarity with Solr’s analysis pipeline.</p>

<p>Consider making Simplified Chinese and traditional Chinese inter-searchable. If one searches for 计算机 (computer, Simplified) or 電脳 (computer, Traditional) , the results should contain the records with both 计算机 and 電脳. At least measure how often each of these writing systems is used by your customers to make an educated decision on how to make search better.</p>

<h2 id="word-segmentation">Word segmentation</h2>

<p>Chinese and Japanese are written in a style that does not delimit word boundaries. Typical Chinese sentences include only Chinese characters, along with a select few punctuation marks and symbols. Typical Japanese sentences include mostly Japanese kana and some adopted Chinese characters that are used in the Japanese writing system. So, how does one decide how to break up the words when there are no separators in between?</p>

<p>As for spaces, they delineate words inconsistently and with variation among writers. Formally, there must always be a space between English words and Chinese words, but in fact this rule is not strict and many neglect it. There is no space between the Arabic numbers and Chinese characters.</p>

<p>Coming back to word segmentation, there are different approaches for splitting the text into the word units. The most common algorithms use dictionaries and, additionally, a set of rules. This topic is still an area of considerable research among the machine learning community. All of these are not perfect: this segmentation cannot be done unambiguously, but different methods show acceptable results for the specific areas. For example, for scientific texts, the dictionary-based methods may show poorer results than the statistical or machine-learning.</p>

<p>For example, the word “中华人民共和国” (People’s Republic of China) is seven characters long and has smaller words within: “人民” (people) and “共和国” (republic country). The first two characters,“中华” are usually not be used as a word independently in modern Chinese, though it can be used as a word in ancient Chinese. Digging further, within the word “人民” (people), “人” is a word (human), but “民” (civilian or folk) is not a standalone word. These components can be organized in the hierarchy. As another example, while the proper segmentation of “中华人民共和国外交部” (Ministry of Foreign Affairs of the PRC) is “中华人民共和国 / 外交 部”, another word, “国外” (overseas), could also be erroneously extracted. Consequently, a search for “国 外” should most likely not match the string “中华人民共和国外交部” but a query for “外 交部” should.</p>

<p>A group of characters might be segmented in different ways resulting in different meanings. For example, In Japanese, the compound 造船所 (shipyard) consists of the word 造船 (‘shipbuilding’, 造 is ‘to make, build’ and 船 is ‘a ship’) followed by the suffix 所 which is ‘a place’. In Chinese, the situation is completely the same. There are Chinese jokes based on these ambiguities. Teahan in its “A compression-based algorithm for Chinese word segmentation” illustrates this with the following funny example:</p>

<table>
  <thead>
    <tr>
      <th>A sentence in Chinese</th>
      <th>我喜欢新西兰花</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Interpretation #1</strong></td>
      <td>I like New Zealand flower</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>我</th>
      <th>喜欢</th>
      <th>新西兰</th>
      <th>花</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>I</td>
      <td>like</td>
      <td>New Zealand</td>
      <td>flower</td>
    </tr>
  </tbody>
</table>

<p>| <strong>Interpretation #2</strong> | I like new broccoli |
|—|—|</p>

<table>
  <thead>
    <tr>
      <th>我</th>
      <th>喜欢</th>
      <th>新</th>
      <th>西兰花</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>I</td>
      <td>like</td>
      <td>new</td>
      <td>broccoli</td>
    </tr>
  </tbody>
</table>

<p>(This situation happens only in speaking language. A Chinese writer will use separator 的 to clarify what he means. 我喜欢新的西兰花 for the case 1 And 我喜欢新西兰的花 for the case 2)</p>

<p>The next example illustrates what happens when each character in a query is treated as a single-character word. The intended query is “physics” or “physicist.” The first character returns documents about such things as “evidence,” “products,” “body,” “image,” “prices”; while the second returns documents about “theory,” “barber,” and so on.</p>

<table>
  <thead>
    <tr>
      <th>物理学 means</th>
      <th>物 means</th>
      <th>理 means</th>
      <th>学 means</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Physics</strong></td>
      <td>Physics <br /> Evidence <br /> Products <br /> Price <br /> Body <br /> Image</td>
      <td>Theory <br /> Barber <br /> Science <br /> Reason <br /> Understand <br /> …</td>
      <td>School <br /> Study <br /> Subject <br /> School</td>
    </tr>
  </tbody>
</table>

<p>It creates a lot of irrelevant documents causing the precision of information retrieval to decrease greatly.</p>

<p>So, the challenge is how to extract the meaningful units of knowledge from the text for indexing to return better results at the query phase.</p>

<p>There are three approaches on how to perform text segmentation for indexing and querying:</p>

<ul>
  <li><strong>Unigrams</strong>: treat individual Chinese characters as tokens</li>
  <li><strong>Bigrams</strong>: treat overlapping groups of two adjacent Chinese characters as tokens</li>
  <li><strong>By part of speech or meaningful words</strong>: performs word segmentation and indexes word units as tokens.</li>
</ul>

<p>For example, for the string “我是中国人” (“I’m a Chinese”),</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th><strong>Unigrams</strong></th>
      <th><strong>Bigrams</strong></th>
      <th><strong>Word segmentation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Token 1</strong></td>
      <td>我</td>
      <td>我是</td>
      <td>我 (“I”)</td>
    </tr>
    <tr>
      <td><strong>Token 2</strong></td>
      <td>是</td>
      <td>是中</td>
      <td>是 (“right”)</td>
    </tr>
    <tr>
      <td><strong>Token 3</strong></td>
      <td>中</td>
      <td>中国</td>
      <td>中国 (“China”)</td>
    </tr>
    <tr>
      <td><strong>Token 4</strong></td>
      <td>国</td>
      <td>国人</td>
      <td>人 (“man”)</td>
    </tr>
    <tr>
      <td><strong>Token 5</strong></td>
      <td>人</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>For the string “私は日本人です” (“I’m Japanese”),</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th><strong>Word segmentation</strong></th>
      <th><strong>Meaning</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Token 1</strong></td>
      <td>私</td>
      <td>“I”</td>
    </tr>
    <tr>
      <td><strong>Token 2</strong></td>
      <td>は</td>
      <td>(particle)</td>
    </tr>
    <tr>
      <td><strong>Token 3</strong></td>
      <td>日本人</td>
      <td>“Japanese”</td>
    </tr>
    <tr>
      <td><strong>Token 4</strong></td>
      <td>です</td>
      <td>“am”</td>
    </tr>
  </tbody>
</table>

<p>The third approach is the most challenging. How to extract word units efficiently?</p>

<p>The simplest method is dictionary-based. This is called the <strong>maximum forward match heuristic</strong>. Given a dictionary of frequently used Chinese words, an input string and the indexing text are compared with words in the dictionary to find the one that matches the greatest number of characters. The alternative approach is maximum backward match heuristic when the text scanned in the backward direction. This method is not accurate enough and creates a lot of false matches.</p>

<p>The alternative method is statistical. This method concentrates on two-character words (because two-character is the most common word length in Chinese) and detects the words based on the frequency of characters and bigrams.</p>

<p>In order to improve the process, there are a lot of other methods too. These methods are based on probabilistic automata and machine learning.</p>

<p>The best and the most universal of these methods are included in Apache Solr, and being part of Solr, in SAP Commerce Cloud as well.</p>

<p>Solr supports various methods of word segmentation both for Chinese and Japanese. Each method treats the text differently.</p>

<h3 id="chinese-tokenizers-for-apache-solr-and-sap-commerce-cloud">Chinese: Tokenizers for Apache Solr (and SAP Commerce Cloud)</h3>

<p>For Chinese,</p>

<ul>
  <li><strong>Standard Analyzer</strong>: character-based (unigram-like) tokenization; useful as a baseline.</li>
  <li><strong>ChineseAnalyzer</strong> (deprecated): retained for backward compatibility in older Lucene/Solr versions and not recommended for new deployments.</li>
  <li><strong>CJKAnalyzer</strong>: indexes bigrams; simple and fast, yielding high recall but low precision as noted below.</li>
  <li><strong>SmartChineseAnalyzer</strong> (Simplified Chinese only): dictionary + HMM-based; effective for general Simplified Chinese, but limited for Traditional Chinese and often outperformed by modern third‑party libraries.</li>
  <li><strong>HanLPTokenizer</strong> (<a href="https://github.com/hankcs/hanlp-lucene-plugin">https://github.com/hankcs/hanlp-lucene-plugin</a>, <a href="http://www.hankcs.com/">http://www.hankcs.com/</a>): modern algorithms (e.g., Viterbi) with strong support for both Simplified and Traditional Chinese; requires separate installation/configuration and typically provides higher accuracy at increased operational complexity.</li>
  <li><strong>Paoding</strong> (<a href="https://stanbol.apache.org/docs/trunk/components/enhancer/nlp/paoding">https://stanbol.apache.org/docs/trunk/components/enhancer/nlp/paoding</a>) (legacy/third‑party): an older analyzer that is no longer commonly maintained; generally not recommended for recent Solr versions.
Let’s have a look at how the analyzers split the “我喜欢新西兰花” (from the example above) into terms.</li>
</ul>

<h4 id="chinese-cjkanalyzer">Chinese: CJKAnalyzer</h4>

<p>This analyzer has a simple bigram tokenizer. It indexes every overlapping two-character sequence without linguistic resources (e.g., “中国人” → “中国”, “国人”). In practice, this yields <em>high recall</em> because many queries will find a matching bigram, but <em>low precision</em> because unrelated strings can share bigrams. For example, a search for “京都” (Kyoto) can match “東京都” (Tokyo Metropolis) due to the shared bigram “京都”. Likewise, as discussed earlier, one would not want “国外” to match “中华人民共和国外交部”, but bigramming tends to over‑match in such cases. A common production practice is to index Chinese simultaneously as words and as overlapping bigrams and combine the methods in a weighted fashion to mitigate noise.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image2.png" alt="CJKAnalyzer example" /></p>

<h4 id="chinese-smartchineseanalyzer">Chinese: SmartChineseAnalyzer</h4>

<p>This analyzer has <strong><em>HMMChineseTokenizer</em></strong> which uses probabilistic knowledge to find the optimal word segmentation for <strong>Simplified Chinese</strong> text. The text is first broken into sentences, then each sentence is segmented into words.</p>

<p>Segmentation is based upon the <a href="http://en.wikipedia.org/wiki/Hidden_Markov_Model">Hidden Markov Model</a>.</p>

<p>A large training corpus was used to calculate Chinese word frequency probability.</p>

<p>This analyzer requires a dictionary to provide statistical data. SmartChineseAnalyzer has an included dictionary out-of-box. The included dictionary data is from <a href="http://www.ictclas.org">ICTCLAS1.0</a>.</p>

<p><strong><em>SmartChineseAnalyzer</em></strong> creates four terms (I + like + New Zealand (新西兰) + flower). It performs well on general Simplified Chinese but does not support Traditional Chinese as effectively as modern external libraries.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image3.png" alt="SmartChineseAnalyzer example" /></p>

<h4 id="chinese-hanlptokenizer-viterbi-algorithm">Chinese: HanLPTokenizer: Viterbi Algorithm</h4>

<p>For our example, <strong>HanLPTokenizer</strong> creates six terms (I + like + New Zealand (新西兰) + Zealand(西兰) + flower):</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image4.png" alt="HanLPTokenizer example" /></p>

<p>HanLPTokenizer supports the following algorithms for word segmentation:</p>

<ul>
  <li><strong>Viterbi</strong> (default): The best balance of efficiency and effectiveness. It is also the shortest path word segmentation, and the HanLP shortest path solution uses the Viterbi algorithm.</li>
  <li><strong>Double array trie tree</strong> (dat): Extreme speed dictionary participle, tens of characters per second (may not get part of speech, depending on your dictionary)</li>
  <li><strong>Conditional random field</strong> (crf): segmentation, part-of-speech tagging and named entity recognition accuracy are high, suitable for higher-demand NLP tasks</li>
  <li><strong>Perceptron</strong>: word segmentation, part-of-speech tagging and named entity recognition, support for online learning</li>
  <li><strong>N shortest</strong> (nshort): Named entity recognition is slightly better, sacrificing speed</li>
</ul>

<p>Unlike SmartChineseAnalyzer, HanLPTokenizer can support Traditional Chinese as well. Deployments typically require adding HanLP as an external dependency and managing its models, which increases operational complexity relative to built‑in analyzers.</p>

<h3 id="domain-specific-dictionaries-and-ongoing-maintenance">Domain-Specific Dictionaries and Ongoing Maintenance</h3>

<p>A critical determinant of segmentation quality is the dictionary itself. General-purpose lexicons perform poorly on specialized corpora such as e-commerce product catalogs, biomedical texts, or legal documents. Production systems should plan for:<br />
(1) <em>Domain customization</em>: seed dictionaries with brand names, SKUs, technical terms, and common compounds;<br />
(2) <em>Feedback loops</em>: mine query and click logs to identify unknown terms and mis-segmentations;<br />
(3) <em>Versioning and evaluation</em>: maintain curated releases of dictionaries with regression tests to prevent quality drift.</p>

<p>These practices usually yield larger gains than swapping tokenizers alone, and they are essential regardless of the analyzer chosen.</p>

<h3 id="japanese-tokenizers-for-apache-solr-and-sap-commerce-cloud">Japanese: Tokenizers for Apache Solr (and SAP Commerce Cloud)</h3>

<p>For Japanese,</p>

<ul>
  <li><strong>CJKAnalyzer</strong> indexes bigrams,</li>
  <li><strong>Japanese Tokenizer</strong> splits the text into word units using morphological analysis, and annotates each term with part-of-speech, base form (a.k.a. lemma), reading and pronunciation.</li>
</ul>

<h4 id="japanese-cjkanalyzer">Japanese: CJKAnalyzer</h4>

<p>This analyzer creates bigrams in the same way as shown above for Chinese.</p>

<h4 id="japanese-japanese-tokenizer-kuromoji">Japanese: Japanese Tokenizer (Kuromoji)</h4>

<p>This morphological tokenizer uses a rolling Viterbi search to find the least cost segmentation (path) of the incoming characters.</p>

<p>This tokenizer is also known as Kuromoji Japanese Morphological Analyzer (<a href="https://www.atilika.org/">https://www.atilika.org/</a>)</p>

<p>For our test query “私は日本人です” (“I’m Japanese”), it returns four terms (“I + particle + Japanese + am)</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image5.png" alt="Kuromoji example 1" /></p>

<p>Let’s take a look at a bit more complicated sentence: 韓国に住んでいていい人に聞いた。(I asked a good person, who lives in South Korea). It consists of the following parts:</p>

<table>
  <thead>
    <tr>
      <th><strong>Element</strong></th>
      <th><strong>Pronounced as</strong></th>
      <th><strong>Meaning</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>韓国</td>
      <td>/kankoku/</td>
      <td>“South Korea”</td>
    </tr>
    <tr>
      <td>に</td>
      <td>/ni/</td>
      <td>/grammatical particle/</td>
    </tr>
    <tr>
      <td>住んでいて</td>
      <td>/sundeite/</td>
      <td>the continuous form of the verb 住む meaning “to live”. It consists of two parts: the conjugation 住んで and a special form of the auxiliary verb いて – to be.</td>
    </tr>
    <tr>
      <td>いい</td>
      <td>/ii/</td>
      <td>adjective, meaning “good”.</td>
    </tr>
    <tr>
      <td>人</td>
      <td>/hito/</td>
      <td>“person”</td>
    </tr>
    <tr>
      <td>に</td>
      <td>/ni/</td>
      <td>/grammatical particle/</td>
    </tr>
    <tr>
      <td>聞いた</td>
      <td>/kiita/</td>
      <td>past form of the verb “to ask”</td>
    </tr>
  </tbody>
</table>

<p>The Japanese Tokenizer gives the following output:</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image6.png" alt="Kuromoji example 2" /></p>

<p>So, actually, we have a bit more parts than we should have, but that is really not a bad thing. The key point is that we still have correct base forms of core words of the original phrase, so that the meaning is preserved. Those additional tokens like て and で can be removed during stop-words filter, along with the grammatical particles.</p>

<p>In Japanese, it’s often useful to do the additional splitting of words to make sure you get hits when searching compounds nouns. For example, if you want to search for 空港 (airport) to match 関西国際空港 (Kansai International Airport), the analyzers won’t allow this since 関西国際空港 tend to be a single token meaning this specific airport. This problems is also applicable to katakana compounds such as シニアソフトウェアエンジニア (Senior Software Engineer). For that, the tokenizer supports different modes:</p>

<ul>
  <li><strong>Normal</strong> – regular segmentation</li>
  <li><strong>Search</strong> – use a heuristic to do additional segmentation useful for search</li>
  <li><strong>Extended</strong> – similar to search mode, but also unigram unknown words (experimental)</li>
</ul>

<p>For some applications, it might be good to use search mode for indexing and normal mode for queries to increase precision and prevent parts of compounds from being matched and highlighted.</p>

<h2 id="word-normalization">Word Normalization</h2>

<p>Word normalization refers to the process that maps a word to some canonical form. For example, in English the canonical form for “are”, “is”, and “being” is “be”. This normalization being performed at both index time and query time improves the accuracy of search results.</p>

<p>Solr uses two approaches to normalize word variations:</p>

<ul>
  <li><strong>Stemming</strong>. The approach to reduce the word to its root form.</li>
  <li><strong>Lemmatization</strong>. The identification of the dictionary form of a word based on its context.</li>
</ul>

<h3 id="solr-filters-for-chinese-and-japanese">Solr Filters for Chinese and Japanese</h3>

<h4 id="japanese-iteration-marks">Japanese Iteration Marks</h4>

<p>For stemming in Japanese, Solr provides <strong><em>JapaneseIterationMarkCharFilter</em></strong> which normalizes horizontal iteration marks (々, odoriji) to their expanded form. These marks are used to represent a duplicated character representing the same morpheme. For example, hitobito, “people”, is usually written 人々, using the kanji for 人 with an iteration mark, 々, rather than 人人, using the same kanji twice (this latter is also allowed, and in this simple case might be used because it is easier to write). By contrast, while 日々 hibi “daily, day after day” is written with the iteration mark, as the morpheme is duplicated, 日日 hinichi “number of days, date” is written with the character duplicated, because it represents different morphemes (hi and nichi).</p>

<h4 id="halfwidth-filter">HalfWidth Filter</h4>

<p>By convention, 1/2 Em wide characters are called “halfwidth”; the others are called correspondingly “fullwidth” characters. <strong><em>CJKWidthFilter</em></strong> folds <a href="https://www.htmlsymbols.xyz/ascii-symbols/fullwidth-ascii-variants">fullwidth ASCII variants</a> into the equivalent basic latin (“ＩｊＩ” -&gt; “IjI”) and <a href="https://en.wikipedia.org/wiki/Half-width_kana">halfwidth Katakana variants</a> into the equivalent Japanese kana (ｶ -&gt; カ).</p>

<h4 id="japanese-base-form-filter">Japanese Base Form Filter</h4>

<p><em>JapaneseBaseFormFilter</em> reduces inflected Japanese verbs and adjectives to their base/dictionary forms.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image7.png" alt="Japanese Base Form Filter example" /></p>

<p>For example, for the phrase “それをください。” (That one, please.), the tokenizer will combine last characters together into a polite form of “ください” (“please do for me”). The BaseFormFilter converts it into the base form, “くださる”.</p>

<table>
  <thead>
    <tr>
      <th><strong>Before</strong></th>
      <th><strong>After</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ください</td>
      <td>くださる</td>
    </tr>
  </tbody>
</table>

<h4 id="japanese-non-meaningful-terms-removal-filter">Japanese Non-meaningful Terms Removal Filter</h4>

<p><em>JapanesePartOfSpeechStopFilterFactory</em> removes token with certain part-of-speech tags (created by the JapaneseTokenizer). For example, “を”, the direct object particle, will be removed by this filter from the token stream.</p>

<table>
  <thead>
    <tr>
      <th><strong>Before</strong></th>
      <th><strong>After</strong></th>
      <th><strong>Comments</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>(それ), (を), (ください)</td>
      <td>(それ), (ください)</td>
      <td>“を” is an auxiliary word, a Japanese particle. It is attached to the end of a word それ to signify that that word is the direct object of the verb.</td>
    </tr>
  </tbody>
</table>

<h4 id="japanese-katakana-stemming">Japanese Katakana Stemming</h4>

<p><em>JapaneseKatakanaStemFilter</em> normalizes common katakana spelling variations ending in a long sound character (U+30FC, “ー “) by removing the long sound character. Only katakana words longer than four characters are processed.</p>

<p>For example, for the phrase “明後日パーティーに行く予定がある。図書館で資料をコピーしました。” (“I plan to go to a party the day after tomorrow. I copied the materials in the library.”), the word パーティー (“party”) has a long sound character in the middle and at the end. The ending symbol is removed by this filter.</p>

<table>
  <thead>
    <tr>
      <th><strong>Before</strong></th>
      <th><strong>After</strong></th>
      <th><strong>Comments</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>パーティー</td>
      <td>パーティ</td>
      <td>This word is “party”. It is borrowed from English.</td>
    </tr>
    <tr>
      <td>コピー</td>
      <td>コピー</td>
      <td>Shorter than 4</td>
    </tr>
  </tbody>
</table>

<h2 id="apache-solr-processing-flow-for-japanese">Apache Solr processing flow for Japanese</h2>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/schem1.png" alt="Solr processing flow for Japanese" /></p>

<h2 id="apache-solr-processing-flow-for-chinese">Apache Solr Processing Flow for Chinese</h2>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/chinese-japanese.png" alt="Solr processing flow for Chinese" /></p>

<h2 id="numerals">Numerals</h2>

<p>In Japan and China, most people and institutions primarily use Arabic numerals. Chinese numerals in the web forms are used too (both in China and Japan) but much less frequently. However, this does not rule out the necessity to support Chinese and Japanese specifics in using numerals.</p>

<p>For Chinese, it is obvious that combinations of numbers and characters can be used, but it is preferred to use the shortest written way:</p>

<table>
  <thead>
    <tr>
      <th><strong>English</strong></th>
      <th><strong>preferable</strong></th>
      <th><strong>secondary preferable</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>one</td>
      <td>一</td>
      <td> </td>
    </tr>
    <tr>
      <td>two</td>
      <td>二</td>
      <td> </td>
    </tr>
    <tr>
      <td>tree</td>
      <td>三</td>
      <td> </td>
    </tr>
    <tr>
      <td>one thousand</td>
      <td>一千</td>
      <td> </td>
    </tr>
    <tr>
      <td>ten thousands</td>
      <td>一万</td>
      <td> </td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>一</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2</td>
      <td>二</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3</td>
      <td>三</td>
    </tr>
    <tr>
      <td>10</td>
      <td>十</td>
      <td>10</td>
    </tr>
    <tr>
      <td>100</td>
      <td>100</td>
      <td>一百</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>一千</td>
      <td>1000</td>
    </tr>
    <tr>
      <td>1500</td>
      <td>1500</td>
      <td>一千五</td>
    </tr>
    <tr>
      <td>2000</td>
      <td>2千</td>
      <td>两千</td>
    </tr>
    <tr>
      <td>10000</td>
      <td>一万</td>
      <td> </td>
    </tr>
    <tr>
      <td>100000</td>
      <td>十万</td>
      <td> </td>
    </tr>
    <tr>
      <td>25000000</td>
      <td>2500万</td>
      <td>两千五百万</td>
    </tr>
  </tbody>
</table>

<p>Japanese numerals are often written using a combination of kanji and Arabic numbers with various kinds of punctuation. For example, ３．２千 means 3200. Other examples are listed in the table below.</p>

<p>Apache Solr comes with the <em>JapaneseNumberFilter</em> which normalizes Japanese numbers to regular Arabic decimal numbers. This filter does this kind of normalization and allows a search for 3200 to match ３．２千 in text, but can also be used to make range facets based on the normalized numbers and so on.</p>

<p>The table below shows the examples of conversions supported by the JapaneseNumberFilter:</p>

<table>
  <thead>
    <tr>
      <th><strong>Before</strong></th>
      <th><strong>After</strong></th>
      <th><strong>Comments</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>〇〇七</td>
      <td>7</td>
      <td><a href="https://en.wiktionary.org/wiki/%E3%80%87">〇</a> <em>(maru) is the same as numeral 0 in English.</em></td>
    </tr>
    <tr>
      <td>一〇〇〇</td>
      <td>1000</td>
      <td> </td>
    </tr>
    <tr>
      <td>三千2百２十三</td>
      <td>3223</td>
      <td> </td>
    </tr>
    <tr>
      <td>兆六百万五千</td>
      <td>1000006005001</td>
      <td> </td>
    </tr>
    <tr>
      <td>３．２千</td>
      <td>3200</td>
      <td>千 means 1000 <br /> “．” is a double-byte point</td>
    </tr>
    <tr>
      <td>１．２万３４５．６７</td>
      <td>12345.67</td>
      <td> </td>
    </tr>
    <tr>
      <td>4,647.100</td>
      <td>4647.1</td>
      <td>“,” is ignored (removed)</td>
    </tr>
    <tr>
      <td>15,7</td>
      <td>157</td>
      <td>“,” is ignored (removed)</td>
    </tr>
    <tr>
      <td>2,500万</td>
      <td>25000000</td>
      <td>万 means 10000</td>
    </tr>
  </tbody>
</table>

<p>The last example shows one of the weaknesses of the filter you need aware of. Commas are almost arbitrary and mean nothing.</p>

<p>This filter may in some cases normalize tokens that are not numbers. For example, 田中京一 is a name and means Tanaka Kyōichi, but 京一 (Kyōichi) out of context can strictly speaking also represent the number 10000000000000001. This filter respects the KeywordAttribute which can be used to prevent specific normalizations from happening.</p>

<p>Japanese formal numbers (daiji), accounting numbers and decimal fractions are currently not supported by the filter.</p>

<h2 id="synonyms">Synonyms</h2>

<p>In Japanese, as well as in many other languages, for the same concept you can find more than one word:</p>

<table>
  <thead>
    <tr>
      <th><strong>Concept: to cause to die</strong> <br /> <strong>English:</strong></th>
      <th><strong>Japanese:</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>to kill</td>
      <td>殺す</td>
    </tr>
    <tr>
      <td>to commit murder</td>
      <td>殺人を犯す</td>
    </tr>
    <tr>
      <td>to murder</td>
      <td>殺害する</td>
    </tr>
    <tr>
      <td>to shoot to death</td>
      <td>射殺する</td>
    </tr>
    <tr>
      <td>to assassinate</td>
      <td>暗殺する</td>
    </tr>
    <tr>
      <td>to execute</td>
      <td>処刑する</td>
    </tr>
  </tbody>
</table>

<p>Apache Solr supports synonyms, but the dictionary of the synonymous words is user-defined.</p>

<h2 id="homophones">Homophones</h2>

<p>Homophones are one of two or more words that are pronounced the same but differ in writing and usually in meaning. In English, the examples are “principal” and “principle”.</p>

<p>Jack Halpern in “The Complexities of Japanese Homophones” illustrates this with the phrase “A Mansion with no Sunshine”. There are twelve legitimate ways (some more likely than others) of how to write this:</p>

<ul>
  <li>日の差さない屋敷 (standard dictionary form)</li>
  <li>日の射さない屋敷</li>
  <li>日のささない屋敷</li>
  <li>日の射さない邸</li>
  <li>日の差さない邸</li>
  <li>日のささない邸</li>
  <li>陽の射さない屋敷</li>
  <li>陽の差さない屋敷</li>
  <li>陽のささない屋敷</li>
  <li>陽の射さない邸</li>
  <li>陽の差さない邸</li>
  <li>陽のささない邸</li>
</ul>

<p>Halpern surveyed six native Japanese speakers, some of whom are professional translators and writers, asking them how they would write the above phrase. He reports that there were six different answers, none of which matched the “standard” form found in dictionaries.</p>

<p>Japanese has orthographic variants based on phonetic substitution. Jack Halpern in its “<a href="http://www.cjk.org/cjk/joa/joapaper.htm#2">The Challenges of Intelligent Japanese Searching</a>” mentioned the following example of that: 盲 is interchangeable with 妄 in such compounds as 妄想 (=盲想) ‘wild idea’, but not in 盲従 moojuu ‘blind obedience’.</p>

<p>Every written Japanese and Chinese word has at least two completely different spellings.</p>

<p>Such diversity naturally causes diversity in the ways how users formulate the query.</p>

<p>Because of a small stock of phonemes in Japanese and Chinese, the number of homophones is very large. Since many homophones are nearly synonymous or even identical in meaning, they are easily confused.</p>

<p>You need to have a semantically classified database of homophones to implement cross-homophone searching. The major issue is that for many homophones, a universally-accepted orthography does not exist. The choice of character should be based on meaning, but in fact it is often unpredictable and governed by the personal preferences of the writer.</p>

<p>For example, Jack Halpern in “The Complexities of Japanese Homophones” illustrates this problem with the following example:</p>

<table>
  <thead>
    <tr>
      <th><strong>English</strong></th>
      <th><strong>Standard</strong></th>
      <th><strong>Sometimes</strong></th>
      <th><strong>Often also</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>to offer</td>
      <td>差す</td>
      <td>さす</td>
      <td> </td>
    </tr>
    <tr>
      <td>to hold up</td>
      <td>差す</td>
      <td>さす</td>
      <td> </td>
    </tr>
    <tr>
      <td>to pour into</td>
      <td>差す</td>
      <td>注す</td>
      <td>さす</td>
    </tr>
    <tr>
      <td>to color</td>
      <td>差す</td>
      <td>注す</td>
      <td>さす</td>
    </tr>
    <tr>
      <td>to shine on</td>
      <td>差す</td>
      <td>射す</td>
      <td>さす</td>
    </tr>
    <tr>
      <td>to aim at</td>
      <td>指す</td>
      <td>差す</td>
      <td> </td>
    </tr>
    <tr>
      <td>to point to</td>
      <td>指す</td>
      <td>さす</td>
      <td> </td>
    </tr>
    <tr>
      <td>to stab</td>
      <td>刺す</td>
      <td>さす</td>
      <td> </td>
    </tr>
    <tr>
      <td>to leave unfinished</td>
      <td>さす</td>
      <td>止す</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>Since similar terms can be spelled different ways, people sometimes purposely use the wrong Kanji because it took too long to type a proper one. The local and global Internet search services (Google Japan, Baidu, Google Hong Kong, and others) can handle such cases. The users are getting used to such a response and use the same pattern at the websites. The search engines integrated into the e-stores are not so smart and the search results aren’t going to be as fruitful.</p>

<table>
  <thead>
    <tr>
      <th><strong>Synonym</strong></th>
      <th><strong>Synonym</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>fox</td>
      <td>フォックス</td>
    </tr>
    <tr>
      <td> </td>
      <td>キツネ</td>
    </tr>
  </tbody>
</table>

<h2 id="search-by-pronunciation">Search by pronunciation</h2>

<p>In Japanese, the pronunciation is directly mapped to the written words. For example, Google, when searching by “とうきょうえ” (tōkyōe) correctly suggests “東京駅” (<strong>tōkyōe</strong>ki) (Tokyo station). While they are written in completely different characters, their pronunciation starts with the same syllables. And the other reason is that this is how Japanese people type: they type words in hiragana and then convert them to kanji or katakana by pressing a hotkey several times until the desired conversion variant is in place.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image8.png" alt="Google suggest for Japanese pronunciation" /></p>

<p>Another example, searching for 京都大学図書館 – “Kyoto University Library”</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image9.png" alt="Kyoto University Library search" /></p>

<h2 id="punctuation-marks">Punctuation marks</h2>

<p>There are punctuation marks specific for Japanese and Chinese. Some of them have similar-looking equivalents in European languages which are not always interchangeable.</p>

<table>
  <thead>
    <tr>
      <th><strong>Punctuation marks</strong></th>
      <th><strong>Example</strong></th>
      <th><strong>Explanation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>〜</td>
      <td>1〜2</td>
      <td>Wavy dash, for ranges</td>
    </tr>
    <tr>
      <td><strong>。</strong></td>
      <td> </td>
      <td>Full stop (=”.”)</td>
    </tr>
    <tr>
      <td><strong>、</strong></td>
      <td>a、b、c</td>
      <td>Enumeration comma</td>
    </tr>
    <tr>
      <td><strong>「　」</strong></td>
      <td>「あいうえお」</td>
      <td>The Japanese equivalent of quotation marks (“”) in other languages.</td>
    </tr>
    <tr>
      <td><strong>・</strong></td>
      <td>ジョン・ドゥ /John Doe/</td>
      <td>Japanese specific: 中点(<em>nakaten</em>) is used to indicate a break in foreign names and phrases. Most commonly it is placed between the first name and the last name written in katakana.</td>
    </tr>
  </tbody>
</table>

<h2 id="search-ui-observations">Search UI observations</h2>

<h3 id="reviewed-chinese-online-stores">Reviewed Chinese Online Stores</h3>

<ul>
  <li><a href="http://suning.com">Suning.com</a>.</li>
  <li><a href="http://gome.com.cn">Gome.com.cn</a></li>
  <li><a href="http://taobao.com">Taobao.com</a></li>
  <li><a href="http://tmall.com">Tmall.com</a></li>
  <li><a href="http://jd.com">Jd.com</a></li>
  <li><a href="http://vip.com">Vip.com</a></li>
  <li><a href="http://dangdang.com">Dangdang.com</a></li>
  <li><a href="http://fanli.com">Fanli.com</a></li>
  <li><a href="http://ly.com">Ly.com</a></li>
  <li><a href="http://1688.com">1688.com</a></li>
  <li><a href="http://zhe800.com">Zhe800.com</a></li>
  <li><a href="http://mizhe.com">mizhe.com</a></li>
</ul>

<h3 id="reviewed-japanese-online-stores">Reviewed Japanese Online Stores</h3>

<ul>
  <li><a href="http://rakuten.co.jp">Rakuten.co.jp</a></li>
  <li><a href="http://zozo.jp">zozo.jp</a></li>
  <li><a href="http://wowma.jp">Wowma.jp</a></li>
  <li><a href="http://qoo10.jp">Qoo10.jp</a></li>
  <li><a href="https://www.mercari.com/jp/">mercari.com/jp/</a></li>
  <li><a href="http://fril.jp">Fril.jp</a></li>
  <li><a href="http://minne.com">Minne.com</a></li>
  <li><a href="http://kakaku.com">Kakaku.com</a></li>
  <li><a href="http://dmm.com">Dmm.com</a></li>
</ul>

<p>There are some points which are differently valued by users when compared with western user interface design.</p>

<p>Chinese and Japanese websites have much less negative space, tiny images (and few of them), and a totally different content presentation with a focus on content rather than on its style. The density of information is higher than we got used to dealing with. Possibly , this layout style is connected to Kanban culture with its tendency to content efficiency: placing a maximum amount of content within a minimum space.</p>

<h3 id="chinese-and-japanese-input-methods">Chinese and Japanese Input Methods</h3>

<h4 id="text-input-in-chinese">Text Input in Chinese</h4>

<p>Chinese websites rely on different ways of input in Chinese characters: Pinyin (a system of Latin transcription of Chinese characters), Sequence of Strokes, Wubi (5 Basic Strokes), Handwriting, Image recognition, and voice input. The computer converts the Pinyin spelled, handwritten, captured or voiced sentence into the correct Chinese character sequence on the screen. Below is functionality offered by the default Chinese version of Android (I should say that it matches input methods in windows):</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-7.54.54-AM.png" alt="Chinese input methods on Android" /></p>

<p>Below I tried to input 2 characters (十 – ten and 百 – hundred) by using a different method.</p>

<p><strong>Wubi (5 strokes).</strong> Wubi is the fastest method, but the most challenging. With Wubi, all characters can be written reliably with no more than 5 keystrokes. The method requires only 2 clicks on a keyboard to spell most of the characters. But it requires to memorize a table to map strokes to keys on keyboard. Pinyin knowledge is not required, so it is widely used among Chinese who don’t know Pinyin.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-7.56.13-AM.png" alt="Wubi input method" /></p>

<p><strong>Pinyin (with 26 English keys).</strong> Pinyin the slowest method, I clicked 4 times before I go get each of the characters. Once a word has been typed in Pinyin, the computer will suggest words matching this pronunciation in a pop-up window. Selecting the intended word from the list can slow down the typing process considerably. But this method is commonly used among young generation who usually learn Pinyin at school. Also, the most popular method among foreigners, because it doesn’t require large vocabulary.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-7.56.13-AM-1.png" alt="Pinyin input method" /></p>

<p><strong>Handwriting.</strong> This method is widely used among them who don’t know Latin alphabets or by those who enjoy calligraphy.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-7.58.03-AM.png" alt="Handwriting input method" /></p>

<p><strong>Stroke sequence.</strong> This method is widely used among them who don’t know Latin alphabets and not that good with handwriting. Originally method used in traditional mobile phones with small non-responsive screens. As far as strokes are grouped, the sequence might be long which slows down the process.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-7.58.57-AM.png" alt="Stroke sequence input method" /></p>

<p><strong>Image recognition</strong>. This method is great for the larger amount of data, doesn’t require any special knowledge.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-8.00.34-AM.png" alt="Image recognition input method" /></p>

<p><strong>Voice recognition</strong></p>

<p>Quite popular in China, but the methodology is facing a challenge because of many variant dialects causing pronunciation differences. Voice recognition projects are presumingly supported by the government as part of countrywide Putonghua popularization. Dmitry Antonov: “In my case, it used Baidu engine (AI/ML) and it smartly returned me it’s brand name Baidu when I pronounced “bai” – hundred in Pinyin, so it is commercialized advertising?”.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/Screen-Shot-2019-08-19-at-8.01.37-AM.png" alt="Voice recognition input method" /></p>

<h4 id="text-input-in-japanese">Text Input in Japanese</h4>

<p>There are two main methods of inputting Japanese: Romaji, via a romanized version of Japanese, and Kana. The keyboards sold in Japan usually look like this:</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image10.png" alt="Japanese keyboard layout" /></p>

<p>The primary input method is typing words by their reading in kana and then convert them to kanji. For example, let’s see how to type phrase 日本語を勉強するのが好きです — “I like studying Japanese”.</p>

<ol>
  <li>
    <p>You type your sentence in hiragana first, at this step it looks like this:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image011.jpg" alt="Typing in Hiragana" /></p>
  </li>
  <li>
    <p>Then you press the conversion key and it converts the current word to the kanji or katakana representation. Because there are many homonyms, often you will see the little window pop up with a list of conversion variants. It looks like this:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image012.jpg" alt="Converting Hiragana to Kanji" /></p>
  </li>
  <li>
    <p>Then you convert each part until you get the needed result.</p>
  </li>
</ol>

<p>On a typical Japanese keyboard there are five helper keys:</p>

<ul>
  <li>変換 — /henkan/, meaning “conversion”. Converts kana to kanji.</li>
  <li>無変換 — /muhenkan/, “no conversion”. Leaves the kana as it is.</li>
  <li>かな, or simply “kana” — kana mode. Also there may be keys for specific kana modes: ひらがな(hiragana), カタカナ(katakana) or ローマ字(romaji).</li>
  <li>英数 — /eisu/, alphanumeric mode.</li>
  <li>半角/全角 — /hankaku, zenkaku/, half-width and full-width mode for inputting latin characters.</li>
</ul>

<p>If one doesn’t have a keyboard with kana support, they can type in romaji. The process is exactly the same, except the first step: instead of typing hiragana directly, you type kana readings in romaji and they are automatically converted into hiragana:</p>

<ol>
  <li><img src="https://hybrismart.com/wp-content/uploads/2019/08/image013.jpg" alt="Typing Romaji" /></li>
  <li><img src="https://hybrismart.com/wp-content/uploads/2019/08/image014.jpg" alt="Romaji converted to Hiragana" /></li>
</ol>

<p><strong>Less search, more navigation</strong></p>

<p>It is common to find the search field a lot less highlighted on the Japanese and Chinese websites. According to Alex Zito-Wolf, “<a href="https://medium.com/@alexzitowolf/chinese-ui-trends-mobile-application-text-search-flows-4884d5f688a">Chinese UI Trends</a>”, Chinese apps and websites tend to prioritize navigation over search. With the Japanese keyboard, it takes about 20+ keypresses to type a few Japanese characters, so it is often faster to get to a particular link than typing something in search.</p>

<p>Zito-Wolf also highlights that many apps use a focus page which is activated once the user clicks on the search bar. The author believes that “Chinese apps create strong hooks to allow users to be routed away from using text search at the beginning of the search process,  allowing these users a faster search completion and more time spent browsing other pages.” This focus page contains the tags which are meant to help the user find the fastest way to construct a search, as well as educate them on how to effectively write search queries improving search efficiency in the long run.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image15.png" alt="Suning.com search UI" />
(Suning.com)</p>

<p>The mobile version of Suning.com redirects the user to a designated search page (/search.html) when a user clicks on the search bar.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image16.png" alt="Suning.com mobile search page" /></p>

<p>Zito-Wolf draws attention to the high role of tags in the search process. “For the query 咖啡 (“Coffee”) (…) like a guessing tree, the system starts with broad additional tags, 价格比高 “Good cost/value ratio”, 交通方便 “Convenient transportation” and 就餐空间大 “Spacious atmosphere”.</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image17.png" alt="Search tags for coffee query" /></p>

<p><strong>Voice search</strong></p>

<p>The UX/UI Designer Pavlo Plakhotia <a href="https://mlsdev.com/blog/mobile-design-for-chinese-market">notices</a> that the implementation of the voice message function is very common for Chinese mobile design. “Voice control is much easier than manual text input, especially for the older audience, who do not always have sufficient skills to work with mobile applications and various ways of entering the set of Chinese hieroglyphs. At present, there is also a trend among users to exploit voice input for search queries instead of typing.”</p>

<p>Gome.com.cn:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image18.png" alt="Voice search icon" /></p>

<h2 id="context-aware-query-recommendations">Context-aware query recommendations</h2>

<p>Many websites show the context/recommended queries under the search bar. This list depends on context and customer behavior. For example, after searching “iphone”, the system understands that the user wants a mobile phone, and recommends other brands too (Huawei, Samsung, Oppo, Vivo)</p>

<p>Tmail.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image21.png" alt="Tmail recommended queries" /></p>

<p>Dianping.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image22.png" alt="Dianping recommended queries" /></p>

<p>The recommendations can be even placed inside the search box (this is travel e-shop, and recommendations are destinations, Suzhou and Shanghai)
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image23.png" alt="In-box recommendations" /></p>

<p>In Japanese stores there are also related queries (qoo10.jp, the query is “vans”):
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image24.png" alt="Qoo10 related queries" /></p>

<h2 id="visual-search">Visual search</h2>

<p>The trend in more and more shops implement visual search.</p>

<p>1688.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image25.png" alt="1688.com visual search icon" /></p>

<p>JD.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image26.png" alt="JD.com visual search icon" /></p>

<p>The image I used for search:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image27.png" alt="Image used for visual search" /></p>

<p>The results:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image28.png" alt="Visual search results" /></p>

<p><strong>No alpha sorting</strong></p>

<p>In Chinese, there is no meaning to sort the search items or facets by alphabet because there is no alphabet. Theoretically, the items can be sorted by the character’s rendering into Pinyin based on Pinyin alphabetical order in the manner as many dictionaries do.</p>

<p>In other aspects, the search box and search results page follow the general market-agnostic UI/UX recommendations.</p>

<h3 id="facet-panel">Facet panel</h3>

<p>Facets are often arranged horizontally because of the Chinese and Japanese script is much denser. However, that is more a characteristic of Chinese websites:</p>

<p><img src="https://hybrismart.com/wp-content/uploads/2019/08/image29.png" alt="Horizontal facets example 1" /></p>

<p>Zhe800.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image30.png" alt="Zhe800.com horizontal facets" /></p>

<p>JD.com:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image31.png" alt="JD.com horizontal facets" /></p>

<p>Gone.com.cn:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image32.png" alt="Gone.com.cn horizontal facets" /></p>

<p>All important facets are open by default, all others are collapsed. You can expand them on hover. In the next screenshot, the facet with the list of tags is opened:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image33.png" alt="Expanded facet tags" /></p>

<p>In Japan, vertical facets are more common:</p>

<p>Rakuten.co.jp:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image34.png" alt="Rakuten vertical facets" /></p>

<p>Zozo.jp:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image35.png" alt="Zozo.jp vertical facets" /></p>

<p>Wowma.jp:
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image36.png" alt="Wowma.jp vertical facets" /></p>

<p>Horizontal facets are used too on Japan’s websites, but it is not so common.
<img src="https://hybrismart.com/wp-content/uploads/2019/08/image37.png" alt="Horizontal facets on a Japanese site" /></p>

<h3 id="recommendations">Recommendations</h3>

<p>If your website is available in different language versions, you need to have answers to the following questions:</p>

<ul>
  <li>What languages can be used on what language versions? Can I search in Chinese on the English website and vice versa?</li>
  <li>Can we mix English and Chinese in the same query? It is especially important for brands and proper names (Sony / ソニー).</li>
  <li>What language variants are supported?</li>
</ul>

<h2 id="web-typography-recommendations">Web typography recommendations</h2>

<p>The best line length is 15-40 characters per line (CPL) for the computer display and 15-21 CPL for the smartphone display (~2 times shorter than it is recommended for English)</p>

<p>In Japanese, Serif (with decorative elements) is called “Mincho” (明朝) and Sans-Serif (plain) is called “Gothic” (ゴシック).</p>

<p>In Chinese, the two most commonly used classifications are Song (宋體, 宋体) or Ming (明體 / 明体), which you could think of as the Chinese serif, and hei (黑體 / 黑体), similar to a sans-serif.</p>

<p>In English, the 3rd party font files have a very small impact to the page loading speed because the character set is relatively small. And the designers embed them into the pages. In Chinese and Japanese, extra fonts can be one of the reasons for a slow-loading page.</p>

<p>Italics is technically supported, but it not recommended to use it with Japanese and Chinese characters. It skews them so that they become unreadable.</p>

<p>Don’t use a font size smaller than 12pt. It’s always better to set your font size by “em” or “%” and take the user preferences into account. If your website targets older people, consider 16pt font size.</p>

<p>Meiryo, MS Gothic, MS Mincho, Yu Gothic, and Yu Mincho fonts are pre-installed in Windows. “Hiragino Kaku Gothic ProN” and “Hiragino Mincho ProN” are pre-installed in MacOS. “HiraKakuProN-W3” and “HiraMinProN-W3” are used in iOS.</p>

<p>If you want to get typography better, Noto will be a good solution. Noto is a Google font family that supports all languages including Chinese and Japanese.</p>

<h2 id="conclusions">Conclusions</h2>

<p>In the above, we’ve touched different aspects of Japanese and Chinese searching. We demonstrated that the challenges are addressable. We also demonstrated that the solutions are still evolving and there are always matters outstanding for deeper research.</p>

<p>Because of the complexities and irregularities of the Chinese and Japanese writing systems, you need not only computational linguistic tools such as morphological analyzers, but also lexical databases fine-tuned to the needs of particular project goals and content. Both analyzers and databases are constantly improving, and it is important to keep an eye on the latest breakthroughs in information retrieval and apply them to your solution to keep delivering better user experience and</p>]]></content><author><name>Rauf Aliev</name></author><category term="Relevance" /><category term="Ranking" /><category term="Indexing" /><category term="Query Processing" /><category term="Lexical Search" /><category term="Keyword Search" /><category term="Query Understanding (NLU)" /><category term="Search UI/UX" /><summary type="html"><![CDATA[Today I want to talk about tailoring website search functionality for Chinese and Japanese languages. When it comes to entering “the East”, companies often face many challenges they could not have experienced before. Everything is different in China and Japan including the way how websites are built and how the users interact with them. In this article, I will cover one aspect of these challenges: how to adapt product/content search to work with Japanese and Chinese languages.]]></summary></entry><entry><title type="html">Building Trust in Search and Recommendation</title><link href="https://www.testmysearch.com/blog/2025/09/02/search-trust.html" rel="alternate" type="text/html" title="Building Trust in Search and Recommendation" /><published>2025-09-02T00:00:00-04:00</published><updated>2025-09-02T00:00:00-04:00</updated><id>https://www.testmysearch.com/blog/2025/09/02/search-trust</id><content type="html" xml:base="https://www.testmysearch.com/blog/2025/09/02/search-trust.html"><![CDATA[<p>When we think about search engines or recommender systems, the default measure of quality is often relevance: does the system return what I asked for? Yet over time, it has become clear that accuracy alone does not create confidence. These systems don’t just retrieve information—they curate visibility, shape opportunity, and implicitly set the terms of what users come to rely on. That’s why the discussion has shifted toward a broader question: <strong>can we trust the ranking we see?</strong></p>

<h2 id="why-trust-matters">Why Trust Matters</h2>

<p>Every list of results is a sequence of choices. Which job ad appears at the top? Which track lands in a playlist? Which hotel listing takes the first slot? These choices are not neutral: they reinforce patterns, create feedback loops, and shape expectations. If results feel arbitrary, skewed, or manipulated, user trust erodes quickly.</p>

<p>Researchers have begun to unpack what “trust” in ranking really means. It is not reducible to a single formula. Depending on the domain, trust may be about transparency, consistency, representativeness, or accountability.</p>

<h2 id="beyond-relevance-three-dimensions-of-reliability">Beyond Relevance: Three Dimensions of Reliability</h2>

<p>Traditionally, ranking quality is assessed through three lenses:</p>

<ul>
  <li><strong>Relevance</strong>: Does the result actually answer the query?</li>
  <li><strong>Diversity</strong>: Does the list reflect a breadth of perspectives or options?</li>
  <li><strong>Novelty</strong>: Does each additional item bring new value instead of repeating the obvious?</li>
</ul>

<p>Trustworthiness does not replace these but cuts across them. A ranking may be relevant but still untrustworthy if it seems biased or opaque. It may be diverse but untrustworthy if the underlying process is unclear.</p>

<h2 id="different-contexts-different-notions-of-trust">Different Contexts, Different Notions of Trust</h2>

<p>The contours of trust look different depending on the environment in which ranking operates.</p>

<h3 id="non-personalized-rankings">Non-Personalized Rankings</h3>
<p>When personalization is minimal—say, image search for “CEO”—users expect systems to avoid stereotypes and hidden agendas. Measures like balance in representation or neutrality checks help sustain credibility.</p>

<h3 id="crowd-sourced-trends">Crowd-Sourced Trends</h3>
<p>Trending hashtags or popular local businesses raise questions of manipulation. Users must feel confident that influence is not captured by a handful of coordinated actors. Mechanisms like “one account, one vote” or proportional weighting preserve the sense that rankings emerge from genuine collective activity.</p>

<h3 id="personalized-recommendations">Personalized Recommendations</h3>
<p>In highly personalized settings, users must believe the system is not pigeonholing them or overlooking signals unfairly. Metrics around consistency of treatment across demographic slices, or alignment with individual feedback, are essential for sustaining confidence.</p>

<h3 id="advertising">Advertising</h3>
<p>Ads complicate trust, since users know money changes the order. Still, they expect a degree of clarity: are opportunities surfaced consistently across similar users? Are high-value options only shown to select groups? Trust falters if targeting becomes indistinguishable from exclusion.</p>

<h3 id="marketplaces">Marketplaces</h3>
<p>Here, the trust relationship extends to multiple sides: consumers, providers, and sometimes intermediaries. Riders must believe driver ratings are meaningful; providers must believe the platform doesn’t bury them arbitrarily. Trust mechanisms must be multi-directional.</p>

<h2 id="open-challenges">Open Challenges</h2>

<p>What is striking is that there is no universal recipe for trust. Transparency may work in one domain but overwhelm in another. Neutrality may suit generic search, but personalization depends on selective emphasis. And trust is entangled with diversity and novelty: a highly varied set of results may feel unreliable if it lacks coherence, while a very narrow set may feel manipulated even if it is statistically balanced.</p>

<h2 id="looking-ahead">Looking Ahead</h2>

<p>Platforms are beginning to address these issues explicitly. Efforts range from clearer disclosures in advertising to algorithmic audits of recommendation pipelines. The challenge is cultural as much as technical: trust has to be earned continuously, not declared once.</p>

<p>Search and recommendation are not only about retrieval; they are about shaping how people see the world. Framing evaluation through the lens of trust makes us ask harder questions: not only <em>did the system work</em>, but <em>does it deserve to be believed</em>?</p>]]></content><author><name>Rauf Aliev</name></author><category term="Responsible AI" /><category term="Search Ethics" /><category term="Recommender Systems" /><category term="Recommendations" /><category term="Ranking" /><category term="Relevance" /><category term="Personalization" /><summary type="html"><![CDATA[When we think about search engines or recommender systems, the default measure of quality is often relevance: does the system return what I asked for? Yet over time, it has become clear that accuracy alone does not create confidence. These systems don’t just retrieve information—they curate visibility, shape opportunity, and implicitly set the terms of what users come to rely on. That’s why the discussion has shifted toward a broader question: can we trust the ranking we see?]]></summary></entry></feed>